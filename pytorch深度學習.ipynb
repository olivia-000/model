{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5de2fc-8cb0-476d-8da5-94db69e0c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openvino\n",
      "  Downloading openvino-2025.3.0-19807-cp310-cp310-manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from openvino) (1.24.1)\n",
      "Collecting openvino-telemetry>=2023.2.1 (from openvino)\n",
      "  Downloading openvino_telemetry-2025.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from openvino) (23.2)\n",
      "Downloading openvino-2025.3.0-19807-cp310-cp310-manylinux2014_x86_64.whl (49.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openvino_telemetry-2025.2.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: openvino-telemetry, openvino\n",
      "Successfully installed openvino-2025.3.0 openvino-telemetry-2025.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openvino --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed16f60-06d7-41ec-bc7d-8cd79481951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-tensorrt\n",
      "  Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl.metadata (596 bytes)\n",
      "Collecting tensorrt (from nvidia-tensorrt)\n",
      "  Downloading tensorrt-10.13.3.9.tar.gz (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt_cu13==10.13.3.9 (from tensorrt->nvidia-tensorrt)\n",
      "  Downloading tensorrt_cu13-10.13.3.9.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt_cu13_libs==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
      "  Downloading tensorrt_cu13_libs-10.13.3.9.tar.gz (706 bytes)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt_cu13_bindings==10.13.3.9 (from tensorrt_cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
      "  Downloading tensorrt_cu13_bindings-10.13.3.9-cp310-none-manylinux_2_28_x86_64.whl.metadata (606 bytes)\n",
      "Collecting nvidia-cuda-runtime-cu13 (from tensorrt_cu13_libs==10.13.3.9->tensorrt_cu13==10.13.3.9->tensorrt->nvidia-tensorrt)\n",
      "  Downloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl.metadata (225 bytes)\n",
      "Downloading nvidia_tensorrt-99.0.0-py3-none-manylinux_2_17_x86_64.whl (17 kB)\n",
      "Downloading tensorrt_cu13_bindings-10.13.3.9-cp310-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu13-0.0.0a0-py2.py3-none-any.whl (1.2 kB)\n",
      "Building wheels for collected packages: tensorrt, tensorrt_cu13, tensorrt_cu13_libs\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.13.3.9-py2.py3-none-any.whl size=46398 sha256=d3940b2a9a155e80a7dd791ddf274da0cf7138bc9a244a739253f240ac8401bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/bf/be/5afa83ab190f98622801ca4321ed121e2def5367e3bb891d72\n",
      "  Building wheel for tensorrt_cu13 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_cu13: filename=tensorrt_cu13-10.13.3.9-py2.py3-none-any.whl size=17436 sha256=a53836856c33dcc8c02b3ffaa19c35dc60861e5d13595f25d233c6feccf3ca64\n",
      "  Stored in directory: /root/.cache/pip/wheels/34/ce/c8/ae41f1c638712fc9ba0d48f1ab718e4f6271c2f7747e3790f6\n",
      "  Building wheel for tensorrt_cu13_libs (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_cu13_libs: filename=tensorrt_cu13_libs-10.13.3.9-py2.py3-none-manylinux_2_28_x86_64.whl size=2740897716 sha256=19a54f2106f7d9496433a01a596fa4e363f58901110306abe1ce7b6e9617c6a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/07/43/8bdc7ba375434899dfb507d269d92f16db14a310b5129e413d\n",
      "Successfully built tensorrt tensorrt_cu13 tensorrt_cu13_libs\n",
      "Installing collected packages: tensorrt_cu13_bindings, nvidia-cuda-runtime-cu13, tensorrt_cu13_libs, tensorrt_cu13, tensorrt, nvidia-tensorrt\n",
      "Successfully installed nvidia-cuda-runtime-cu13-0.0.0a0 nvidia-tensorrt-99.0.0 tensorrt-10.13.3.9 tensorrt_cu13-10.13.3.9 tensorrt_cu13_bindings-10.13.3.9 tensorrt_cu13_libs-10.13.3.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting torch-tensorrt\n",
      "  Downloading torch_tensorrt-2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=23 in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (23.2)\n",
      "Collecting typing-extensions>=4.7.0 (from torch-tensorrt)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting dllist (from torch-tensorrt)\n",
      "  Downloading dllist-2.0.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting torch<2.9.0,>=2.8.0 (from torch-tensorrt)\n",
      "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting tensorrt<10.13.0,>=10.12.0 (from torch-tensorrt)\n",
      "  Downloading tensorrt-10.12.0.36.tar.gz (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorrt-cu12-bindings<10.13.0,>=10.12.0 (from torch-tensorrt)\n",
      "  Downloading tensorrt_cu12_bindings-10.12.0.36-cp310-none-manylinux_2_28_x86_64.whl.metadata (607 bytes)\n",
      "Collecting tensorrt-cu12-libs<10.13.0,>=10.12.0 (from torch-tensorrt)\n",
      "  Downloading tensorrt_cu12_libs-10.12.0.36.tar.gz (709 bytes)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-tensorrt) (1.24.1)\n",
      "Collecting tensorrt_cu12==10.12.0.36 (from tensorrt<10.13.0,>=10.12.0->torch-tensorrt)\n",
      "  Downloading tensorrt_cu12-10.12.0.36.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12 (from tensorrt-cu12-libs<10.13.0,>=10.12.0->torch-tensorrt)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.9.79-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt) (3.9.0)\n",
      "Collecting sympy>=1.13.3 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.9.0,>=2.8.0->torch-tensorrt) (2023.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12 (from tensorrt-cu12-libs<10.13.0,>=10.12.0->torch-tensorrt)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.4.0 (from torch<2.9.0,>=2.8.0->torch-tensorrt)\n",
      "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.4.0->torch<2.9.0,>=2.8.0->torch-tensorrt) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch<2.9.0,>=2.8.0->torch-tensorrt) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.9.0,>=2.8.0->torch-tensorrt) (2.1.2)\n",
      "Downloading torch_tensorrt-2.8.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_34_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorrt_cu12_bindings-10.12.0.36-cp310-none-manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.0/888.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m212.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dllist-2.0.0-py3-none-any.whl (5.7 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m142.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: tensorrt, tensorrt_cu12, tensorrt-cu12-libs\n",
      "  Building wheel for tensorrt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt: filename=tensorrt-10.12.0.36-py2.py3-none-any.whl size=46641 sha256=d57cc94784aa4196bdd3846ba3ff8013dd83b3cd4a2e5e205b81a5834b8c23d2\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/12/2f/04cb0da2afe8d2a7f100f50814b46ef9ec24a308cc4c320f46\n",
      "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.12.0.36-py2.py3-none-any.whl size=17477 sha256=fb702fd7eab146e17b13f147cc8ba8fa216da5e9b3a2638e21d4cefd61c6a41f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/5b/0b/f12f75d8b1f2787e83666508a6f52c2e2cd64e76babc4abdf5\n",
      "  Building wheel for tensorrt-cu12-libs (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.12.0.36-py2.py3-none-manylinux_2_28_x86_64.whl size=3095483544 sha256=3910039e1d49de0edfdc8bf273e40ad4b85a9d57c7c383fe0e22f75417df9610\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/30/0c/5deca08d1af19cbc0f6b9f806372edf64841c30ff47eff7a81\n",
      "Successfully built tensorrt tensorrt_cu12 tensorrt-cu12-libs\n",
      "Installing collected packages: tensorrt-cu12-bindings, nvidia-cusparselt-cu12, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dllist, tensorrt-cu12-libs, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tensorrt_cu12, nvidia-cusolver-cu12, torch, tensorrt, torch-tensorrt\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nvidia-tensorrt --break-system-packages\n",
    "!pip install torch-tensorrt --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f03e74e-ed2d-4e52-b6f5-039a14f99fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx==1.15.0 in /usr/local/lib/python3.10/dist-packages (1.15.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx==1.15.0) (1.24.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx==1.15.0) (6.32.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx==1.15.0 --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b351d1f1-2179-41cd-9095-0368d0b570c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🏥 醫學影像分割系統 - 專業版\n",
      "================================================================================\n",
      "✓ 使用 PIL 繪製文字\n",
      "✓ 所有套件已就緒\n",
      "\n",
      "================================================================================\n",
      "開始處理\n",
      "================================================================================\n",
      "\n",
      "📊 步驟 1: 載入資料\n",
      "\n",
      "📊 資料集: Hippocampus\n",
      "   訓練樣本: 260\n",
      "✓ 載入 3 個案例\n",
      "\n",
      "📊 步驟 2: 處理案例 367\n",
      "   原始尺寸: (36, 57, 37)\n",
      "   原始 spacing: [1. 1. 1.]\n",
      "\n",
      "📊 步驟 3: 預處理\n",
      "   處理後尺寸: (64, 64, 64)\n",
      "   新 spacing: [0.5625   0.890625 0.578125]\n",
      "   體素體積: 0.29 mm³/voxel\n",
      "\n",
      "📊 步驟 4: 執行分割\n",
      "   左側: 4639 體素\n",
      "   右側: 13376 體素\n",
      "\n",
      "📊 步驟 5: 特徵提取\n",
      "   總體積: 5217.6 mm³\n",
      "   左側體積: 1343.6 mm³\n",
      "   右側體積: 3874.1 mm³\n",
      "   Dice係數: 0.014\n",
      "\n",
      "📊 步驟 6: 創建可視化\n",
      "   ✓ 已保存: /workspace/outputs/result_367.png\n",
      "   ✓ 已保存: /workspace/outputs/report_367.json\n",
      "\n",
      "================================================================================\n",
      "✓ 處理完成!\n",
      "================================================================================\n",
      "\n",
      "📊 最終結果:\n",
      "  總體積: 5217.6 mm³\n",
      "  Dice分數: 0.014\n",
      "\n",
      "輸出位置: /workspace/outputs/\n",
      "\n",
      "✅ 系統運行成功!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "🏥 醫學影像分割系統 - 專業修正版\n",
    "修正：spacing計算、標註處理、向量化縮放、解剖學標註\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🏥 醫學影像分割系統 - 專業版\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    USE_PIL = True\n",
    "    print(\"✓ 使用 PIL 繪製文字\")\n",
    "except:\n",
    "    USE_PIL = False\n",
    "    print(\"✓ 不使用文字標註\")\n",
    "\n",
    "print(\"✓ 所有套件已就緒\")\n",
    "\n",
    "# ==================== 資料載入 ====================\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, data_root):\n",
    "        self.data_root = Path(data_root)\n",
    "        dataset_json = self.data_root / 'dataset.json'\n",
    "        \n",
    "        if not dataset_json.exists():\n",
    "            raise FileNotFoundError(f\"找不到 dataset.json: {dataset_json}\")\n",
    "        \n",
    "        with open(dataset_json, 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        print(f\"\\n📊 資料集: {self.metadata['name']}\")\n",
    "        print(f\"   訓練樣本: {self.metadata['numTraining']}\")\n",
    "    \n",
    "    def load_nifti(self, filepath):\n",
    "        \"\"\"載入 NIfTI 檔案\"\"\"\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"檔案不存在: {filepath}\")\n",
    "        \n",
    "        img = nib.load(str(filepath))\n",
    "        data = img.get_fdata()\n",
    "        spacing = np.array(img.header.get_zooms()[:3])\n",
    "        \n",
    "        return data, {'spacing': spacing, 'shape': np.array(data.shape)}\n",
    "    \n",
    "    def get_cases(self, num=5):\n",
    "        \"\"\"安全地獲取案例\"\"\"\n",
    "        cases = []\n",
    "        training_data = self.metadata.get('training', [])\n",
    "        \n",
    "        for item in training_data[:num]:\n",
    "            # 保守處理路徑\n",
    "            img_rel = item['image'].lstrip('./')\n",
    "            lbl_rel = item['label'].lstrip('./')\n",
    "            \n",
    "            img_path = self.data_root / img_rel\n",
    "            lbl_path = self.data_root / lbl_rel\n",
    "            \n",
    "            # 檢查存在性\n",
    "            if img_path.exists() and lbl_path.exists():\n",
    "                case_id = img_path.stem.replace('hippocampus_', '').replace('.nii', '')\n",
    "                cases.append({\n",
    "                    'image': img_path,\n",
    "                    'label': lbl_path,\n",
    "                    'id': case_id\n",
    "                })\n",
    "            else:\n",
    "                print(f\"⚠️ 跳過缺失檔案: {img_path.name}\")\n",
    "        \n",
    "        if not cases:\n",
    "            raise ValueError(\"沒有找到有效的案例檔案\")\n",
    "        \n",
    "        return cases\n",
    "\n",
    "# ==================== 向量化縮放 ====================\n",
    "\n",
    "def resize_nearest_vectorized(image, target_shape):\n",
    "    \"\"\"向量化的最近鄰縮放 - O(target_size)\"\"\"\n",
    "    src_d, src_h, src_w = image.shape\n",
    "    dst_d, dst_h, dst_w = target_shape\n",
    "    \n",
    "    # 計算源索引 (向量化)\n",
    "    scale_d = src_d / dst_d\n",
    "    scale_h = src_h / dst_h\n",
    "    scale_w = src_w / dst_w\n",
    "    \n",
    "    idx_d = np.floor(np.arange(dst_d) * scale_d).astype(int)\n",
    "    idx_h = np.floor(np.arange(dst_h) * scale_h).astype(int)\n",
    "    idx_w = np.floor(np.arange(dst_w) * scale_w).astype(int)\n",
    "    \n",
    "    # 邊界檢查\n",
    "    idx_d = np.clip(idx_d, 0, src_d - 1)\n",
    "    idx_h = np.clip(idx_h, 0, src_h - 1)\n",
    "    idx_w = np.clip(idx_w, 0, src_w - 1)\n",
    "    \n",
    "    # 一次性索引 (NumPy 高級索引)\n",
    "    result = image[idx_d[:, None, None], idx_h[None, :, None], idx_w[None, None, :]]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ==================== 預處理（分流版本）====================\n",
    "\n",
    "def preprocess_image(image, target_size=64):\n",
    "    \"\"\"影像預處理 - z-score 標準化\"\"\"\n",
    "    # 百分位裁切\n",
    "    p1, p99 = np.percentile(image, [1, 99])\n",
    "    image = np.clip(image, p1, p99)\n",
    "    \n",
    "    # Z-score 標準化\n",
    "    mean = np.mean(image)\n",
    "    std = np.std(image)\n",
    "    if std > 1e-8:\n",
    "        image = (image - mean) / std\n",
    "    \n",
    "    # 縮放\n",
    "    target_shape = (target_size, target_size, target_size)\n",
    "    result = resize_nearest_vectorized(image, target_shape)\n",
    "    \n",
    "    return result.astype(np.float32)\n",
    "\n",
    "def preprocess_label(label, target_size=64):\n",
    "    \"\"\"標註預處理 - 僅重採樣（保持整數）\"\"\"\n",
    "    # 直接最近鄰縮放（不做標準化）\n",
    "    target_shape = (target_size, target_size, target_size)\n",
    "    result = resize_nearest_vectorized(label, target_shape)\n",
    "    \n",
    "    # 四捨五入並轉為整數\n",
    "    result = np.round(result).astype(np.uint8)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_new_spacing(orig_spacing, orig_shape, target_shape):\n",
    "    \"\"\"計算重採樣後的新 spacing\"\"\"\n",
    "    orig_spacing = np.array(orig_spacing)\n",
    "    orig_shape = np.array(orig_shape)\n",
    "    target_shape = np.array(target_shape)\n",
    "    \n",
    "    new_spacing = (orig_spacing * orig_shape) / target_shape\n",
    "    \n",
    "    return new_spacing\n",
    "\n",
    "# ==================== 分割 ====================\n",
    "\n",
    "def segment(image):\n",
    "    \"\"\"簡單閾值分割\"\"\"\n",
    "    threshold = np.percentile(image, 70)\n",
    "    binary = (image > threshold).astype(np.uint8)\n",
    "    \n",
    "    mid = binary.shape[0] // 2\n",
    "    center = binary.shape[2] // 2  # 寬度軸中點\n",
    "    prediction = np.zeros_like(binary)\n",
    "    \n",
    "    # 注意：這裡用左右分區，非前後\n",
    "    # 在中間層處理\n",
    "    for i in range(max(0, mid-10), min(binary.shape[0], mid+10)):\n",
    "        prediction[i, :, :center] = binary[i, :, :center] * 1  # 左側\n",
    "        prediction[i, :, center:] = binary[i, :, center:] * 2  # 右側\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# ==================== 特徵提取（修正 spacing）====================\n",
    "\n",
    "def extract_features(pred, gt, new_spacing):\n",
    "    \"\"\"\n",
    "    使用重採樣後的 spacing 計算體積\n",
    "    new_spacing: 已根據縮放比例調整過的 spacing\n",
    "    \"\"\"\n",
    "    voxel_volume = float(np.prod(new_spacing))\n",
    "    \n",
    "    left_vol = float(np.sum(pred == 1)) * voxel_volume\n",
    "    right_vol = float(np.sum(pred == 2)) * voxel_volume\n",
    "    total = left_vol + right_vol\n",
    "    \n",
    "    # Dice 係數\n",
    "    dice_scores = []\n",
    "    for i in [1, 2]:\n",
    "        p = (pred == i).astype(np.float32)\n",
    "        g = (gt == i).astype(np.float32)\n",
    "        inter = float(np.sum(p * g))\n",
    "        union = float(np.sum(p) + np.sum(g))\n",
    "        dice = 2 * inter / (union + 1e-8) if union > 0 else 0.0\n",
    "        dice_scores.append(dice)\n",
    "    \n",
    "    return {\n",
    "        'total_volume': total,\n",
    "        'left_vol': left_vol,\n",
    "        'right_vol': right_vol,\n",
    "        'dice': float(np.mean(dice_scores)),\n",
    "        'dice_left': dice_scores[0],\n",
    "        'dice_right': dice_scores[1]\n",
    "    }\n",
    "\n",
    "# ==================== 可視化 ====================\n",
    "\n",
    "def add_text_pil(image_array, features):\n",
    "    \"\"\"使用PIL添加文字\"\"\"\n",
    "    img = Image.fromarray(image_array)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 12)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    texts = [\n",
    "        \"HIPPOCAMPUS SEGMENTATION\",\n",
    "        \"(Left-Right Split Demo)\",\n",
    "        \"\",\n",
    "        f\"Total: {features['total_volume']:.1f} mm3\",\n",
    "        f\"Left:  {features['left_vol']:.1f} mm3\",\n",
    "        f\"Right: {features['right_vol']:.1f} mm3\",\n",
    "        \"\",\n",
    "        f\"Dice: {features['dice']:.3f}\",\n",
    "        f\"  Left:  {features['dice_left']:.3f}\",\n",
    "        f\"  Right: {features['dice_right']:.3f}\",\n",
    "    ]\n",
    "    \n",
    "    y = 10\n",
    "    for text in texts:\n",
    "        draw.text((10, y), text, fill=(0, 0, 0), font=font)\n",
    "        y += 18\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "def visualize(image, pred, gt, features):\n",
    "    \"\"\"創建可視化\"\"\"\n",
    "    mid = pred.shape[0] // 2\n",
    "    views = []\n",
    "    \n",
    "    for offset in [-8, 0, 8]:\n",
    "        idx = mid + offset\n",
    "        if 0 <= idx < pred.shape[0]:\n",
    "            # 標準化到0-255\n",
    "            img_slice = image[idx]\n",
    "            img_min, img_max = float(img_slice.min()), float(img_slice.max())\n",
    "            if img_max > img_min:\n",
    "                img_norm = ((img_slice - img_min) / (img_max - img_min) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img_norm = np.zeros_like(img_slice, dtype=np.uint8)\n",
    "            \n",
    "            # 轉為RGB\n",
    "            img_rgb = np.stack([img_norm, img_norm, img_norm], axis=-1)\n",
    "            \n",
    "            # 預測疊加（左=紅，右=藍）\n",
    "            pred_overlay = img_rgb.copy()\n",
    "            pred_overlay[pred[idx] == 1] = [255, 0, 0]  # 左側-紅色\n",
    "            pred_overlay[pred[idx] == 2] = [0, 0, 255]  # 右側-藍色\n",
    "            pred_result = (img_rgb * 0.7 + pred_overlay * 0.3).astype(np.uint8)\n",
    "            \n",
    "            # Ground Truth疊加（左=綠，右=黃）\n",
    "            gt_overlay = img_rgb.copy()\n",
    "            gt_overlay[gt[idx] == 1] = [0, 255, 0]      # 左側-綠色\n",
    "            gt_overlay[gt[idx] == 2] = [255, 255, 0]    # 右側-黃色\n",
    "            gt_result = (img_rgb * 0.7 + gt_overlay * 0.3).astype(np.uint8)\n",
    "            \n",
    "            combined = np.hstack([pred_result, gt_result])\n",
    "            views.append(combined)\n",
    "    \n",
    "    result = np.vstack(views)\n",
    "    \n",
    "    # 添加文字\n",
    "    if USE_PIL:\n",
    "        text_h = result.shape[0]\n",
    "        text_w = 300\n",
    "        text_area = np.ones((text_h, text_w, 3), dtype=np.uint8) * 255\n",
    "        text_area = add_text_pil(text_area, features)\n",
    "        result = np.hstack([result, text_area])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_image(image_array, filepath):\n",
    "    \"\"\"使用PIL保存\"\"\"\n",
    "    img = Image.fromarray(image_array.astype(np.uint8))\n",
    "    img.save(filepath)\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "\n",
    "def main():\n",
    "    DATA_ROOT = Path('/workspace/Task04_Hippocampus')\n",
    "    OUTPUT_DIR = Path('/workspace/outputs')\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"開始處理\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 載入資料\n",
    "    print(\"\\n📊 步驟 1: 載入資料\")\n",
    "    loader = DataLoader(DATA_ROOT)\n",
    "    cases = loader.get_cases(num=3)\n",
    "    print(f\"✓ 載入 {len(cases)} 個案例\")\n",
    "    \n",
    "    # 處理第一個案例\n",
    "    case = cases[0]\n",
    "    print(f\"\\n📊 步驟 2: 處理案例 {case['id']}\")\n",
    "    \n",
    "    image, img_meta = loader.load_nifti(case['image'])\n",
    "    label, lbl_meta = loader.load_nifti(case['label'])\n",
    "    print(f\"   原始尺寸: {image.shape}\")\n",
    "    print(f\"   原始 spacing: {img_meta['spacing']}\")\n",
    "    \n",
    "    # 預處理（分流）\n",
    "    print(\"\\n📊 步驟 3: 預處理\")\n",
    "    target_size = 64\n",
    "    image_prep = preprocess_image(image, target_size)\n",
    "    label_prep = preprocess_label(label, target_size)\n",
    "    \n",
    "    # 計算新 spacing\n",
    "    new_spacing = calculate_new_spacing(\n",
    "        img_meta['spacing'], \n",
    "        img_meta['shape'], \n",
    "        (target_size, target_size, target_size)\n",
    "    )\n",
    "    \n",
    "    print(f\"   處理後尺寸: {image_prep.shape}\")\n",
    "    print(f\"   新 spacing: {new_spacing}\")\n",
    "    print(f\"   體素體積: {np.prod(new_spacing):.2f} mm³/voxel\")\n",
    "    \n",
    "    # 分割\n",
    "    print(\"\\n📊 步驟 4: 執行分割\")\n",
    "    prediction = segment(image_prep)\n",
    "    print(f\"   左側: {np.sum(prediction == 1)} 體素\")\n",
    "    print(f\"   右側: {np.sum(prediction == 2)} 體素\")\n",
    "    \n",
    "    # 特徵提取（使用新 spacing）\n",
    "    print(\"\\n📊 步驟 5: 特徵提取\")\n",
    "    features = extract_features(prediction, label_prep, new_spacing)\n",
    "    print(f\"   總體積: {features['total_volume']:.1f} mm³\")\n",
    "    print(f\"   左側體積: {features['left_vol']:.1f} mm³\")\n",
    "    print(f\"   右側體積: {features['right_vol']:.1f} mm³\")\n",
    "    print(f\"   Dice係數: {features['dice']:.3f}\")\n",
    "    \n",
    "    # 可視化\n",
    "    print(\"\\n📊 步驟 6: 創建可視化\")\n",
    "    viz = visualize(image_prep, prediction, label_prep, features)\n",
    "    \n",
    "    output_path = OUTPUT_DIR / f\"result_{case['id']}.png\"\n",
    "    save_image(viz, output_path)\n",
    "    print(f\"   ✓ 已保存: {output_path}\")\n",
    "    \n",
    "    # JSON報告\n",
    "    report = {\n",
    "        'case_id': case['id'],\n",
    "        'original_shape': img_meta['shape'].tolist(),\n",
    "        'original_spacing': img_meta['spacing'].tolist(),\n",
    "        'resampled_shape': [target_size] * 3,\n",
    "        'resampled_spacing': new_spacing.tolist(),\n",
    "        'features': features,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    json_path = OUTPUT_DIR / f\"report_{case['id']}.json\"\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    print(f\"   ✓ 已保存: {json_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✓ 處理完成!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n📊 最終結果:\")\n",
    "    print(f\"  總體積: {features['total_volume']:.1f} mm³\")\n",
    "    print(f\"  Dice分數: {features['dice']:.3f}\")\n",
    "    print(f\"\\n輸出位置: {OUTPUT_DIR}/\")\n",
    "    print(\"\\n✅ 系統運行成功!\")\n",
    "    \n",
    "    return viz, features\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result_viz, result_features = main()\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02b8fdfd-3d38-4e2a-9fb0-5fd2d2e195e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧠 醫學影像分割訓練系統 - 專業版\n",
      "================================================================================\n",
      "✓ PyTorch 2.1.0+cu118\n",
      "✓ CUDA: True\n",
      "✓ cuDNN benchmark enabled\n",
      "\n",
      "使用設備: cuda\n",
      "\n",
      "準備資料...\n",
      "  訓練集: 208 個案例\n",
      "  驗證集: 52 個案例\n",
      "\n",
      "建立模型...\n",
      "  參數: 1,402,003\n",
      "  AMP enabled: True\n",
      "\n",
      "開始訓練 10 epochs\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.5706\n",
      "    Batch 10/104, Loss: 0.4696\n",
      "    Batch 20/104, Loss: 0.4542\n",
      "    Batch 30/104, Loss: 0.4323\n",
      "    Batch 40/104, Loss: 0.4178\n",
      "    Batch 50/104, Loss: 0.4056\n",
      "    Batch 60/104, Loss: 0.4053\n",
      "    Batch 70/104, Loss: 0.3969\n",
      "    Batch 80/104, Loss: 0.3498\n",
      "    Batch 90/104, Loss: 0.3299\n",
      "    Batch 100/104, Loss: 0.3091\n",
      "\n",
      "  訓練損失: 0.4097\n",
      "  驗證損失: 0.3119\n",
      "  驗證 Dice: 0.7447\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.7447)\n",
      "\n",
      "Epoch 2/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.3355\n",
      "    Batch 10/104, Loss: 0.2731\n",
      "    Batch 20/104, Loss: 0.2825\n",
      "    Batch 30/104, Loss: 0.2375\n",
      "    Batch 40/104, Loss: 0.2094\n",
      "    Batch 50/104, Loss: 0.2021\n",
      "    Batch 60/104, Loss: 0.1952\n",
      "    Batch 70/104, Loss: 0.1852\n",
      "    Batch 80/104, Loss: 0.1330\n",
      "    Batch 90/104, Loss: 0.1436\n",
      "    Batch 100/104, Loss: 0.1489\n",
      "\n",
      "  訓練損失: 0.2093\n",
      "  驗證損失: 0.1442\n",
      "  驗證 Dice: 0.8265\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8265)\n",
      "\n",
      "Epoch 3/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1185\n",
      "    Batch 10/104, Loss: 0.1186\n",
      "    Batch 20/104, Loss: 0.1181\n",
      "    Batch 30/104, Loss: 0.1157\n",
      "    Batch 40/104, Loss: 0.1015\n",
      "    Batch 50/104, Loss: 0.0916\n",
      "    Batch 60/104, Loss: 0.0949\n",
      "    Batch 70/104, Loss: 0.1114\n",
      "    Batch 80/104, Loss: 0.0838\n",
      "    Batch 90/104, Loss: 0.0835\n",
      "    Batch 100/104, Loss: 0.0836\n",
      "\n",
      "  訓練損失: 0.1086\n",
      "  驗證損失: 0.0992\n",
      "  驗證 Dice: 0.8518\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8518)\n",
      "\n",
      "Epoch 4/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0792\n",
      "    Batch 10/104, Loss: 0.0927\n",
      "    Batch 20/104, Loss: 0.1016\n",
      "    Batch 30/104, Loss: 0.0692\n",
      "    Batch 40/104, Loss: 0.0928\n",
      "    Batch 50/104, Loss: 0.0895\n",
      "    Batch 60/104, Loss: 0.0750\n",
      "    Batch 70/104, Loss: 0.0633\n",
      "    Batch 80/104, Loss: 0.0996\n",
      "    Batch 90/104, Loss: 0.0953\n",
      "    Batch 100/104, Loss: 0.0859\n",
      "\n",
      "  訓練損失: 0.0869\n",
      "  驗證損失: 0.0883\n",
      "  驗證 Dice: 0.8585\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8585)\n",
      "\n",
      "Epoch 5/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0762\n",
      "    Batch 10/104, Loss: 0.0963\n",
      "    Batch 20/104, Loss: 0.0751\n",
      "    Batch 30/104, Loss: 0.0911\n",
      "    Batch 40/104, Loss: 0.0719\n",
      "    Batch 50/104, Loss: 0.0832\n",
      "    Batch 60/104, Loss: 0.0663\n",
      "    Batch 70/104, Loss: 0.0628\n",
      "    Batch 80/104, Loss: 0.0784\n",
      "    Batch 90/104, Loss: 0.0645\n",
      "    Batch 100/104, Loss: 0.0893\n",
      "\n",
      "  訓練損失: 0.0792\n",
      "  驗證損失: 0.0811\n",
      "  驗證 Dice: 0.8634\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8634)\n",
      "\n",
      "Epoch 6/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0692\n",
      "    Batch 10/104, Loss: 0.0694\n",
      "    Batch 20/104, Loss: 0.0898\n",
      "    Batch 30/104, Loss: 0.0547\n",
      "    Batch 40/104, Loss: 0.0662\n",
      "    Batch 50/104, Loss: 0.0735\n",
      "    Batch 60/104, Loss: 0.0797\n",
      "    Batch 70/104, Loss: 0.0604\n",
      "    Batch 80/104, Loss: 0.0779\n",
      "    Batch 90/104, Loss: 0.0737\n",
      "    Batch 100/104, Loss: 0.0794\n",
      "\n",
      "  訓練損失: 0.0726\n",
      "  驗證損失: 0.0756\n",
      "  驗證 Dice: 0.8717\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8717)\n",
      "\n",
      "Epoch 7/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0598\n",
      "    Batch 10/104, Loss: 0.0668\n",
      "    Batch 20/104, Loss: 0.0569\n",
      "    Batch 30/104, Loss: 0.0498\n",
      "    Batch 40/104, Loss: 0.1033\n",
      "    Batch 50/104, Loss: 0.0520\n",
      "    Batch 60/104, Loss: 0.0857\n",
      "    Batch 70/104, Loss: 0.0803\n",
      "    Batch 80/104, Loss: 0.0573\n",
      "    Batch 90/104, Loss: 0.0463\n",
      "    Batch 100/104, Loss: 0.0631\n",
      "\n",
      "  訓練損失: 0.0709\n",
      "  驗證損失: 0.0765\n",
      "  驗證 Dice: 0.8703\n",
      "  學習率: 0.001000\n",
      "\n",
      "Epoch 8/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0643\n",
      "    Batch 10/104, Loss: 0.0831\n",
      "    Batch 20/104, Loss: 0.0615\n",
      "    Batch 30/104, Loss: 0.0527\n",
      "    Batch 40/104, Loss: 0.0835\n",
      "    Batch 50/104, Loss: 0.0886\n",
      "    Batch 60/104, Loss: 0.0516\n",
      "    Batch 70/104, Loss: 0.0918\n",
      "    Batch 80/104, Loss: 0.0716\n",
      "    Batch 90/104, Loss: 0.0531\n",
      "    Batch 100/104, Loss: 0.0618\n",
      "\n",
      "  訓練損失: 0.0678\n",
      "  驗證損失: 0.0687\n",
      "  驗證 Dice: 0.8823\n",
      "  學習率: 0.001000\n",
      "  ✓ 保存最佳模型 (Dice: 0.8823)\n",
      "\n",
      "Epoch 9/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0508\n",
      "    Batch 10/104, Loss: 0.0525\n",
      "    Batch 20/104, Loss: 0.0465\n",
      "    Batch 30/104, Loss: 0.0612\n",
      "    Batch 40/104, Loss: 0.0553\n",
      "    Batch 50/104, Loss: 0.0788\n",
      "    Batch 60/104, Loss: 0.0563\n",
      "    Batch 70/104, Loss: 0.0825\n",
      "    Batch 80/104, Loss: 0.0746\n",
      "    Batch 90/104, Loss: 0.0683\n",
      "    Batch 100/104, Loss: 0.0690\n",
      "\n",
      "  訓練損失: 0.0655\n",
      "  驗證損失: 0.0735\n",
      "  驗證 Dice: 0.8736\n",
      "  學習率: 0.001000\n",
      "\n",
      "Epoch 10/10\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0703\n",
      "    Batch 10/104, Loss: 0.0749\n",
      "    Batch 20/104, Loss: 0.0480\n",
      "    Batch 30/104, Loss: 0.0742\n",
      "    Batch 40/104, Loss: 0.0709\n",
      "    Batch 50/104, Loss: 0.0446\n",
      "    Batch 60/104, Loss: 0.0728\n",
      "    Batch 70/104, Loss: 0.0553\n",
      "    Batch 80/104, Loss: 0.1032\n",
      "    Batch 90/104, Loss: 0.0688\n",
      "    Batch 100/104, Loss: 0.0559\n",
      "\n",
      "  訓練損失: 0.0644\n",
      "  驗證損失: 0.0687\n",
      "  驗證 Dice: 0.8820\n",
      "  學習率: 0.000500\n",
      "\n",
      "================================================================================\n",
      "✓ 訓練完成! 最佳 Dice: 0.8823\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "🧠 醫學影像分割訓練系統 - 專業完整版\n",
    "整合：隨機切分、類別平衡、AMP、梯度裁剪、優化的評估指標\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🧠 醫學影像分割訓練系統 - 專業版\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "os.environ['TORCH_DISABLE_ONNX'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "print(f\"✓ PyTorch {torch.__version__}\")\n",
    "print(f\"✓ CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "# cuDNN 優化\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"✓ cuDNN benchmark enabled\")\n",
    "\n",
    "# ==================== 資料集 ====================\n",
    "\n",
    "class HippocampusDataset(Dataset):\n",
    "    def __init__(self, data_root, indices, target_size=64):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        with open(self.data_root / 'dataset.json', 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        training_data = metadata['training']\n",
    "        self.cases = [training_data[i] for i in indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "    \n",
    "    def resize_3d(self, image, target_shape):\n",
    "        \"\"\"向量化最近鄰縮放\"\"\"\n",
    "        src_d, src_h, src_w = image.shape\n",
    "        dst_d, dst_h, dst_w = target_shape\n",
    "        \n",
    "        idx_d = np.clip(np.floor(np.arange(dst_d) * src_d / dst_d).astype(int), 0, src_d - 1)\n",
    "        idx_h = np.clip(np.floor(np.arange(dst_h) * src_h / dst_h).astype(int), 0, src_h - 1)\n",
    "        idx_w = np.clip(np.floor(np.arange(dst_w) * src_w / dst_w).astype(int), 0, src_w - 1)\n",
    "        \n",
    "        return image[idx_d[:, None, None], idx_h[None, :, None], idx_w[None, None, :]]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        case = self.cases[idx]\n",
    "        img_path = self.data_root / case['image'].lstrip('./')\n",
    "        lbl_path = self.data_root / case['label'].lstrip('./')\n",
    "        \n",
    "        # 載入影像 - 直接轉 float32 節省記憶體\n",
    "        image = nib.load(str(img_path)).get_fdata(dtype=np.float32)\n",
    "        p1, p99 = np.percentile(image, [1, 99])\n",
    "        image = np.clip(image, p1, p99)\n",
    "        mean, std = image.mean(), image.std()\n",
    "        if std > 1e-8:\n",
    "            image = (image - mean) / std\n",
    "        \n",
    "        # 載入標註 - float32\n",
    "        label = nib.load(str(lbl_path)).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        # 縮放\n",
    "        image = self.resize_3d(image, (self.target_size,) * 3)\n",
    "        label = self.resize_3d(label, (self.target_size,) * 3)\n",
    "        label = np.round(label).astype(np.int64)\n",
    "        \n",
    "        return torch.FloatTensor(image).unsqueeze(0), torch.LongTensor(label)\n",
    "\n",
    "# ==================== 資料切分（隨機） ====================\n",
    "\n",
    "def get_train_val_split(num_samples, train_ratio=0.8, seed=42):\n",
    "    \"\"\"固定隨機種子的資料切分\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split_idx = int(num_samples * train_ratio)\n",
    "    return indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# ==================== 模型 ====================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_ch)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn2(self.conv2(self.relu(self.bn1(self.conv1(x))))))\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=3, base=16):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_ch, base)\n",
    "        self.enc2 = ConvBlock(base, base * 2)\n",
    "        self.enc3 = ConvBlock(base * 2, base * 4)\n",
    "        self.bottleneck = ConvBlock(base * 4, base * 8)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose3d(base * 8, base * 4, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(base * 8, base * 4)\n",
    "        self.up2 = nn.ConvTranspose3d(base * 4, base * 2, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(base * 4, base * 2)\n",
    "        self.up1 = nn.ConvTranspose3d(base * 2, base, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(base * 2, base)\n",
    "        \n",
    "        self.out = nn.Conv3d(base, num_classes, 1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        \n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        \n",
    "        return self.out(d1)\n",
    "\n",
    "# ==================== 損失函數（類別平衡）====================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss 處理類別不平衡\"\"\"\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        if alpha is not None:\n",
    "            self.register_buffer('alpha', alpha)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[target]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        target_one_hot = F.one_hot(target, pred.shape[1]).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        inter = (pred * target_one_hot).sum(dim=(2, 3, 4))\n",
    "        union = pred.sum(dim=(2, 3, 4)) + target_one_hot.sum(dim=(2, 3, 4))\n",
    "        dice = (2. * inter + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, use_focal=True):\n",
    "        super().__init__()\n",
    "        if use_focal:\n",
    "            # 背景權重較低\n",
    "            alpha = torch.tensor([0.2, 1.0, 1.0])\n",
    "            self.ce = FocalLoss(alpha=alpha, gamma=2.0)\n",
    "        else:\n",
    "            # 傳統加權 CE\n",
    "            weight = torch.tensor([0.2, 1.0, 1.0])\n",
    "            self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "        \n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return 0.3 * self.ce(pred, target) + 0.7 * self.dice(pred, target)\n",
    "\n",
    "# ==================== Adam with Weight Decay ====================\n",
    "\n",
    "class AdamW:\n",
    "    \"\"\"手動實現 AdamW，支援 weight decay\"\"\"\n",
    "    def __init__(self, params, lr=1e-3, weight_decay=1e-4):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta1 = 0.9\n",
    "        self.beta2 = 0.999\n",
    "        self.eps = 1e-8\n",
    "        self.t = 0\n",
    "        \n",
    "        # 為了相容 GradScaler，添加 param_groups\n",
    "        self.param_groups = [{'params': self.params, 'lr': lr}]\n",
    "        \n",
    "        self.m = [torch.zeros_like(p.data) for p in self.params]\n",
    "        self.v = [torch.zeros_like(p.data) for p in self.params]\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            if p.grad is not None:\n",
    "                p.grad.zero_()\n",
    "    \n",
    "    def step(self, closure=None):\n",
    "        \"\"\"添加 closure 參數以相容 optimizer 介面\"\"\"\n",
    "        self.t += 1\n",
    "        for i, p in enumerate(self.params):\n",
    "            if p.grad is None:\n",
    "                continue\n",
    "            \n",
    "            grad = p.grad.data\n",
    "            \n",
    "            # Weight decay\n",
    "            if self.weight_decay > 0:\n",
    "                p.data.mul_(1 - self.lr * self.weight_decay)\n",
    "            \n",
    "            # Adam 更新\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * grad ** 2\n",
    "            \n",
    "            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "            \n",
    "            p.data -= self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "    \n",
    "    def set_lr(self, lr):\n",
    "        \"\"\"動態調整學習率\"\"\"\n",
    "        self.lr = lr\n",
    "        self.param_groups[0]['lr'] = lr\n",
    "\n",
    "# ==================== 訓練器（優化版）====================\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device, output_dir, use_amp=True):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "        self.criterion = CombinedLoss(use_focal=True).to(device)\n",
    "        \n",
    "        # AMP\n",
    "        self.use_amp = use_amp and torch.cuda.is_available()\n",
    "        self.scaler = GradScaler() if self.use_amp else None\n",
    "        \n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_dice': []}\n",
    "        self.best_dice = 0.0\n",
    "        self.lr = 1e-3\n",
    "        \n",
    "        print(f\"  AMP enabled: {self.use_amp}\")\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # AMP forward\n",
    "            if self.use_amp:\n",
    "                with autocast():\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"    Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"累積式 Dice 計算\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # 累積 intersection 和 union\n",
    "        total_inter = {1: 0.0, 2: 0.0}\n",
    "        total_union = {1: 0.0, 2: 0.0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = self.model(images)\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "                else:\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                # 累積每個類別的 intersection 和 union\n",
    "                for cls in [1, 2]:\n",
    "                    pred_mask = (preds == cls).float()\n",
    "                    target_mask = (labels == cls).float()\n",
    "                    \n",
    "                    total_inter[cls] += (pred_mask * target_mask).sum().item()\n",
    "                    total_union[cls] += (pred_mask.sum() + target_mask.sum()).item()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        # 計算整體 Dice\n",
    "        dice_scores = []\n",
    "        for cls in [1, 2]:\n",
    "            dice = (2.0 * total_inter[cls]) / (total_union[cls] + 1e-8)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        avg_dice = np.mean(dice_scores)\n",
    "        \n",
    "        return total_loss / len(self.val_loader), avg_dice\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        print(f\"\\n開始訓練 {num_epochs} epochs\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_dice = self.validate()\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_dice'].append(val_dice)\n",
    "            \n",
    "            # 學習率衰減\n",
    "            if epoch % 10 == 0:\n",
    "                self.lr *= 0.5\n",
    "                self.optimizer.set_lr(self.lr)\n",
    "            \n",
    "            print(f\"\\n  訓練損失: {train_loss:.4f}\")\n",
    "            print(f\"  驗證損失: {val_loss:.4f}\")\n",
    "            print(f\"  驗證 Dice: {val_dice:.4f}\")\n",
    "            print(f\"  學習率: {self.lr:.6f}\")\n",
    "            \n",
    "            # 保存最佳\n",
    "            if val_dice > self.best_dice:\n",
    "                self.best_dice = val_dice\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'dice': val_dice,\n",
    "                    'history': self.history\n",
    "                }, self.output_dir / 'best_model.pth')\n",
    "                print(f\"  ✓ 保存最佳模型 (Dice: {val_dice:.4f})\")\n",
    "        \n",
    "        # 保存歷史\n",
    "        with open(self.output_dir / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"✓ 訓練完成! 最佳 Dice: {self.best_dice:.4f}\")\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "\n",
    "def main():\n",
    "    DATA_ROOT = '/workspace/Task04_Hippocampus'\n",
    "    OUTPUT_DIR = '/workspace/outputs/training_pro'\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 10\n",
    "    TARGET_SIZE = 64\n",
    "    USE_AMP = True\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\n使用設備: {device}\")\n",
    "    \n",
    "    # 隨機切分資料\n",
    "    print(\"\\n準備資料...\")\n",
    "    with open(Path(DATA_ROOT) / 'dataset.json') as f:\n",
    "        num_samples = len(json.load(f)['training'])\n",
    "    \n",
    "    train_indices, val_indices = get_train_val_split(num_samples, train_ratio=0.8, seed=42)\n",
    "    print(f\"  訓練集: {len(train_indices)} 個案例\")\n",
    "    print(f\"  驗證集: {len(val_indices)} 個案例\")\n",
    "    \n",
    "    train_dataset = HippocampusDataset(DATA_ROOT, train_indices, TARGET_SIZE)\n",
    "    val_dataset = HippocampusDataset(DATA_ROOT, val_indices, TARGET_SIZE)\n",
    "    \n",
    "    # 優化的 DataLoader 參數\n",
    "    num_workers = min(4, os.cpu_count() or 1) if torch.cuda.is_available() else 0\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        persistent_workers=num_workers > 0,\n",
    "        prefetch_factor=2 if num_workers > 0 else None\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    \n",
    "    print(\"\\n建立模型...\")\n",
    "    model = UNet3D(1, 3, 16)\n",
    "    print(f\"  參數: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    trainer = Trainer(model, train_loader, val_loader, device, OUTPUT_DIR, use_amp=USE_AMP)\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n訓練中斷\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b98f35d1-5879-40aa-80fc-ee20d7878b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧠 醫學影像分割訓練系統 - 生產級\n",
      "================================================================================\n",
      "\n",
      "🔧 設置環境...\n",
      "  ✓ 已短路 torch._compile 和 torch.onnx\n",
      "\n",
      "✓ PyTorch 2.1.0+cu118\n",
      "✓ CUDA: True\n",
      "✓ cuDNN benchmark enabled\n",
      "\n",
      "🎲 設置隨機種子: 42\n",
      "使用設備: cuda\n",
      "\n",
      "準備資料...\n",
      "  訓練集: 208 個案例\n",
      "  驗證集: 52 個案例\n",
      "  DataLoader workers: 4\n",
      "  影像插值: trilinear\n",
      "  標註插值: nearest\n",
      "\n",
      "建立模型...\n",
      "  參數: 1,402,003\n",
      "  使用 GroupNorm (穩定於小 batch)\n",
      "  使用 SGD + Nesterov momentum\n",
      "  使用 Cosine Annealing LR (T_max=30)\n",
      "\n",
      "開始訓練 30 epochs\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.6117\n",
      "    Batch 10/104, Loss: 0.5528\n",
      "    Batch 20/104, Loss: 0.5192\n",
      "    Batch 30/104, Loss: 0.4926\n",
      "    Batch 40/104, Loss: 0.4747\n",
      "    Batch 50/104, Loss: 0.4702\n",
      "    Batch 60/104, Loss: 0.4432\n",
      "    Batch 70/104, Loss: 0.4337\n",
      "    Batch 80/104, Loss: 0.4114\n",
      "    Batch 90/104, Loss: 0.4004\n",
      "    Batch 100/104, Loss: 0.3695\n",
      "\n",
      "  訓練損失: 0.4646\n",
      "  驗證損失: 0.3680\n",
      "  驗證 Dice: 0.0298\n",
      "  學習率: 0.009973\n",
      "  ✓ 保存最佳模型 (Dice: 0.0298)\n",
      "\n",
      "Epoch 2/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.3700\n",
      "    Batch 10/104, Loss: 0.3577\n",
      "    Batch 20/104, Loss: 0.3397\n",
      "    Batch 30/104, Loss: 0.3447\n",
      "    Batch 40/104, Loss: 0.3026\n",
      "    Batch 50/104, Loss: 0.2982\n",
      "    Batch 60/104, Loss: 0.2739\n",
      "    Batch 70/104, Loss: 0.2777\n",
      "    Batch 80/104, Loss: 0.2624\n",
      "    Batch 90/104, Loss: 0.2459\n",
      "    Batch 100/104, Loss: 0.2423\n",
      "\n",
      "  訓練損失: 0.2968\n",
      "  驗證損失: 0.2326\n",
      "  驗證 Dice: 0.5295\n",
      "  學習率: 0.009891\n",
      "  ✓ 保存最佳模型 (Dice: 0.5295)\n",
      "\n",
      "Epoch 3/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2316\n",
      "    Batch 10/104, Loss: 0.2167\n",
      "    Batch 20/104, Loss: 0.2134\n",
      "    Batch 30/104, Loss: 0.1640\n",
      "    Batch 40/104, Loss: 0.1266\n",
      "    Batch 50/104, Loss: 0.1207\n",
      "    Batch 60/104, Loss: 0.1205\n",
      "    Batch 70/104, Loss: 0.1110\n",
      "    Batch 80/104, Loss: 0.1016\n",
      "    Batch 90/104, Loss: 0.1049\n",
      "    Batch 100/104, Loss: 0.0846\n",
      "\n",
      "  訓練損失: 0.1438\n",
      "  驗證損失: 0.0982\n",
      "  驗證 Dice: 0.8400\n",
      "  學習率: 0.009756\n",
      "  ✓ 保存最佳模型 (Dice: 0.8400)\n",
      "\n",
      "Epoch 4/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1001\n",
      "    Batch 10/104, Loss: 0.0889\n",
      "    Batch 20/104, Loss: 0.1027\n",
      "    Batch 30/104, Loss: 0.1054\n",
      "    Batch 40/104, Loss: 0.0920\n",
      "    Batch 50/104, Loss: 0.0986\n",
      "    Batch 60/104, Loss: 0.0916\n",
      "    Batch 70/104, Loss: 0.0857\n",
      "    Batch 80/104, Loss: 0.0809\n",
      "    Batch 90/104, Loss: 0.0928\n",
      "    Batch 100/104, Loss: 0.1099\n",
      "\n",
      "  訓練損失: 0.0912\n",
      "  驗證損失: 0.0880\n",
      "  驗證 Dice: 0.8475\n",
      "  學習率: 0.009568\n",
      "  ✓ 保存最佳模型 (Dice: 0.8475)\n",
      "\n",
      "Epoch 5/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0744\n",
      "    Batch 10/104, Loss: 0.0809\n",
      "    Batch 20/104, Loss: 0.0780\n",
      "    Batch 30/104, Loss: 0.0777\n",
      "    Batch 40/104, Loss: 0.0817\n",
      "    Batch 50/104, Loss: 0.0834\n",
      "    Batch 60/104, Loss: 0.0762\n",
      "    Batch 70/104, Loss: 0.0729\n",
      "    Batch 80/104, Loss: 0.0729\n",
      "    Batch 90/104, Loss: 0.0869\n",
      "    Batch 100/104, Loss: 0.0868\n",
      "\n",
      "  訓練損失: 0.0830\n",
      "  驗證損失: 0.0842\n",
      "  驗證 Dice: 0.8532\n",
      "  學習率: 0.009331\n",
      "  ✓ 保存最佳模型 (Dice: 0.8532)\n",
      "\n",
      "Epoch 6/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0666\n",
      "    Batch 10/104, Loss: 0.0669\n",
      "    Batch 20/104, Loss: 0.0872\n",
      "    Batch 30/104, Loss: 0.0969\n",
      "    Batch 40/104, Loss: 0.0750\n",
      "    Batch 50/104, Loss: 0.1094\n",
      "    Batch 60/104, Loss: 0.0908\n",
      "    Batch 70/104, Loss: 0.0876\n",
      "    Batch 80/104, Loss: 0.0626\n",
      "    Batch 90/104, Loss: 0.0664\n",
      "    Batch 100/104, Loss: 0.0846\n",
      "\n",
      "  訓練損失: 0.0800\n",
      "  驗證損失: 0.0817\n",
      "  驗證 Dice: 0.8547\n",
      "  學習率: 0.009046\n",
      "  ✓ 保存最佳模型 (Dice: 0.8547)\n",
      "\n",
      "Epoch 7/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0619\n",
      "    Batch 10/104, Loss: 0.0647\n",
      "    Batch 20/104, Loss: 0.0826\n",
      "    Batch 30/104, Loss: 0.1051\n",
      "    Batch 40/104, Loss: 0.0647\n",
      "    Batch 50/104, Loss: 0.0729\n",
      "    Batch 60/104, Loss: 0.0734\n",
      "    Batch 70/104, Loss: 0.0765\n",
      "    Batch 80/104, Loss: 0.0770\n",
      "    Batch 90/104, Loss: 0.0629\n",
      "    Batch 100/104, Loss: 0.0861\n",
      "\n",
      "  訓練損失: 0.0777\n",
      "  驗證損失: 0.0815\n",
      "  驗證 Dice: 0.8580\n",
      "  學習率: 0.008717\n",
      "  ✓ 保存最佳模型 (Dice: 0.8580)\n",
      "\n",
      "Epoch 8/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0612\n",
      "    Batch 10/104, Loss: 0.0807\n",
      "    Batch 20/104, Loss: 0.0680\n",
      "    Batch 30/104, Loss: 0.0834\n",
      "    Batch 40/104, Loss: 0.0864\n",
      "    Batch 50/104, Loss: 0.0680\n",
      "    Batch 60/104, Loss: 0.0863\n",
      "    Batch 70/104, Loss: 0.0923\n",
      "    Batch 80/104, Loss: 0.0693\n",
      "    Batch 90/104, Loss: 0.0831\n",
      "    Batch 100/104, Loss: 0.0760\n",
      "\n",
      "  訓練損失: 0.0758\n",
      "  驗證損失: 0.0801\n",
      "  驗證 Dice: 0.8579\n",
      "  學習率: 0.008347\n",
      "\n",
      "Epoch 9/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0801\n",
      "    Batch 10/104, Loss: 0.0758\n",
      "    Batch 20/104, Loss: 0.0810\n",
      "    Batch 30/104, Loss: 0.0854\n",
      "    Batch 40/104, Loss: 0.0678\n",
      "    Batch 50/104, Loss: 0.0924\n",
      "    Batch 60/104, Loss: 0.0690\n",
      "    Batch 70/104, Loss: 0.0764\n",
      "    Batch 80/104, Loss: 0.0774\n",
      "    Batch 90/104, Loss: 0.0687\n",
      "    Batch 100/104, Loss: 0.0902\n",
      "\n",
      "  訓練損失: 0.0740\n",
      "  驗證損失: 0.0788\n",
      "  驗證 Dice: 0.8605\n",
      "  學習率: 0.007941\n",
      "  ✓ 保存最佳模型 (Dice: 0.8605)\n",
      "\n",
      "Epoch 10/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0679\n",
      "    Batch 10/104, Loss: 0.0587\n",
      "    Batch 20/104, Loss: 0.0869\n",
      "    Batch 30/104, Loss: 0.0621\n",
      "    Batch 40/104, Loss: 0.0614\n",
      "    Batch 50/104, Loss: 0.0771\n",
      "    Batch 60/104, Loss: 0.0845\n",
      "    Batch 70/104, Loss: 0.0679\n",
      "    Batch 80/104, Loss: 0.0867\n",
      "    Batch 90/104, Loss: 0.0691\n",
      "    Batch 100/104, Loss: 0.0701\n",
      "\n",
      "  訓練損失: 0.0724\n",
      "  驗證損失: 0.0772\n",
      "  驗證 Dice: 0.8647\n",
      "  學習率: 0.007503\n",
      "  ✓ 保存最佳模型 (Dice: 0.8647)\n",
      "\n",
      "Epoch 11/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0745\n",
      "    Batch 10/104, Loss: 0.0824\n",
      "    Batch 20/104, Loss: 0.0683\n",
      "    Batch 30/104, Loss: 0.0803\n",
      "    Batch 40/104, Loss: 0.0765\n",
      "    Batch 50/104, Loss: 0.0776\n",
      "    Batch 60/104, Loss: 0.0655\n",
      "    Batch 70/104, Loss: 0.0680\n",
      "    Batch 80/104, Loss: 0.0784\n",
      "    Batch 90/104, Loss: 0.0765\n",
      "    Batch 100/104, Loss: 0.0757\n",
      "\n",
      "  訓練損失: 0.0715\n",
      "  驗證損失: 0.0775\n",
      "  驗證 Dice: 0.8641\n",
      "  學習率: 0.007037\n",
      "\n",
      "Epoch 12/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0682\n",
      "    Batch 10/104, Loss: 0.0868\n",
      "    Batch 20/104, Loss: 0.0730\n",
      "    Batch 30/104, Loss: 0.0771\n",
      "    Batch 40/104, Loss: 0.0608\n",
      "    Batch 50/104, Loss: 0.0650\n",
      "    Batch 60/104, Loss: 0.0761\n",
      "    Batch 70/104, Loss: 0.0828\n",
      "    Batch 80/104, Loss: 0.0560\n",
      "    Batch 90/104, Loss: 0.0761\n",
      "    Batch 100/104, Loss: 0.0721\n",
      "\n",
      "  訓練損失: 0.0698\n",
      "  驗證損失: 0.0762\n",
      "  驗證 Dice: 0.8662\n",
      "  學習率: 0.006549\n",
      "  ✓ 保存最佳模型 (Dice: 0.8662)\n",
      "\n",
      "Epoch 13/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0617\n",
      "    Batch 10/104, Loss: 0.0681\n",
      "    Batch 20/104, Loss: 0.0680\n",
      "    Batch 30/104, Loss: 0.0744\n",
      "    Batch 40/104, Loss: 0.0865\n",
      "    Batch 50/104, Loss: 0.0696\n",
      "    Batch 60/104, Loss: 0.0585\n",
      "    Batch 70/104, Loss: 0.0688\n",
      "    Batch 80/104, Loss: 0.0776\n",
      "    Batch 90/104, Loss: 0.0665\n",
      "    Batch 100/104, Loss: 0.0782\n",
      "\n",
      "  訓練損失: 0.0688\n",
      "  驗證損失: 0.0756\n",
      "  驗證 Dice: 0.8666\n",
      "  學習率: 0.006044\n",
      "  ✓ 保存最佳模型 (Dice: 0.8666)\n",
      "\n",
      "Epoch 14/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0617\n",
      "    Batch 10/104, Loss: 0.0643\n",
      "    Batch 20/104, Loss: 0.0833\n",
      "    Batch 30/104, Loss: 0.0656\n",
      "    Batch 40/104, Loss: 0.0717\n",
      "    Batch 50/104, Loss: 0.0711\n",
      "    Batch 60/104, Loss: 0.0675\n",
      "    Batch 70/104, Loss: 0.0670\n",
      "    Batch 80/104, Loss: 0.0647\n",
      "    Batch 90/104, Loss: 0.0756\n",
      "    Batch 100/104, Loss: 0.0910\n",
      "\n",
      "  訓練損失: 0.0673\n",
      "  驗證損失: 0.0764\n",
      "  驗證 Dice: 0.8658\n",
      "  學習率: 0.005527\n",
      "\n",
      "Epoch 15/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0791\n",
      "    Batch 10/104, Loss: 0.0700\n",
      "    Batch 20/104, Loss: 0.0617\n",
      "    Batch 30/104, Loss: 0.0699\n",
      "    Batch 40/104, Loss: 0.0547\n",
      "    Batch 50/104, Loss: 0.0570\n",
      "    Batch 60/104, Loss: 0.0836\n",
      "    Batch 70/104, Loss: 0.0904\n",
      "    Batch 80/104, Loss: 0.0848\n",
      "    Batch 90/104, Loss: 0.0695\n",
      "    Batch 100/104, Loss: 0.0605\n",
      "\n",
      "  訓練損失: 0.0659\n",
      "  驗證損失: 0.0775\n",
      "  驗證 Dice: 0.8624\n",
      "  學習率: 0.005005\n",
      "\n",
      "Epoch 16/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0538\n",
      "    Batch 10/104, Loss: 0.0634\n",
      "    Batch 20/104, Loss: 0.0639\n",
      "    Batch 30/104, Loss: 0.0755\n",
      "    Batch 40/104, Loss: 0.0797\n",
      "    Batch 50/104, Loss: 0.0739\n",
      "    Batch 60/104, Loss: 0.0546\n",
      "    Batch 70/104, Loss: 0.0516\n",
      "    Batch 80/104, Loss: 0.0575\n",
      "    Batch 90/104, Loss: 0.0638\n",
      "    Batch 100/104, Loss: 0.0612\n",
      "\n",
      "  訓練損失: 0.0647\n",
      "  驗證損失: 0.0754\n",
      "  驗證 Dice: 0.8671\n",
      "  學習率: 0.004483\n",
      "  ✓ 保存最佳模型 (Dice: 0.8671)\n",
      "\n",
      "Epoch 17/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0582\n",
      "    Batch 10/104, Loss: 0.0547\n",
      "    Batch 20/104, Loss: 0.0647\n",
      "    Batch 30/104, Loss: 0.0578\n",
      "    Batch 40/104, Loss: 0.0663\n",
      "    Batch 50/104, Loss: 0.0521\n",
      "    Batch 60/104, Loss: 0.0525\n",
      "    Batch 70/104, Loss: 0.0692\n",
      "    Batch 80/104, Loss: 0.0657\n",
      "    Batch 90/104, Loss: 0.0683\n",
      "    Batch 100/104, Loss: 0.0747\n",
      "\n",
      "  訓練損失: 0.0635\n",
      "  驗證損失: 0.0761\n",
      "  驗證 Dice: 0.8665\n",
      "  學習率: 0.003966\n",
      "\n",
      "Epoch 18/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0513\n",
      "    Batch 10/104, Loss: 0.0613\n",
      "    Batch 20/104, Loss: 0.0765\n",
      "    Batch 30/104, Loss: 0.0634\n",
      "    Batch 40/104, Loss: 0.0514\n",
      "    Batch 50/104, Loss: 0.0484\n",
      "    Batch 60/104, Loss: 0.0530\n",
      "    Batch 70/104, Loss: 0.0512\n",
      "    Batch 80/104, Loss: 0.0613\n",
      "    Batch 90/104, Loss: 0.0711\n",
      "    Batch 100/104, Loss: 0.0569\n",
      "\n",
      "  訓練損失: 0.0621\n",
      "  驗證損失: 0.0765\n",
      "  驗證 Dice: 0.8660\n",
      "  學習率: 0.003461\n",
      "\n",
      "Epoch 19/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0606\n",
      "    Batch 10/104, Loss: 0.0572\n",
      "    Batch 20/104, Loss: 0.0615\n",
      "    Batch 30/104, Loss: 0.0499\n",
      "    Batch 40/104, Loss: 0.0534\n",
      "    Batch 50/104, Loss: 0.0783\n",
      "    Batch 60/104, Loss: 0.0496\n",
      "    Batch 70/104, Loss: 0.0502\n",
      "    Batch 80/104, Loss: 0.0472\n",
      "    Batch 90/104, Loss: 0.0591\n",
      "    Batch 100/104, Loss: 0.0732\n",
      "\n",
      "  訓練損失: 0.0607\n",
      "  驗證損失: 0.0766\n",
      "  驗證 Dice: 0.8660\n",
      "  學習率: 0.002973\n",
      "\n",
      "Epoch 20/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0546\n",
      "    Batch 10/104, Loss: 0.0581\n",
      "    Batch 20/104, Loss: 0.0540\n",
      "    Batch 30/104, Loss: 0.0624\n",
      "    Batch 40/104, Loss: 0.0742\n",
      "    Batch 50/104, Loss: 0.0568\n",
      "    Batch 60/104, Loss: 0.0529\n",
      "    Batch 70/104, Loss: 0.0567\n",
      "    Batch 80/104, Loss: 0.0617\n",
      "    Batch 90/104, Loss: 0.0492\n",
      "    Batch 100/104, Loss: 0.0730\n",
      "\n",
      "  訓練損失: 0.0596\n",
      "  驗證損失: 0.0761\n",
      "  驗證 Dice: 0.8657\n",
      "  學習率: 0.002508\n",
      "\n",
      "Epoch 21/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0466\n",
      "    Batch 10/104, Loss: 0.0568\n",
      "    Batch 20/104, Loss: 0.0546\n",
      "    Batch 30/104, Loss: 0.0648\n",
      "    Batch 40/104, Loss: 0.0680\n",
      "    Batch 50/104, Loss: 0.0596\n",
      "    Batch 60/104, Loss: 0.0671\n",
      "    Batch 70/104, Loss: 0.0554\n",
      "    Batch 80/104, Loss: 0.0502\n",
      "    Batch 90/104, Loss: 0.0590\n",
      "    Batch 100/104, Loss: 0.0772\n",
      "\n",
      "  訓練損失: 0.0582\n",
      "  驗證損失: 0.0764\n",
      "  驗證 Dice: 0.8658\n",
      "  學習率: 0.002069\n",
      "\n",
      "Epoch 22/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0629\n",
      "    Batch 10/104, Loss: 0.0446\n",
      "    Batch 20/104, Loss: 0.0461\n",
      "    Batch 30/104, Loss: 0.0560\n",
      "    Batch 40/104, Loss: 0.0464\n",
      "    Batch 50/104, Loss: 0.0757\n",
      "    Batch 60/104, Loss: 0.0472\n",
      "    Batch 70/104, Loss: 0.0468\n",
      "    Batch 80/104, Loss: 0.0504\n",
      "    Batch 90/104, Loss: 0.0545\n",
      "    Batch 100/104, Loss: 0.0507\n",
      "\n",
      "  訓練損失: 0.0573\n",
      "  驗證損失: 0.0768\n",
      "  驗證 Dice: 0.8655\n",
      "  學習率: 0.001663\n",
      "\n",
      "Epoch 23/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0474\n",
      "    Batch 10/104, Loss: 0.0564\n",
      "    Batch 20/104, Loss: 0.0471\n",
      "    Batch 30/104, Loss: 0.0443\n",
      "    Batch 40/104, Loss: 0.0502\n",
      "    Batch 50/104, Loss: 0.0549\n",
      "    Batch 60/104, Loss: 0.0654\n",
      "    Batch 70/104, Loss: 0.0475\n",
      "    Batch 80/104, Loss: 0.0500\n",
      "    Batch 90/104, Loss: 0.0550\n",
      "    Batch 100/104, Loss: 0.0468\n",
      "\n",
      "  訓練損失: 0.0564\n",
      "  驗證損失: 0.0762\n",
      "  驗證 Dice: 0.8657\n",
      "  學習率: 0.001293\n",
      "\n",
      "Epoch 24/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0577\n",
      "    Batch 10/104, Loss: 0.0537\n",
      "    Batch 20/104, Loss: 0.0483\n",
      "    Batch 30/104, Loss: 0.0594\n",
      "    Batch 40/104, Loss: 0.0577\n",
      "    Batch 50/104, Loss: 0.0475\n",
      "    Batch 60/104, Loss: 0.0496\n",
      "    Batch 70/104, Loss: 0.0545\n",
      "    Batch 80/104, Loss: 0.0656\n",
      "    Batch 90/104, Loss: 0.0532\n",
      "    Batch 100/104, Loss: 0.0781\n",
      "\n",
      "  訓練損失: 0.0556\n",
      "  驗證損失: 0.0772\n",
      "  驗證 Dice: 0.8640\n",
      "  學習率: 0.000964\n",
      "\n",
      "Epoch 25/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0560\n",
      "    Batch 10/104, Loss: 0.0454\n",
      "    Batch 20/104, Loss: 0.0569\n",
      "    Batch 30/104, Loss: 0.0601\n",
      "    Batch 40/104, Loss: 0.0522\n",
      "    Batch 50/104, Loss: 0.0560\n",
      "    Batch 60/104, Loss: 0.0498\n",
      "    Batch 70/104, Loss: 0.0626\n",
      "    Batch 80/104, Loss: 0.0545\n",
      "    Batch 90/104, Loss: 0.0556\n",
      "    Batch 100/104, Loss: 0.0642\n",
      "\n",
      "  訓練損失: 0.0550\n",
      "  驗證損失: 0.0771\n",
      "  驗證 Dice: 0.8646\n",
      "  學習率: 0.000679\n",
      "\n",
      "Epoch 26/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0524\n",
      "    Batch 10/104, Loss: 0.0538\n",
      "    Batch 20/104, Loss: 0.0441\n",
      "    Batch 30/104, Loss: 0.0577\n",
      "    Batch 40/104, Loss: 0.0481\n",
      "    Batch 50/104, Loss: 0.0510\n",
      "    Batch 60/104, Loss: 0.0435\n",
      "    Batch 70/104, Loss: 0.0550\n",
      "    Batch 80/104, Loss: 0.0457\n",
      "    Batch 90/104, Loss: 0.0562\n",
      "    Batch 100/104, Loss: 0.0513\n",
      "\n",
      "  訓練損失: 0.0544\n",
      "  驗證損失: 0.0776\n",
      "  驗證 Dice: 0.8643\n",
      "  學習率: 0.000442\n",
      "\n",
      "Epoch 27/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0493\n",
      "    Batch 10/104, Loss: 0.0523\n",
      "    Batch 20/104, Loss: 0.0497\n",
      "    Batch 30/104, Loss: 0.0425\n",
      "    Batch 40/104, Loss: 0.0552\n",
      "    Batch 50/104, Loss: 0.0490\n",
      "    Batch 60/104, Loss: 0.0649\n",
      "    Batch 70/104, Loss: 0.0485\n",
      "    Batch 80/104, Loss: 0.0615\n",
      "    Batch 90/104, Loss: 0.0453\n",
      "    Batch 100/104, Loss: 0.0583\n",
      "\n",
      "  訓練損失: 0.0541\n",
      "  驗證損失: 0.0772\n",
      "  驗證 Dice: 0.8645\n",
      "  學習率: 0.000254\n",
      "\n",
      "Epoch 28/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0470\n",
      "    Batch 10/104, Loss: 0.0492\n",
      "    Batch 20/104, Loss: 0.0617\n",
      "    Batch 30/104, Loss: 0.0660\n",
      "    Batch 40/104, Loss: 0.0486\n",
      "    Batch 50/104, Loss: 0.0562\n",
      "    Batch 60/104, Loss: 0.0578\n",
      "    Batch 70/104, Loss: 0.0432\n",
      "    Batch 80/104, Loss: 0.0559\n",
      "    Batch 90/104, Loss: 0.0433\n",
      "    Batch 100/104, Loss: 0.0547\n",
      "\n",
      "  訓練損失: 0.0538\n",
      "  驗證損失: 0.0771\n",
      "  驗證 Dice: 0.8642\n",
      "  學習率: 0.000119\n",
      "\n",
      "Epoch 29/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0536\n",
      "    Batch 10/104, Loss: 0.0495\n",
      "    Batch 20/104, Loss: 0.0598\n",
      "    Batch 30/104, Loss: 0.0554\n",
      "    Batch 40/104, Loss: 0.0504\n",
      "    Batch 50/104, Loss: 0.0497\n",
      "    Batch 60/104, Loss: 0.0508\n",
      "    Batch 70/104, Loss: 0.0516\n",
      "    Batch 80/104, Loss: 0.0526\n",
      "    Batch 90/104, Loss: 0.0462\n",
      "    Batch 100/104, Loss: 0.0506\n",
      "\n",
      "  訓練損失: 0.0536\n",
      "  驗證損失: 0.0773\n",
      "  驗證 Dice: 0.8645\n",
      "  學習率: 0.000037\n",
      "\n",
      "Epoch 30/30\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.0488\n",
      "    Batch 10/104, Loss: 0.0703\n",
      "    Batch 20/104, Loss: 0.0502\n",
      "    Batch 30/104, Loss: 0.0541\n",
      "    Batch 40/104, Loss: 0.0576\n",
      "    Batch 50/104, Loss: 0.0565\n",
      "    Batch 60/104, Loss: 0.0454\n",
      "    Batch 70/104, Loss: 0.0517\n",
      "    Batch 80/104, Loss: 0.0520\n",
      "    Batch 90/104, Loss: 0.0553\n",
      "    Batch 100/104, Loss: 0.0450\n",
      "\n",
      "  訓練損失: 0.0535\n",
      "  驗證損失: 0.0774\n",
      "  驗證 Dice: 0.8644\n",
      "  學習率: 0.000010\n",
      "\n",
      "================================================================================\n",
      "✓ 訓練完成! 最佳 Dice: 0.8671\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "🧠 醫學影像分割訓練系統 - 生產級版本\n",
    "精準短路 torch._compile/onnx、trilinear 插值、完全可重現、Cosine LR\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🧠 醫學影像分割訓練系統 - 生產級\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ==================== 精準短路：避免載入 transformers ====================\n",
    "print(\"\\n🔧 設置環境...\")\n",
    "\n",
    "# 創建 stub 模組來短路導入鏈\n",
    "class _StubModule:\n",
    "    \"\"\"Stub 模組，阻止實際載入但不破壞導入鏈\"\"\"\n",
    "    def __getattr__(self, name):\n",
    "        return _StubModule()\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return _StubModule()\n",
    "\n",
    "# 短路 torch._compile 和 torch.onnx，避免觸發 transformers\n",
    "sys.modules['torch._compile'] = _StubModule()\n",
    "sys.modules['torch.onnx'] = _StubModule()\n",
    "print(\"  ✓ 已短路 torch._compile 和 torch.onnx\")\n",
    "\n",
    "# ==================== 導入套件 ====================\n",
    "\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(f\"\\n✓ PyTorch {torch.__version__}\")\n",
    "print(f\"✓ CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(\"✓ cuDNN benchmark enabled\")\n",
    "\n",
    "# ==================== 完全可重現設置 ====================\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"設置所有隨機種子以確保可重現\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # 為了完全可重現（會稍微降低性能）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==================== 資料集（優化插值）====================\n",
    "\n",
    "class HippocampusDataset(Dataset):\n",
    "    def __init__(self, data_root, indices, target_size=64):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        with open(self.data_root / 'dataset.json', 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        training_data = metadata['training']\n",
    "        self.cases = [training_data[i] for i in indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        case = self.cases[idx]\n",
    "        img_path = self.data_root / case['image'].lstrip('./')\n",
    "        lbl_path = self.data_root / case['label'].lstrip('./')\n",
    "        \n",
    "        # 載入影像 - float32\n",
    "        image = nib.load(str(img_path)).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        # Z-score 正規化\n",
    "        p1, p99 = np.percentile(image, [1, 99])\n",
    "        image = np.clip(image, p1, p99)\n",
    "        mean, std = image.mean(), image.std()\n",
    "        if std > 1e-8:\n",
    "            image = (image - mean) / std\n",
    "        \n",
    "        # 載入標註 - float32\n",
    "        label = nib.load(str(lbl_path)).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        # 轉為 torch tensor（添加 batch 和 channel 維度）\n",
    "        image_t = torch.from_numpy(image).unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]\n",
    "        label_t = torch.from_numpy(label).unsqueeze(0).unsqueeze(0)  # [1, 1, D, H, W]\n",
    "        \n",
    "        # 使用 PyTorch 的 F.interpolate\n",
    "        # 影像：trilinear（更平滑）\n",
    "        image_resized = F.interpolate(\n",
    "            image_t,\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='trilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)  # [1, D, H, W]\n",
    "        \n",
    "        # 標註：nearest（保持整數值）\n",
    "        label_resized = F.interpolate(\n",
    "            label_t,\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='nearest'\n",
    "        ).squeeze(0).squeeze(0)  # [D, H, W]\n",
    "        \n",
    "        # 清洗標註\n",
    "        label_resized = torch.clamp(label_resized.long(), 0, 2)\n",
    "        \n",
    "        return image_resized, label_resized\n",
    "\n",
    "def get_train_val_split(num_samples, train_ratio=0.8, seed=42):\n",
    "    \"\"\"固定隨機種子的資料切分\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split_idx = int(num_samples * train_ratio)\n",
    "    return indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# ==================== 模型 ====================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_groups=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1)\n",
    "        self.gn1 = nn.GroupNorm(min(num_groups, out_ch), out_ch)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1)\n",
    "        self.gn2 = nn.GroupNorm(min(num_groups, out_ch), out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.gn1(self.conv1(x)))\n",
    "        x = self.relu(self.gn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=3, base=16):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_ch, base)\n",
    "        self.enc2 = ConvBlock(base, base * 2)\n",
    "        self.enc3 = ConvBlock(base * 2, base * 4)\n",
    "        self.bottleneck = ConvBlock(base * 4, base * 8)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose3d(base * 8, base * 4, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(base * 8, base * 4)\n",
    "        self.up2 = nn.ConvTranspose3d(base * 4, base * 2, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(base * 4, base * 2)\n",
    "        self.up1 = nn.ConvTranspose3d(base * 2, base, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(base * 2, base)\n",
    "        \n",
    "        self.out = nn.Conv3d(base, num_classes, 1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        \n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        \n",
    "        return self.out(d1)\n",
    "\n",
    "# ==================== 損失函數 ====================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        if alpha is not None:\n",
    "            self.register_buffer('alpha', alpha)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[target]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        target_one_hot = F.one_hot(target, pred.shape[1]).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        inter = (pred * target_one_hot).sum(dim=(2, 3, 4))\n",
    "        union = pred.sum(dim=(2, 3, 4)) + target_one_hot.sum(dim=(2, 3, 4))\n",
    "        dice = (2. * inter + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, device, use_focal=True):\n",
    "        super().__init__()\n",
    "        if use_focal:\n",
    "            alpha = torch.tensor([0.2, 1.0, 1.0], device=device)\n",
    "            self.ce = FocalLoss(alpha=alpha, gamma=2.0)\n",
    "        else:\n",
    "            weight = torch.tensor([0.2, 1.0, 1.0], device=device)\n",
    "            self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "        \n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        return 0.3 * self.ce(pred, target) + 0.7 * self.dice(pred, target)\n",
    "\n",
    "# ==================== Cosine Annealing 學習率 ====================\n",
    "\n",
    "class CosineAnnealingLR:\n",
    "    \"\"\"手動實現 Cosine Annealing LR Scheduler\"\"\"\n",
    "    def __init__(self, optimizer, T_max, eta_min=0):\n",
    "        self.optimizer = optimizer\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.base_lr = optimizer.param_groups[0]['lr']\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"更新學習率\"\"\"\n",
    "        self.current_epoch += 1\n",
    "        lr = self.eta_min + (self.base_lr - self.eta_min) * \\\n",
    "             (1 + math.cos(math.pi * self.current_epoch / self.T_max)) / 2\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    def get_lr(self):\n",
    "        \"\"\"獲取當前學習率\"\"\"\n",
    "        return self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "# ==================== 訓練器 ====================\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device, output_dir, num_epochs):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 使用 SGD with momentum\n",
    "        self.optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=1e-2,\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            nesterov=True\n",
    "        )\n",
    "        \n",
    "        # Cosine Annealing LR\n",
    "        self.scheduler = CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=num_epochs,\n",
    "            eta_min=1e-5\n",
    "        )\n",
    "        \n",
    "        self.criterion = CombinedLoss(device=device, use_focal=True)\n",
    "        self.history = {'train_loss': [], 'val_loss': [], 'val_dice': [], 'lr': []}\n",
    "        self.best_dice = 0.0\n",
    "        \n",
    "        print(f\"  使用 SGD + Nesterov momentum\")\n",
    "        print(f\"  使用 Cosine Annealing LR (T_max={num_epochs})\")\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"    Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def validate(self):\n",
    "        \"\"\"累積式 Dice 計算\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        total_inter = {1: 0.0, 2: 0.0}\n",
    "        total_union = {1: 0.0, 2: 0.0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                for cls in [1, 2]:\n",
    "                    pred_mask = (preds == cls).float()\n",
    "                    target_mask = (labels == cls).float()\n",
    "                    total_inter[cls] += (pred_mask * target_mask).sum().item()\n",
    "                    total_union[cls] += (pred_mask.sum() + target_mask.sum()).item()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        dice_scores = []\n",
    "        for cls in [1, 2]:\n",
    "            dice = (2.0 * total_inter[cls]) / (total_union[cls] + 1e-8)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        return total_loss / len(self.val_loader), np.mean(dice_scores)\n",
    "    \n",
    "    def train(self, num_epochs):\n",
    "        print(f\"\\n開始訓練 {num_epochs} epochs\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_dice = self.validate()\n",
    "            \n",
    "            # 更新學習率\n",
    "            self.scheduler.step()\n",
    "            current_lr = self.scheduler.get_lr()\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_dice'].append(val_dice)\n",
    "            self.history['lr'].append(current_lr)\n",
    "            \n",
    "            print(f\"\\n  訓練損失: {train_loss:.4f}\")\n",
    "            print(f\"  驗證損失: {val_loss:.4f}\")\n",
    "            print(f\"  驗證 Dice: {val_dice:.4f}\")\n",
    "            print(f\"  學習率: {current_lr:.6f}\")\n",
    "            \n",
    "            if val_dice > self.best_dice:\n",
    "                self.best_dice = val_dice\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'dice': val_dice,\n",
    "                    'history': self.history\n",
    "                }, self.output_dir / 'best_model.pth')\n",
    "                print(f\"  ✓ 保存最佳模型 (Dice: {val_dice:.4f})\")\n",
    "        \n",
    "        with open(self.output_dir / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"✓ 訓練完成! 最佳 Dice: {self.best_dice:.4f}\")\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "\n",
    "def main():\n",
    "    # 設置隨機種子（確保可重現）\n",
    "    SEED = 42\n",
    "    set_seed(SEED)\n",
    "    print(f\"\\n🎲 設置隨機種子: {SEED}\")\n",
    "    \n",
    "    DATA_ROOT = '/workspace/Task04_Hippocampus'\n",
    "    OUTPUT_DIR = '/workspace/outputs/training_production'\n",
    "    BATCH_SIZE = 2\n",
    "    NUM_EPOCHS = 30  # SGD 需要更多 epochs 才能達到好的收斂\n",
    "    TARGET_SIZE = 64\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用設備: {device}\")\n",
    "    \n",
    "    print(\"\\n準備資料...\")\n",
    "    with open(Path(DATA_ROOT) / 'dataset.json') as f:\n",
    "        num_samples = len(json.load(f)['training'])\n",
    "    \n",
    "    train_indices, val_indices = get_train_val_split(num_samples, train_ratio=0.8, seed=SEED)\n",
    "    print(f\"  訓練集: {len(train_indices)} 個案例\")\n",
    "    print(f\"  驗證集: {len(val_indices)} 個案例\")\n",
    "    \n",
    "    train_dataset = HippocampusDataset(DATA_ROOT, train_indices, TARGET_SIZE)\n",
    "    val_dataset = HippocampusDataset(DATA_ROOT, val_indices, TARGET_SIZE)\n",
    "    \n",
    "    # DataLoader 配置（可選優化）\n",
    "    use_multiprocessing = torch.cuda.is_available()\n",
    "    num_workers = min(4, os.cpu_count() or 1) if use_multiprocessing else 0\n",
    "    \n",
    "    train_loader_kwargs = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'shuffle': True,\n",
    "        'num_workers': num_workers,\n",
    "    }\n",
    "    if num_workers > 0:\n",
    "        train_loader_kwargs.update({\n",
    "            'pin_memory': True,\n",
    "            'persistent_workers': True,\n",
    "            'prefetch_factor': 2\n",
    "        })\n",
    "    \n",
    "    val_loader_kwargs = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'shuffle': False,\n",
    "        'num_workers': num_workers,\n",
    "    }\n",
    "    if num_workers > 0:\n",
    "        val_loader_kwargs['pin_memory'] = True\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, **train_loader_kwargs)\n",
    "    val_loader = DataLoader(val_dataset, **val_loader_kwargs)\n",
    "    \n",
    "    print(f\"  DataLoader workers: {num_workers}\")\n",
    "    print(f\"  影像插值: trilinear\")\n",
    "    print(f\"  標註插值: nearest\")\n",
    "    \n",
    "    print(\"\\n建立模型...\")\n",
    "    model = UNet3D(1, 3, 16)\n",
    "    print(f\"  參數: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"  使用 GroupNorm (穩定於小 batch)\")\n",
    "    \n",
    "    trainer = Trainer(model, train_loader, val_loader, device, OUTPUT_DIR, NUM_EPOCHS)\n",
    "    trainer.train(NUM_EPOCHS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n訓練中斷\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "010e274c-dc8b-409d-baad-e9318d262059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "提升 Dice 的改進版訓練系統\n",
      "================================================================================\n",
      "\n",
      "PyTorch 2.1.0+cu118\n",
      "CUDA: True\n",
      "\n",
      "設置環境完成\n",
      "  TF32 enabled\n",
      "隨機種子: 42\n",
      "使用設備: cuda\n",
      "\n",
      "準備資料...\n",
      "  訓練集: 208\n",
      "  驗證集: 52\n",
      "\n",
      "建立模型...\n",
      "  參數: 3,152,913\n",
      "  AdamW (lr=0.0005) + Warmup(5) + Cosine\n",
      "  更大模型 (base=24)\n",
      "  更強增強 (noise + blur)\n",
      "  更長訓練 (50 epochs)\n",
      "  Dice 權重: 0.8\n",
      "\n",
      "開始訓練 50 epochs\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 1.7866\n",
      "    Batch 10/104, Loss: 1.6767\n",
      "    Batch 20/104, Loss: 1.5896\n",
      "    Batch 30/104, Loss: 1.4519\n",
      "    Batch 40/104, Loss: 1.2524\n",
      "    Batch 50/104, Loss: 1.1830\n",
      "    Batch 60/104, Loss: 1.1920\n",
      "    Batch 70/104, Loss: 1.1376\n",
      "    Batch 80/104, Loss: 1.1990\n",
      "    Batch 90/104, Loss: 1.1095\n",
      "    Batch 100/104, Loss: 1.1447\n",
      "\n",
      "  訓練損失: 1.3372\n",
      "  驗證損失: 0.7977\n",
      "  驗證 Dice: 0.0584 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0770, IoU: 0.0400\n",
      "    Class 2 - Dice: 0.0399, IoU: 0.0203\n",
      "  學習率: 0.000100\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 2/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 1.0202\n",
      "    Batch 10/104, Loss: 0.9235\n",
      "    Batch 20/104, Loss: 0.8873\n",
      "    Batch 30/104, Loss: 0.9362\n",
      "    Batch 40/104, Loss: 0.8607\n",
      "    Batch 50/104, Loss: 0.8954\n",
      "    Batch 60/104, Loss: 0.8031\n",
      "    Batch 70/104, Loss: 0.7979\n",
      "    Batch 80/104, Loss: 0.7960\n",
      "    Batch 90/104, Loss: 0.8016\n",
      "    Batch 100/104, Loss: 0.8371\n",
      "\n",
      "  訓練損失: 0.8759\n",
      "  驗證損失: 0.7962\n",
      "  驗證 Dice: 0.0587 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0793, IoU: 0.0413\n",
      "    Class 2 - Dice: 0.0382, IoU: 0.0194\n",
      "  學習率: 0.000200\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 3/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.7485\n",
      "    Batch 10/104, Loss: 0.7573\n",
      "    Batch 20/104, Loss: 0.8227\n",
      "    Batch 30/104, Loss: 0.7090\n",
      "    Batch 40/104, Loss: 0.7257\n",
      "    Batch 50/104, Loss: 0.8371\n",
      "    Batch 60/104, Loss: 0.7577\n",
      "    Batch 70/104, Loss: 0.7153\n",
      "    Batch 80/104, Loss: 0.7443\n",
      "    Batch 90/104, Loss: 0.7384\n",
      "    Batch 100/104, Loss: 0.6273\n",
      "\n",
      "  訓練損失: 0.7608\n",
      "  驗證損失: 0.7946\n",
      "  驗證 Dice: 0.0590 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0817, IoU: 0.0426\n",
      "    Class 2 - Dice: 0.0364, IoU: 0.0185\n",
      "  學習率: 0.000300\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 4/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.6731\n",
      "    Batch 10/104, Loss: 0.6977\n",
      "    Batch 20/104, Loss: 0.7056\n",
      "    Batch 30/104, Loss: 0.7820\n",
      "    Batch 40/104, Loss: 0.6758\n",
      "    Batch 50/104, Loss: 0.8133\n",
      "    Batch 60/104, Loss: 0.6095\n",
      "    Batch 70/104, Loss: 0.5929\n",
      "    Batch 80/104, Loss: 0.6542\n",
      "    Batch 90/104, Loss: 0.5933\n",
      "    Batch 100/104, Loss: 0.6879\n",
      "\n",
      "  訓練損失: 0.6546\n",
      "  驗證損失: 0.7930\n",
      "  驗證 Dice: 0.0592 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0838, IoU: 0.0437\n",
      "    Class 2 - Dice: 0.0347, IoU: 0.0177\n",
      "  學習率: 0.000400\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 5/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.5565\n",
      "    Batch 10/104, Loss: 0.6084\n",
      "    Batch 20/104, Loss: 0.6174\n",
      "    Batch 30/104, Loss: 0.5921\n",
      "    Batch 40/104, Loss: 0.5743\n",
      "    Batch 50/104, Loss: 0.5208\n",
      "    Batch 60/104, Loss: 0.5356\n",
      "    Batch 70/104, Loss: 0.5128\n",
      "    Batch 80/104, Loss: 0.5019\n",
      "    Batch 90/104, Loss: 0.5194\n",
      "    Batch 100/104, Loss: 0.4410\n",
      "\n",
      "  訓練損失: 0.5600\n",
      "  驗證損失: 0.7914\n",
      "  驗證 Dice: 0.0599 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0865, IoU: 0.0452\n",
      "    Class 2 - Dice: 0.0333, IoU: 0.0169\n",
      "  學習率: 0.000500\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 6/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.5224\n",
      "    Batch 10/104, Loss: 0.4697\n",
      "    Batch 20/104, Loss: 0.6036\n",
      "    Batch 30/104, Loss: 0.4547\n",
      "    Batch 40/104, Loss: 0.4635\n",
      "    Batch 50/104, Loss: 0.4807\n",
      "    Batch 60/104, Loss: 0.5257\n",
      "    Batch 70/104, Loss: 0.4363\n",
      "    Batch 80/104, Loss: 0.4716\n",
      "    Batch 90/104, Loss: 0.4329\n",
      "    Batch 100/104, Loss: 0.5041\n",
      "\n",
      "  訓練損失: 0.4848\n",
      "  驗證損失: 0.7896\n",
      "  驗證 Dice: 0.0611 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0899, IoU: 0.0471\n",
      "    Class 2 - Dice: 0.0324, IoU: 0.0165\n",
      "  學習率: 0.000499\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 7/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.4934\n",
      "    Batch 10/104, Loss: 0.4246\n",
      "    Batch 20/104, Loss: 0.4884\n",
      "    Batch 30/104, Loss: 0.3733\n",
      "    Batch 40/104, Loss: 0.3949\n",
      "    Batch 50/104, Loss: 0.4314\n",
      "    Batch 60/104, Loss: 0.4212\n",
      "    Batch 70/104, Loss: 0.5153\n",
      "    Batch 80/104, Loss: 0.4134\n",
      "    Batch 90/104, Loss: 0.4264\n",
      "    Batch 100/104, Loss: 0.4164\n",
      "\n",
      "  訓練損失: 0.4498\n",
      "  驗證損失: 0.7877\n",
      "  驗證 Dice: 0.0632 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0937, IoU: 0.0491\n",
      "    Class 2 - Dice: 0.0327, IoU: 0.0166\n",
      "  學習率: 0.000498\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 8/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.4077\n",
      "    Batch 10/104, Loss: 0.3951\n",
      "    Batch 20/104, Loss: 0.4076\n",
      "    Batch 30/104, Loss: 0.4007\n",
      "    Batch 40/104, Loss: 0.4371\n",
      "    Batch 50/104, Loss: 0.4323\n",
      "    Batch 60/104, Loss: 0.3640\n",
      "    Batch 70/104, Loss: 0.4325\n",
      "    Batch 80/104, Loss: 0.3258\n",
      "    Batch 90/104, Loss: 0.6407\n",
      "    Batch 100/104, Loss: 0.4187\n",
      "\n",
      "  訓練損失: 0.4242\n",
      "  驗證損失: 0.7858\n",
      "  驗證 Dice: 0.0659 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.0974, IoU: 0.0512\n",
      "    Class 2 - Dice: 0.0345, IoU: 0.0175\n",
      "  學習率: 0.000495\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 9/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.4313\n",
      "    Batch 10/104, Loss: 0.4341\n",
      "    Batch 20/104, Loss: 0.3675\n",
      "    Batch 30/104, Loss: 0.4182\n",
      "    Batch 40/104, Loss: 0.5088\n",
      "    Batch 50/104, Loss: 0.3924\n",
      "    Batch 60/104, Loss: 0.3765\n",
      "    Batch 70/104, Loss: 0.3548\n",
      "    Batch 80/104, Loss: 0.3686\n",
      "    Batch 90/104, Loss: 0.4675\n",
      "    Batch 100/104, Loss: 0.3769\n",
      "\n",
      "  訓練損失: 0.3982\n",
      "  驗證損失: 0.7838\n",
      "  驗證 Dice: 0.0692 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1008, IoU: 0.0531\n",
      "    Class 2 - Dice: 0.0376, IoU: 0.0191\n",
      "  學習率: 0.000490\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 10/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.3272\n",
      "    Batch 10/104, Loss: 0.3729\n",
      "    Batch 20/104, Loss: 0.3418\n",
      "    Batch 30/104, Loss: 0.3138\n",
      "    Batch 40/104, Loss: 0.3136\n",
      "    Batch 50/104, Loss: 0.4421\n",
      "    Batch 60/104, Loss: 0.3102\n",
      "    Batch 70/104, Loss: 0.4670\n",
      "    Batch 80/104, Loss: 0.4468\n",
      "    Batch 90/104, Loss: 0.3234\n",
      "    Batch 100/104, Loss: 0.3220\n",
      "\n",
      "  訓練損失: 0.3828\n",
      "  驗證損失: 0.7817\n",
      "  驗證 Dice: 0.0719 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1040, IoU: 0.0548\n",
      "    Class 2 - Dice: 0.0398, IoU: 0.0203\n",
      "  學習率: 0.000485\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 11/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2544\n",
      "    Batch 10/104, Loss: 0.3094\n",
      "    Batch 20/104, Loss: 0.2413\n",
      "    Batch 30/104, Loss: 0.2683\n",
      "    Batch 40/104, Loss: 0.2381\n",
      "    Batch 50/104, Loss: 0.2988\n",
      "    Batch 60/104, Loss: 0.3805\n",
      "    Batch 70/104, Loss: 0.2196\n",
      "    Batch 80/104, Loss: 0.2488\n",
      "    Batch 90/104, Loss: 0.2211\n",
      "    Batch 100/104, Loss: 0.2547\n",
      "\n",
      "  訓練損失: 0.2797\n",
      "  驗證損失: 0.7797\n",
      "  驗證 Dice: 0.0729 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1067, IoU: 0.0563\n",
      "    Class 2 - Dice: 0.0391, IoU: 0.0200\n",
      "  學習率: 0.000478\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 12/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2914\n",
      "    Batch 10/104, Loss: 0.2132\n",
      "    Batch 20/104, Loss: 0.2481\n",
      "    Batch 30/104, Loss: 0.2870\n",
      "    Batch 40/104, Loss: 0.3225\n",
      "    Batch 50/104, Loss: 0.3364\n",
      "    Batch 60/104, Loss: 0.2674\n",
      "    Batch 70/104, Loss: 0.2727\n",
      "    Batch 80/104, Loss: 0.2760\n",
      "    Batch 90/104, Loss: 0.2716\n",
      "    Batch 100/104, Loss: 0.2005\n",
      "\n",
      "  訓練損失: 0.2766\n",
      "  驗證損失: 0.7777\n",
      "  驗證 Dice: 0.0724 \n",
      "    Class 1 - Dice: 0.1088, IoU: 0.0575\n",
      "    Class 2 - Dice: 0.0361, IoU: 0.0184\n",
      "  學習率: 0.000471\n",
      "\n",
      "Epoch 13/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2295\n",
      "    Batch 10/104, Loss: 0.2509\n",
      "    Batch 20/104, Loss: 0.2019\n",
      "    Batch 30/104, Loss: 0.2945\n",
      "    Batch 40/104, Loss: 0.2981\n",
      "    Batch 50/104, Loss: 0.2761\n",
      "    Batch 60/104, Loss: 0.2390\n",
      "    Batch 70/104, Loss: 0.2346\n",
      "    Batch 80/104, Loss: 0.2629\n",
      "    Batch 90/104, Loss: 0.2649\n",
      "    Batch 100/104, Loss: 0.2290\n",
      "\n",
      "  訓練損失: 0.2669\n",
      "  驗證損失: 0.7756\n",
      "  驗證 Dice: 0.0711 \n",
      "    Class 1 - Dice: 0.1105, IoU: 0.0585\n",
      "    Class 2 - Dice: 0.0317, IoU: 0.0161\n",
      "  學習率: 0.000462\n",
      "\n",
      "Epoch 14/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.3164\n",
      "    Batch 10/104, Loss: 0.2573\n",
      "    Batch 20/104, Loss: 0.2233\n",
      "    Batch 30/104, Loss: 0.2932\n",
      "    Batch 40/104, Loss: 0.2898\n",
      "    Batch 50/104, Loss: 0.2213\n",
      "    Batch 60/104, Loss: 0.3180\n",
      "    Batch 70/104, Loss: 0.3422\n",
      "    Batch 80/104, Loss: 0.2778\n",
      "    Batch 90/104, Loss: 0.2618\n",
      "    Batch 100/104, Loss: 0.3831\n",
      "\n",
      "  訓練損失: 0.2647\n",
      "  驗證損失: 0.7735\n",
      "  驗證 Dice: 0.0696 \n",
      "    Class 1 - Dice: 0.1123, IoU: 0.0595\n",
      "    Class 2 - Dice: 0.0269, IoU: 0.0136\n",
      "  學習率: 0.000452\n",
      "\n",
      "Epoch 15/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2396\n",
      "    Batch 10/104, Loss: 0.2187\n",
      "    Batch 20/104, Loss: 0.3318\n",
      "    Batch 30/104, Loss: 0.2304\n",
      "    Batch 40/104, Loss: 0.2531\n",
      "    Batch 50/104, Loss: 0.2132\n",
      "    Batch 60/104, Loss: 0.2599\n",
      "    Batch 70/104, Loss: 0.2362\n",
      "    Batch 80/104, Loss: 0.2545\n",
      "    Batch 90/104, Loss: 0.2125\n",
      "    Batch 100/104, Loss: 0.2325\n",
      "\n",
      "  訓練損失: 0.2610\n",
      "  驗證損失: 0.7713\n",
      "  驗證 Dice: 0.0685 \n",
      "    Class 1 - Dice: 0.1143, IoU: 0.0606\n",
      "    Class 2 - Dice: 0.0227, IoU: 0.0115\n",
      "  學習率: 0.000442\n",
      "\n",
      "Epoch 16/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2242\n",
      "    Batch 10/104, Loss: 0.2549\n",
      "    Batch 20/104, Loss: 0.2785\n",
      "    Batch 30/104, Loss: 0.2259\n",
      "    Batch 40/104, Loss: 0.2290\n",
      "    Batch 50/104, Loss: 0.2439\n",
      "    Batch 60/104, Loss: 0.2010\n",
      "    Batch 70/104, Loss: 0.2541\n",
      "    Batch 80/104, Loss: 0.2043\n",
      "    Batch 90/104, Loss: 0.2293\n",
      "    Batch 100/104, Loss: 0.2581\n",
      "\n",
      "  訓練損失: 0.2546\n",
      "  驗證損失: 0.7690\n",
      "  驗證 Dice: 0.0681 \n",
      "    Class 1 - Dice: 0.1168, IoU: 0.0620\n",
      "    Class 2 - Dice: 0.0194, IoU: 0.0098\n",
      "  學習率: 0.000430\n",
      "\n",
      "Epoch 17/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2394\n",
      "    Batch 10/104, Loss: 0.2775\n",
      "    Batch 20/104, Loss: 0.2287\n",
      "    Batch 30/104, Loss: 0.2712\n",
      "    Batch 40/104, Loss: 0.2531\n",
      "    Batch 50/104, Loss: 0.3008\n",
      "    Batch 60/104, Loss: 0.2857\n",
      "    Batch 70/104, Loss: 0.2356\n",
      "    Batch 80/104, Loss: 0.2743\n",
      "    Batch 90/104, Loss: 0.2902\n",
      "    Batch 100/104, Loss: 0.2245\n",
      "\n",
      "  訓練損失: 0.2538\n",
      "  驗證損失: 0.7665\n",
      "  驗證 Dice: 0.0689 \n",
      "    Class 1 - Dice: 0.1201, IoU: 0.0639\n",
      "    Class 2 - Dice: 0.0177, IoU: 0.0089\n",
      "  學習率: 0.000417\n",
      "\n",
      "Epoch 18/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2322\n",
      "    Batch 10/104, Loss: 0.3227\n",
      "    Batch 20/104, Loss: 0.2175\n",
      "    Batch 30/104, Loss: 0.2676\n",
      "    Batch 40/104, Loss: 0.2006\n",
      "    Batch 50/104, Loss: 0.2423\n",
      "    Batch 60/104, Loss: 0.2598\n",
      "    Batch 70/104, Loss: 0.2395\n",
      "    Batch 80/104, Loss: 0.2704\n",
      "    Batch 90/104, Loss: 0.2796\n",
      "    Batch 100/104, Loss: 0.2378\n",
      "\n",
      "  訓練損失: 0.2480\n",
      "  驗證損失: 0.7637\n",
      "  驗證 Dice: 0.0713 \n",
      "    Class 1 - Dice: 0.1245, IoU: 0.0664\n",
      "    Class 2 - Dice: 0.0181, IoU: 0.0091\n",
      "  學習率: 0.000404\n",
      "\n",
      "Epoch 19/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2901\n",
      "    Batch 10/104, Loss: 0.2343\n",
      "    Batch 20/104, Loss: 0.2328\n",
      "    Batch 30/104, Loss: 0.2845\n",
      "    Batch 40/104, Loss: 0.3247\n",
      "    Batch 50/104, Loss: 0.2026\n",
      "    Batch 60/104, Loss: 0.2370\n",
      "    Batch 70/104, Loss: 0.2112\n",
      "    Batch 80/104, Loss: 0.1974\n",
      "    Batch 90/104, Loss: 0.2405\n",
      "    Batch 100/104, Loss: 0.2947\n",
      "\n",
      "  訓練損失: 0.2453\n",
      "  驗證損失: 0.7603\n",
      "  驗證 Dice: 0.0752 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1303, IoU: 0.0697\n",
      "    Class 2 - Dice: 0.0201, IoU: 0.0102\n",
      "  學習率: 0.000390\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 20/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2877\n",
      "    Batch 10/104, Loss: 0.2862\n",
      "    Batch 20/104, Loss: 0.3119\n",
      "    Batch 30/104, Loss: 0.2196\n",
      "    Batch 40/104, Loss: 0.2615\n",
      "    Batch 50/104, Loss: 0.2973\n",
      "    Batch 60/104, Loss: 0.2301\n",
      "    Batch 70/104, Loss: 0.2136\n",
      "    Batch 80/104, Loss: 0.2626\n",
      "    Batch 90/104, Loss: 0.2357\n",
      "    Batch 100/104, Loss: 0.2185\n",
      "\n",
      "  訓練損失: 0.2449\n",
      "  驗證損失: 0.7564\n",
      "  驗證 Dice: 0.0822 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1381, IoU: 0.0742\n",
      "    Class 2 - Dice: 0.0263, IoU: 0.0133\n",
      "  學習率: 0.000375\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 21/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2212\n",
      "    Batch 10/104, Loss: 0.2526\n",
      "    Batch 20/104, Loss: 0.2059\n",
      "    Batch 30/104, Loss: 0.3114\n",
      "    Batch 40/104, Loss: 0.2749\n",
      "    Batch 50/104, Loss: 0.2167\n",
      "    Batch 60/104, Loss: 0.2415\n",
      "    Batch 70/104, Loss: 0.2892\n",
      "    Batch 80/104, Loss: 0.3211\n",
      "    Batch 90/104, Loss: 0.2130\n",
      "    Batch 100/104, Loss: 0.2421\n",
      "\n",
      "  訓練損失: 0.2390\n",
      "  驗證損失: 0.7516\n",
      "  驗證 Dice: 0.0933 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1487, IoU: 0.0803\n",
      "    Class 2 - Dice: 0.0379, IoU: 0.0193\n",
      "  學習率: 0.000360\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 22/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2440\n",
      "    Batch 10/104, Loss: 0.2588\n",
      "    Batch 20/104, Loss: 0.2226\n",
      "    Batch 30/104, Loss: 0.2204\n",
      "    Batch 40/104, Loss: 0.2135\n",
      "    Batch 50/104, Loss: 0.1846\n",
      "    Batch 60/104, Loss: 0.2836\n",
      "    Batch 70/104, Loss: 0.2168\n",
      "    Batch 80/104, Loss: 0.2517\n",
      "    Batch 90/104, Loss: 0.2058\n",
      "    Batch 100/104, Loss: 0.2937\n",
      "\n",
      "  訓練損失: 0.2377\n",
      "  驗證損失: 0.7458\n",
      "  驗證 Dice: 0.1121 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1647, IoU: 0.0898\n",
      "    Class 2 - Dice: 0.0595, IoU: 0.0307\n",
      "  學習率: 0.000344\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 23/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2837\n",
      "    Batch 10/104, Loss: 0.2183\n",
      "    Batch 20/104, Loss: 0.2120\n",
      "    Batch 30/104, Loss: 0.1842\n",
      "    Batch 40/104, Loss: 0.1926\n",
      "    Batch 50/104, Loss: 0.2034\n",
      "    Batch 60/104, Loss: 0.2200\n",
      "    Batch 70/104, Loss: 0.2494\n",
      "    Batch 80/104, Loss: 0.2307\n",
      "    Batch 90/104, Loss: 0.2246\n",
      "    Batch 100/104, Loss: 0.2343\n",
      "\n",
      "  訓練損失: 0.2362\n",
      "  驗證損失: 0.7391\n",
      "  驗證 Dice: 0.1409 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.1894, IoU: 0.1046\n",
      "    Class 2 - Dice: 0.0924, IoU: 0.0485\n",
      "  學習率: 0.000328\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 24/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1992\n",
      "    Batch 10/104, Loss: 0.1964\n",
      "    Batch 20/104, Loss: 0.1947\n",
      "    Batch 30/104, Loss: 0.2055\n",
      "    Batch 40/104, Loss: 0.2276\n",
      "    Batch 50/104, Loss: 0.2825\n",
      "    Batch 60/104, Loss: 0.2565\n",
      "    Batch 70/104, Loss: 0.2206\n",
      "    Batch 80/104, Loss: 0.2626\n",
      "    Batch 90/104, Loss: 0.2463\n",
      "    Batch 100/104, Loss: 0.1931\n",
      "\n",
      "  訓練損失: 0.2333\n",
      "  驗證損失: 0.7312\n",
      "  驗證 Dice: 0.1855 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.2325, IoU: 0.1316\n",
      "    Class 2 - Dice: 0.1384, IoU: 0.0744\n",
      "  學習率: 0.000311\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 25/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2146\n",
      "    Batch 10/104, Loss: 0.2140\n",
      "    Batch 20/104, Loss: 0.2795\n",
      "    Batch 30/104, Loss: 0.2267\n",
      "    Batch 40/104, Loss: 0.2660\n",
      "    Batch 50/104, Loss: 0.2701\n",
      "    Batch 60/104, Loss: 0.2465\n",
      "    Batch 70/104, Loss: 0.2331\n",
      "    Batch 80/104, Loss: 0.2043\n",
      "    Batch 90/104, Loss: 0.1948\n",
      "    Batch 100/104, Loss: 0.2545\n",
      "\n",
      "  訓練損失: 0.2369\n",
      "  驗證損失: 0.7220\n",
      "  驗證 Dice: 0.2504 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.3024, IoU: 0.1781\n",
      "    Class 2 - Dice: 0.1983, IoU: 0.1101\n",
      "  學習率: 0.000294\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 26/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2381\n",
      "    Batch 10/104, Loss: 0.2503\n",
      "    Batch 20/104, Loss: 0.2591\n",
      "    Batch 30/104, Loss: 0.2002\n",
      "    Batch 40/104, Loss: 0.3141\n",
      "    Batch 50/104, Loss: 0.2641\n",
      "    Batch 60/104, Loss: 0.2348\n",
      "    Batch 70/104, Loss: 0.1723\n",
      "    Batch 80/104, Loss: 0.2514\n",
      "    Batch 90/104, Loss: 0.2236\n",
      "    Batch 100/104, Loss: 0.2134\n",
      "\n",
      "  訓練損失: 0.2324\n",
      "  驗證損失: 0.7115\n",
      "  驗證 Dice: 0.3329 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.3923, IoU: 0.2440\n",
      "    Class 2 - Dice: 0.2735, IoU: 0.1584\n",
      "  學習率: 0.000277\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 27/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2181\n",
      "    Batch 10/104, Loss: 0.2616\n",
      "    Batch 20/104, Loss: 0.2291\n",
      "    Batch 30/104, Loss: 0.2366\n",
      "    Batch 40/104, Loss: 0.1910\n",
      "    Batch 50/104, Loss: 0.2052\n",
      "    Batch 60/104, Loss: 0.1818\n",
      "    Batch 70/104, Loss: 0.2212\n",
      "    Batch 80/104, Loss: 0.2374\n",
      "    Batch 90/104, Loss: 0.2368\n",
      "    Batch 100/104, Loss: 0.2098\n",
      "\n",
      "  訓練損失: 0.2250\n",
      "  驗證損失: 0.6998\n",
      "  驗證 Dice: 0.4239 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.4918, IoU: 0.3261\n",
      "    Class 2 - Dice: 0.3559, IoU: 0.2165\n",
      "  學習率: 0.000259\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 28/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2300\n",
      "    Batch 10/104, Loss: 0.2794\n",
      "    Batch 20/104, Loss: 0.2334\n",
      "    Batch 30/104, Loss: 0.2348\n",
      "    Batch 40/104, Loss: 0.2009\n",
      "    Batch 50/104, Loss: 0.2249\n",
      "    Batch 60/104, Loss: 0.2110\n",
      "    Batch 70/104, Loss: 0.1797\n",
      "    Batch 80/104, Loss: 0.1967\n",
      "    Batch 90/104, Loss: 0.2029\n",
      "    Batch 100/104, Loss: 0.2239\n",
      "\n",
      "  訓練損失: 0.2274\n",
      "  驗證損失: 0.6872\n",
      "  驗證 Dice: 0.5072 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.5810, IoU: 0.4095\n",
      "    Class 2 - Dice: 0.4334, IoU: 0.2766\n",
      "  學習率: 0.000242\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 29/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2206\n",
      "    Batch 10/104, Loss: 0.2100\n",
      "    Batch 20/104, Loss: 0.2225\n",
      "    Batch 30/104, Loss: 0.2134\n",
      "    Batch 40/104, Loss: 0.1796\n",
      "    Batch 50/104, Loss: 0.2209\n",
      "    Batch 60/104, Loss: 0.2114\n",
      "    Batch 70/104, Loss: 0.2150\n",
      "    Batch 80/104, Loss: 0.2537\n",
      "    Batch 90/104, Loss: 0.2403\n",
      "    Batch 100/104, Loss: 0.1911\n",
      "\n",
      "  訓練損失: 0.2265\n",
      "  驗證損失: 0.6736\n",
      "  驗證 Dice: 0.5773 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.6514, IoU: 0.4830\n",
      "    Class 2 - Dice: 0.5032, IoU: 0.3361\n",
      "  學習率: 0.000224\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 30/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2239\n",
      "    Batch 10/104, Loss: 0.1889\n",
      "    Batch 20/104, Loss: 0.2242\n",
      "    Batch 30/104, Loss: 0.2728\n",
      "    Batch 40/104, Loss: 0.2397\n",
      "    Batch 50/104, Loss: 0.2104\n",
      "    Batch 60/104, Loss: 0.2289\n",
      "    Batch 70/104, Loss: 0.2171\n",
      "    Batch 80/104, Loss: 0.2183\n",
      "    Batch 90/104, Loss: 0.2339\n",
      "    Batch 100/104, Loss: 0.2886\n",
      "\n",
      "  訓練損失: 0.2233\n",
      "  驗證損失: 0.6594\n",
      "  驗證 Dice: 0.6315 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7003, IoU: 0.5388\n",
      "    Class 2 - Dice: 0.5627, IoU: 0.3915\n",
      "  學習率: 0.000207\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 31/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2196\n",
      "    Batch 10/104, Loss: 0.1933\n",
      "    Batch 20/104, Loss: 0.2245\n",
      "    Batch 30/104, Loss: 0.1959\n",
      "    Batch 40/104, Loss: 0.2194\n",
      "    Batch 50/104, Loss: 0.1892\n",
      "    Batch 60/104, Loss: 0.2116\n",
      "    Batch 70/104, Loss: 0.2428\n",
      "    Batch 80/104, Loss: 0.2187\n",
      "    Batch 90/104, Loss: 0.2211\n",
      "    Batch 100/104, Loss: 0.2213\n",
      "\n",
      "  訓練損失: 0.2232\n",
      "  驗證損失: 0.6448\n",
      "  驗證 Dice: 0.6730 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7340, IoU: 0.5798\n",
      "    Class 2 - Dice: 0.6119, IoU: 0.4409\n",
      "  學習率: 0.000190\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 32/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2939\n",
      "    Batch 10/104, Loss: 0.1784\n",
      "    Batch 20/104, Loss: 0.1645\n",
      "    Batch 30/104, Loss: 0.1842\n",
      "    Batch 40/104, Loss: 0.2014\n",
      "    Batch 50/104, Loss: 0.1714\n",
      "    Batch 60/104, Loss: 0.2546\n",
      "    Batch 70/104, Loss: 0.2327\n",
      "    Batch 80/104, Loss: 0.2571\n",
      "    Batch 90/104, Loss: 0.2183\n",
      "    Batch 100/104, Loss: 0.2146\n",
      "\n",
      "  訓練損失: 0.2197\n",
      "  驗證損失: 0.6302\n",
      "  驗證 Dice: 0.7046 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7574, IoU: 0.6095\n",
      "    Class 2 - Dice: 0.6518, IoU: 0.4835\n",
      "  學習率: 0.000173\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 33/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2289\n",
      "    Batch 10/104, Loss: 0.2630\n",
      "    Batch 20/104, Loss: 0.1977\n",
      "    Batch 30/104, Loss: 0.1829\n",
      "    Batch 40/104, Loss: 0.2387\n",
      "    Batch 50/104, Loss: 0.2988\n",
      "    Batch 60/104, Loss: 0.2607\n",
      "    Batch 70/104, Loss: 0.2223\n",
      "    Batch 80/104, Loss: 0.1841\n",
      "    Batch 90/104, Loss: 0.2338\n",
      "    Batch 100/104, Loss: 0.2310\n",
      "\n",
      "  訓練損失: 0.2198\n",
      "  驗證損失: 0.6154\n",
      "  驗證 Dice: 0.7298 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7748, IoU: 0.6324\n",
      "    Class 2 - Dice: 0.6848, IoU: 0.5207\n",
      "  學習率: 0.000157\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 34/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1568\n",
      "    Batch 10/104, Loss: 0.2826\n",
      "    Batch 20/104, Loss: 0.2204\n",
      "    Batch 30/104, Loss: 0.2435\n",
      "    Batch 40/104, Loss: 0.2346\n",
      "    Batch 50/104, Loss: 0.2160\n",
      "    Batch 60/104, Loss: 0.1821\n",
      "    Batch 70/104, Loss: 0.1780\n",
      "    Batch 80/104, Loss: 0.1909\n",
      "    Batch 90/104, Loss: 0.1761\n",
      "    Batch 100/104, Loss: 0.2313\n",
      "\n",
      "  訓練損失: 0.2181\n",
      "  驗證損失: 0.6004\n",
      "  驗證 Dice: 0.7499 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7880, IoU: 0.6502\n",
      "    Class 2 - Dice: 0.7118, IoU: 0.5526\n",
      "  學習率: 0.000141\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 35/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2709\n",
      "    Batch 10/104, Loss: 0.1938\n",
      "    Batch 20/104, Loss: 0.2119\n",
      "    Batch 30/104, Loss: 0.2362\n",
      "    Batch 40/104, Loss: 0.2471\n",
      "    Batch 50/104, Loss: 0.2256\n",
      "    Batch 60/104, Loss: 0.1878\n",
      "    Batch 70/104, Loss: 0.1884\n",
      "    Batch 80/104, Loss: 0.2291\n",
      "    Batch 90/104, Loss: 0.2143\n",
      "    Batch 100/104, Loss: 0.2073\n",
      "\n",
      "  訓練損失: 0.2150\n",
      "  驗證損失: 0.5858\n",
      "  驗證 Dice: 0.7659 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.7984, IoU: 0.6644\n",
      "    Class 2 - Dice: 0.7333, IoU: 0.5790\n",
      "  學習率: 0.000126\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 36/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2196\n",
      "    Batch 10/104, Loss: 0.1850\n",
      "    Batch 20/104, Loss: 0.2300\n",
      "    Batch 30/104, Loss: 0.2414\n",
      "    Batch 40/104, Loss: 0.2320\n",
      "    Batch 50/104, Loss: 0.1761\n",
      "    Batch 60/104, Loss: 0.1973\n",
      "    Batch 70/104, Loss: 0.2137\n",
      "    Batch 80/104, Loss: 0.1982\n",
      "    Batch 90/104, Loss: 0.2240\n",
      "    Batch 100/104, Loss: 0.1770\n",
      "\n",
      "  訓練損失: 0.2144\n",
      "  驗證損失: 0.5711\n",
      "  驗證 Dice: 0.7791 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8072, IoU: 0.6767\n",
      "    Class 2 - Dice: 0.7510, IoU: 0.6013\n",
      "  學習率: 0.000111\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 37/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1947\n",
      "    Batch 10/104, Loss: 0.1856\n",
      "    Batch 20/104, Loss: 0.1898\n",
      "    Batch 30/104, Loss: 0.2181\n",
      "    Batch 40/104, Loss: 0.1699\n",
      "    Batch 50/104, Loss: 0.2052\n",
      "    Batch 60/104, Loss: 0.2149\n",
      "    Batch 70/104, Loss: 0.1729\n",
      "    Batch 80/104, Loss: 0.1985\n",
      "    Batch 90/104, Loss: 0.2876\n",
      "    Batch 100/104, Loss: 0.2363\n",
      "\n",
      "  訓練損失: 0.2136\n",
      "  驗證損失: 0.5566\n",
      "  驗證 Dice: 0.7896 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8141, IoU: 0.6865\n",
      "    Class 2 - Dice: 0.7651, IoU: 0.6195\n",
      "  學習率: 0.000097\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 38/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1966\n",
      "    Batch 10/104, Loss: 0.2136\n",
      "    Batch 20/104, Loss: 0.2020\n",
      "    Batch 30/104, Loss: 0.2928\n",
      "    Batch 40/104, Loss: 0.3115\n",
      "    Batch 50/104, Loss: 0.2134\n",
      "    Batch 60/104, Loss: 0.2295\n",
      "    Batch 70/104, Loss: 0.2317\n",
      "    Batch 80/104, Loss: 0.1850\n",
      "    Batch 90/104, Loss: 0.2013\n",
      "    Batch 100/104, Loss: 0.1974\n",
      "\n",
      "  訓練損失: 0.2128\n",
      "  驗證損失: 0.5423\n",
      "  驗證 Dice: 0.7979 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8197, IoU: 0.6945\n",
      "    Class 2 - Dice: 0.7761, IoU: 0.6341\n",
      "  學習率: 0.000084\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 39/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2373\n",
      "    Batch 10/104, Loss: 0.1845\n",
      "    Batch 20/104, Loss: 0.2014\n",
      "    Batch 30/104, Loss: 0.2139\n",
      "    Batch 40/104, Loss: 0.2932\n",
      "    Batch 50/104, Loss: 0.2282\n",
      "    Batch 60/104, Loss: 0.2688\n",
      "    Batch 70/104, Loss: 0.1982\n",
      "    Batch 80/104, Loss: 0.2369\n",
      "    Batch 90/104, Loss: 0.2028\n",
      "    Batch 100/104, Loss: 0.2194\n",
      "\n",
      "  訓練損失: 0.2103\n",
      "  驗證損失: 0.5280\n",
      "  驗證 Dice: 0.8051 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8247, IoU: 0.7018\n",
      "    Class 2 - Dice: 0.7855, IoU: 0.6468\n",
      "  學習率: 0.000071\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 40/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2020\n",
      "    Batch 10/104, Loss: 0.2095\n",
      "    Batch 20/104, Loss: 0.2193\n",
      "    Batch 30/104, Loss: 0.2163\n",
      "    Batch 40/104, Loss: 0.2202\n",
      "    Batch 50/104, Loss: 0.2518\n",
      "    Batch 60/104, Loss: 0.2182\n",
      "    Batch 70/104, Loss: 0.1847\n",
      "    Batch 80/104, Loss: 0.1960\n",
      "    Batch 90/104, Loss: 0.2228\n",
      "    Batch 100/104, Loss: 0.1759\n",
      "\n",
      "  訓練損失: 0.2111\n",
      "  驗證損失: 0.5140\n",
      "  驗證 Dice: 0.8111 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8290, IoU: 0.7080\n",
      "    Class 2 - Dice: 0.7932, IoU: 0.6573\n",
      "  學習率: 0.000059\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 41/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1949\n",
      "    Batch 10/104, Loss: 0.2110\n",
      "    Batch 20/104, Loss: 0.1492\n",
      "    Batch 30/104, Loss: 0.2184\n",
      "    Batch 40/104, Loss: 0.1737\n",
      "    Batch 50/104, Loss: 0.2295\n",
      "    Batch 60/104, Loss: 0.1804\n",
      "    Batch 70/104, Loss: 0.2152\n",
      "    Batch 80/104, Loss: 0.2528\n",
      "    Batch 90/104, Loss: 0.2404\n",
      "    Batch 100/104, Loss: 0.1844\n",
      "\n",
      "  訓練損失: 0.2080\n",
      "  驗證損失: 0.4999\n",
      "  驗證 Dice: 0.8162 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8327, IoU: 0.7133\n",
      "    Class 2 - Dice: 0.7997, IoU: 0.6663\n",
      "  學習率: 0.000049\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 42/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2156\n",
      "    Batch 10/104, Loss: 0.2141\n",
      "    Batch 20/104, Loss: 0.1997\n",
      "    Batch 30/104, Loss: 0.1931\n",
      "    Batch 40/104, Loss: 0.1901\n",
      "    Batch 50/104, Loss: 0.2282\n",
      "    Batch 60/104, Loss: 0.2228\n",
      "    Batch 70/104, Loss: 0.2054\n",
      "    Batch 80/104, Loss: 0.1647\n",
      "    Batch 90/104, Loss: 0.1729\n",
      "    Batch 100/104, Loss: 0.2099\n",
      "\n",
      "  訓練損失: 0.2070\n",
      "  驗證損失: 0.4862\n",
      "  驗證 Dice: 0.8204 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8357, IoU: 0.7178\n",
      "    Class 2 - Dice: 0.8051, IoU: 0.6738\n",
      "  學習率: 0.000039\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 43/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2384\n",
      "    Batch 10/104, Loss: 0.1584\n",
      "    Batch 20/104, Loss: 0.2302\n",
      "    Batch 30/104, Loss: 0.2301\n",
      "    Batch 40/104, Loss: 0.2351\n",
      "    Batch 50/104, Loss: 0.1801\n",
      "    Batch 60/104, Loss: 0.1902\n",
      "    Batch 70/104, Loss: 0.2013\n",
      "    Batch 80/104, Loss: 0.1699\n",
      "    Batch 90/104, Loss: 0.1499\n",
      "    Batch 100/104, Loss: 0.1625\n",
      "\n",
      "  訓練損失: 0.2061\n",
      "  驗證損失: 0.4727\n",
      "  驗證 Dice: 0.8238 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8383, IoU: 0.7216\n",
      "    Class 2 - Dice: 0.8092, IoU: 0.6796\n",
      "  學習率: 0.000030\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 44/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1735\n",
      "    Batch 10/104, Loss: 0.2346\n",
      "    Batch 20/104, Loss: 0.2042\n",
      "    Batch 30/104, Loss: 0.1756\n",
      "    Batch 40/104, Loss: 0.2186\n",
      "    Batch 50/104, Loss: 0.1972\n",
      "    Batch 60/104, Loss: 0.2540\n",
      "    Batch 70/104, Loss: 0.1921\n",
      "    Batch 80/104, Loss: 0.2261\n",
      "    Batch 90/104, Loss: 0.1931\n",
      "    Batch 100/104, Loss: 0.1813\n",
      "\n",
      "  訓練損失: 0.2056\n",
      "  驗證損失: 0.4595\n",
      "  驗證 Dice: 0.8269 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8407, IoU: 0.7252\n",
      "    Class 2 - Dice: 0.8130, IoU: 0.6849\n",
      "  學習率: 0.000023\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 45/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2393\n",
      "    Batch 10/104, Loss: 0.1707\n",
      "    Batch 20/104, Loss: 0.1851\n",
      "    Batch 30/104, Loss: 0.2214\n",
      "    Batch 40/104, Loss: 0.1730\n",
      "    Batch 50/104, Loss: 0.2112\n",
      "    Batch 60/104, Loss: 0.2002\n",
      "    Batch 70/104, Loss: 0.2533\n",
      "    Batch 80/104, Loss: 0.1706\n",
      "    Batch 90/104, Loss: 0.2037\n",
      "    Batch 100/104, Loss: 0.1925\n",
      "\n",
      "  訓練損失: 0.2055\n",
      "  驗證損失: 0.4465\n",
      "  驗證 Dice: 0.8295 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8430, IoU: 0.7285\n",
      "    Class 2 - Dice: 0.8160, IoU: 0.6892\n",
      "  學習率: 0.000016\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 46/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.2067\n",
      "    Batch 10/104, Loss: 0.1807\n",
      "    Batch 20/104, Loss: 0.1796\n",
      "    Batch 30/104, Loss: 0.1915\n",
      "    Batch 40/104, Loss: 0.1896\n",
      "    Batch 50/104, Loss: 0.2398\n",
      "    Batch 60/104, Loss: 0.2256\n",
      "    Batch 70/104, Loss: 0.1722\n",
      "    Batch 80/104, Loss: 0.2005\n",
      "    Batch 90/104, Loss: 0.2193\n",
      "    Batch 100/104, Loss: 0.1823\n",
      "\n",
      "  訓練損失: 0.2053\n",
      "  驗證損失: 0.4338\n",
      "  驗證 Dice: 0.8319 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8450, IoU: 0.7315\n",
      "    Class 2 - Dice: 0.8189, IoU: 0.6933\n",
      "  學習率: 0.000011\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 47/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1704\n",
      "    Batch 10/104, Loss: 0.2298\n",
      "    Batch 20/104, Loss: 0.2136\n",
      "    Batch 30/104, Loss: 0.1664\n",
      "    Batch 40/104, Loss: 0.1729\n",
      "    Batch 50/104, Loss: 0.1861\n",
      "    Batch 60/104, Loss: 0.1929\n",
      "    Batch 70/104, Loss: 0.1877\n",
      "    Batch 80/104, Loss: 0.1951\n",
      "    Batch 90/104, Loss: 0.2318\n",
      "    Batch 100/104, Loss: 0.1530\n",
      "\n",
      "  訓練損失: 0.2045\n",
      "  驗證損失: 0.4213\n",
      "  驗證 Dice: 0.8340 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8467, IoU: 0.7341\n",
      "    Class 2 - Dice: 0.8213, IoU: 0.6968\n",
      "  學習率: 0.000006\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 48/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1936\n",
      "    Batch 10/104, Loss: 0.2081\n",
      "    Batch 20/104, Loss: 0.2073\n",
      "    Batch 30/104, Loss: 0.1898\n",
      "    Batch 40/104, Loss: 0.2686\n",
      "    Batch 50/104, Loss: 0.2246\n",
      "    Batch 60/104, Loss: 0.1784\n",
      "    Batch 70/104, Loss: 0.2031\n",
      "    Batch 80/104, Loss: 0.2000\n",
      "    Batch 90/104, Loss: 0.2161\n",
      "    Batch 100/104, Loss: 0.1895\n",
      "\n",
      "  訓練損失: 0.2046\n",
      "  驗證損失: 0.4093\n",
      "  驗證 Dice: 0.8359 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8484, IoU: 0.7366\n",
      "    Class 2 - Dice: 0.8234, IoU: 0.6998\n",
      "  學習率: 0.000003\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 49/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1793\n",
      "    Batch 10/104, Loss: 0.2091\n",
      "    Batch 20/104, Loss: 0.1865\n",
      "    Batch 30/104, Loss: 0.2234\n",
      "    Batch 40/104, Loss: 0.1670\n",
      "    Batch 50/104, Loss: 0.2257\n",
      "    Batch 60/104, Loss: 0.1839\n",
      "    Batch 70/104, Loss: 0.1777\n",
      "    Batch 80/104, Loss: 0.1976\n",
      "    Batch 90/104, Loss: 0.1614\n",
      "    Batch 100/104, Loss: 0.1725\n",
      "\n",
      "  訓練損失: 0.2041\n",
      "  驗證損失: 0.3976\n",
      "  驗證 Dice: 0.8376 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8498, IoU: 0.7389\n",
      "    Class 2 - Dice: 0.8253, IoU: 0.7026\n",
      "  學習率: 0.000002\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "Epoch 50/50\n",
      "----------------------------------------\n",
      "    Batch 0/104, Loss: 0.1909\n",
      "    Batch 10/104, Loss: 0.1830\n",
      "    Batch 20/104, Loss: 0.2051\n",
      "    Batch 30/104, Loss: 0.1920\n",
      "    Batch 40/104, Loss: 0.2020\n",
      "    Batch 50/104, Loss: 0.2119\n",
      "    Batch 60/104, Loss: 0.2359\n",
      "    Batch 70/104, Loss: 0.1863\n",
      "    Batch 80/104, Loss: 0.1811\n",
      "    Batch 90/104, Loss: 0.2286\n",
      "    Batch 100/104, Loss: 0.2509\n",
      "\n",
      "  訓練損失: 0.2027\n",
      "  驗證損失: 0.3861\n",
      "  驗證 Dice: 0.8391 🎯 新紀錄!\n",
      "    Class 1 - Dice: 0.8512, IoU: 0.7409\n",
      "    Class 2 - Dice: 0.8270, IoU: 0.7050\n",
      "  學習率: 0.000001\n",
      "  ✓ 已保存最佳模型\n",
      "\n",
      "================================================================================\n",
      "訓練完成! 最佳 Dice: 0.8391\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "🚀 提升 Dice 的改進版訓練系統\n",
    "策略：更大模型 + 更強增強 + LR warmup + 更長訓練\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"提升 Dice 的改進版訓練系統\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import json\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "from types import ModuleType\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "print(f\"\\nPyTorch {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "\n",
    "# ==================== Stub ====================\n",
    "\n",
    "def create_stub_module(name, attributes):\n",
    "    mod = ModuleType(name)\n",
    "    for attr_name, attr_value in attributes.items():\n",
    "        setattr(mod, attr_name, attr_value)\n",
    "    return mod\n",
    "\n",
    "sys.modules['torch._compile'] = create_stub_module('torch._compile', {'inner': lambda func: func})\n",
    "sys.modules['torch.onnx'] = create_stub_module('torch.onnx', {'is_in_onnx_export': False})\n",
    "\n",
    "print(\"\\n設置環境完成\")\n",
    "\n",
    "# ==================== 改進的 Config ====================\n",
    "\n",
    "class ImprovedConfig:\n",
    "    def __init__(self):\n",
    "        self.seed = 42\n",
    "        self.data_root = '/workspace/Task04_Hippocampus'\n",
    "        self.output_dir = '/workspace/outputs/training_improved'\n",
    "        \n",
    "        # 更長訓練\n",
    "        self.batch_size = 2\n",
    "        self.num_epochs = 50  # 從 30 增加到 50\n",
    "        self.target_size = 64\n",
    "        \n",
    "        # 改進的學習率策略\n",
    "        self.lr = 5e-4  # 從 1e-3 降到 5e-4（更穩定）\n",
    "        self.weight_decay = 1e-4\n",
    "        self.lr_min = 1e-6  # 從 1e-5 降到 1e-6\n",
    "        self.warmup_epochs = 5  # 新增：前 5 epochs warmup\n",
    "        \n",
    "        # 更大的模型\n",
    "        self.model_base = 24  # 從 16 增加到 24\n",
    "        self.num_classes = 3\n",
    "        self.deep_supervision = True\n",
    "        self.ds_weights = [1.0, 0.5, 0.25]\n",
    "        self.ds_warmup_epochs = 10  # 延長深度監督暖身\n",
    "        self.ds_warmup_weights = [1.0, 0.75, 0.5]\n",
    "        \n",
    "        self.use_amp = True\n",
    "        self.use_ema = True\n",
    "        self.ema_decay = 0.9999\n",
    "        self.grad_clip = 1.0\n",
    "        \n",
    "        # 調整損失權重（更重視 Dice）\n",
    "        self.use_focal = True\n",
    "        self.focal_alpha = [0.2, 1.0, 1.0]\n",
    "        self.focal_gamma = 2.0\n",
    "        self.loss_weights = [0.2, 0.8]  # CE:Dice = 0.2:0.8（從 0.3:0.7）\n",
    "        self.dice_ignore_background = True\n",
    "        \n",
    "        # 更強的數據增強\n",
    "        self.aug_flip_prob = 0.5\n",
    "        self.aug_rotate_prob = 0.5\n",
    "        self.aug_gamma_prob = 0.5\n",
    "        self.aug_gamma_range = [0.7, 1.3]  # 從 [0.8, 1.2] 擴大\n",
    "        self.aug_intensity_shift_prob = 0.5\n",
    "        self.aug_intensity_shift_range = [-0.15, 0.15]  # 從 [-0.1, 0.1] 擴大\n",
    "        self.aug_intensity_scale_prob = 0.5\n",
    "        self.aug_intensity_scale_range = [0.85, 1.15]  # 從 [0.9, 1.1] 擴大\n",
    "        self.aug_noise_prob = 0.3  # 新增：高斯噪聲\n",
    "        self.aug_noise_std = 0.1\n",
    "        self.aug_blur_prob = 0.2  # 新增：模糊\n",
    "        \n",
    "        self.num_workers = 4\n",
    "        self.pin_memory = True\n",
    "        self.persistent_workers = True\n",
    "        self.prefetch_factor = 2\n",
    "        \n",
    "        self.use_tf32 = True\n",
    "        self.use_channels_last = False\n",
    "        self.use_deterministic_algorithms = False\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=2)\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        config = cls()\n",
    "        with open(path, 'r') as f:\n",
    "            config.__dict__.update(json.load(f))\n",
    "        return config\n",
    "\n",
    "# ==================== 設置 ====================\n",
    "\n",
    "def set_seed(seed=42, use_tf32=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "    if use_tf32 and torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "        print(\"  TF32 enabled\")\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "def get_generator(seed):\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "    return g\n",
    "\n",
    "def gcd(a, b):\n",
    "    while b:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "MEMORY_FORMAT = getattr(torch, \"channels_last_3d\", torch.contiguous_format)\n",
    "\n",
    "# ==================== 改進的數據增強 ====================\n",
    "\n",
    "class ImprovedAugmentation3D:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    \n",
    "    def random_flip(self, image, label):\n",
    "        if np.random.rand() < self.config.aug_flip_prob:\n",
    "            axis = np.random.choice([0, 1, 2])\n",
    "            image = torch.flip(image, dims=[axis + 1])\n",
    "            label = torch.flip(label, dims=[axis])\n",
    "        return image, label\n",
    "    \n",
    "    def random_rotate_90(self, image, label):\n",
    "        if np.random.rand() < self.config.aug_rotate_prob:\n",
    "            k = np.random.randint(1, 4)\n",
    "            image = torch.rot90(image, k, dims=[2, 3])\n",
    "            label = torch.rot90(label, k, dims=[1, 2])\n",
    "        return image, label\n",
    "    \n",
    "    def random_gamma(self, image):\n",
    "        if np.random.rand() < self.config.aug_gamma_prob:\n",
    "            gamma = np.random.uniform(*self.config.aug_gamma_range)\n",
    "            image_min = image.min()\n",
    "            image_max = image.max()\n",
    "            if image_max > image_min:\n",
    "                image_norm = (image - image_min) / (image_max - image_min)\n",
    "                image = torch.pow(image_norm, gamma)\n",
    "                image = image * (image_max - image_min) + image_min\n",
    "        return image\n",
    "    \n",
    "    def random_intensity_shift(self, image):\n",
    "        if np.random.rand() < self.config.aug_intensity_shift_prob:\n",
    "            shift = np.random.uniform(*self.config.aug_intensity_shift_range)\n",
    "            image = image + shift\n",
    "        return image\n",
    "    \n",
    "    def random_intensity_scale(self, image):\n",
    "        if np.random.rand() < self.config.aug_intensity_scale_prob:\n",
    "            scale = np.random.uniform(*self.config.aug_intensity_scale_range)\n",
    "            image = image * scale\n",
    "        return image\n",
    "    \n",
    "    def add_gaussian_noise(self, image):\n",
    "        \"\"\"新增：高斯噪聲\"\"\"\n",
    "        if np.random.rand() < self.config.aug_noise_prob:\n",
    "            noise = torch.randn_like(image) * self.config.aug_noise_std\n",
    "            image = image + noise\n",
    "        return image\n",
    "    \n",
    "    def gaussian_blur(self, image):\n",
    "        \"\"\"新增：高斯模糊\"\"\"\n",
    "        if np.random.rand() < self.config.aug_blur_prob:\n",
    "            # 使用 avg pooling 模擬模糊\n",
    "            image = F.avg_pool3d(image.unsqueeze(0), 3, stride=1, padding=1).squeeze(0)\n",
    "        return image\n",
    "    \n",
    "    def apply(self, image, label, is_training=True):\n",
    "        if not is_training:\n",
    "            return image, label\n",
    "        \n",
    "        image, label = self.random_flip(image, label)\n",
    "        image, label = self.random_rotate_90(image, label)\n",
    "        image = self.random_gamma(image)\n",
    "        image = self.random_intensity_shift(image)\n",
    "        image = self.random_intensity_scale(image)\n",
    "        image = self.add_gaussian_noise(image)\n",
    "        image = self.gaussian_blur(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# ==================== 數據集 ====================\n",
    "\n",
    "class HippocampusDataset(Dataset):\n",
    "    def __init__(self, data_root, indices, config, is_training=True):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.config = config\n",
    "        self.is_training = is_training\n",
    "        self.augmentation = ImprovedAugmentation3D(config)\n",
    "        \n",
    "        with open(self.data_root / 'dataset.json', 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        \n",
    "        training_data = metadata['training']\n",
    "        self.cases = [training_data[i] for i in indices]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        case = self.cases[idx]\n",
    "        img_path = self.data_root / case['image'].lstrip('./')\n",
    "        lbl_path = self.data_root / case['label'].lstrip('./')\n",
    "        \n",
    "        image = nib.load(str(img_path)).get_fdata(dtype=np.float32)\n",
    "        label = nib.load(str(lbl_path)).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        p1, p99 = np.percentile(image, [1, 99])\n",
    "        image = np.clip(image, p1, p99)\n",
    "        mean, std = image.mean(), image.std()\n",
    "        if std > 1e-8:\n",
    "            image = (image - mean) / std\n",
    "        \n",
    "        image_t = torch.from_numpy(image).unsqueeze(0).unsqueeze(0)\n",
    "        label_t = torch.from_numpy(label).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        image = F.interpolate(\n",
    "            image_t, size=(self.config.target_size,) * 3,\n",
    "            mode='trilinear', align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        label = F.interpolate(\n",
    "            label_t, size=(self.config.target_size,) * 3,\n",
    "            mode='nearest'\n",
    "        ).squeeze(0).squeeze(0)\n",
    "        \n",
    "        label = torch.round(label).long()\n",
    "        label = torch.clamp(label, 0, 2)\n",
    "        \n",
    "        image, label = self.augmentation.apply(image, label, self.is_training)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "def get_train_val_split(num_samples, train_ratio=0.8, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    split_idx = int(num_samples * train_ratio)\n",
    "    return indices[:split_idx], indices[split_idx:]\n",
    "\n",
    "# ==================== 模型 ====================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, num_groups=8):\n",
    "        super().__init__()\n",
    "        actual_groups = gcd(num_groups, out_ch)\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_ch, out_ch, 3, padding=1)\n",
    "        self.gn1 = nn.GroupNorm(actual_groups, out_ch)\n",
    "        self.conv2 = nn.Conv3d(out_ch, out_ch, 3, padding=1)\n",
    "        self.gn2 = nn.GroupNorm(actual_groups, out_ch)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.gn1(self.conv1(x)))\n",
    "        x = self.relu(self.gn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UNet3DDeepSupervision(nn.Module):\n",
    "    def __init__(self, in_ch=1, num_classes=3, base=16, deep_supervision=True):\n",
    "        super().__init__()\n",
    "        self.deep_supervision = deep_supervision\n",
    "        \n",
    "        self.enc1 = ConvBlock(in_ch, base)\n",
    "        self.enc2 = ConvBlock(base, base * 2)\n",
    "        self.enc3 = ConvBlock(base * 2, base * 4)\n",
    "        self.bottleneck = ConvBlock(base * 4, base * 8)\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose3d(base * 8, base * 4, 2, stride=2)\n",
    "        self.dec3 = ConvBlock(base * 8, base * 4)\n",
    "        self.up2 = nn.ConvTranspose3d(base * 4, base * 2, 2, stride=2)\n",
    "        self.dec2 = ConvBlock(base * 4, base * 2)\n",
    "        self.up1 = nn.ConvTranspose3d(base * 2, base, 2, stride=2)\n",
    "        self.dec1 = ConvBlock(base * 2, base)\n",
    "        \n",
    "        self.out = nn.Conv3d(base, num_classes, 1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        \n",
    "        if deep_supervision:\n",
    "            self.ds_out3 = nn.Conv3d(base * 4, num_classes, 1)\n",
    "            self.ds_out2 = nn.Conv3d(base * 2, num_classes, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "        \n",
    "        d3 = self.dec3(torch.cat([self.up3(b), e3], 1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], 1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], 1))\n",
    "        \n",
    "        out = self.out(d1)\n",
    "        \n",
    "        if self.deep_supervision and self.training:\n",
    "            ds3 = F.interpolate(self.ds_out3(d3), size=out.shape[2:], mode='trilinear', align_corners=False)\n",
    "            ds2 = F.interpolate(self.ds_out2(d2), size=out.shape[2:], mode='trilinear', align_corners=False)\n",
    "            return out, ds3, ds2\n",
    "        \n",
    "        return out\n",
    "\n",
    "# ==================== EMA ====================\n",
    "\n",
    "class ModelEMA:\n",
    "    def __init__(self, model, decay=0.9999):\n",
    "        self.model = copy.deepcopy(model).eval()\n",
    "        self.decay = decay\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def update(self, model):\n",
    "        with torch.no_grad():\n",
    "            model_state = model.state_dict()\n",
    "            ema_state = self.model.state_dict()\n",
    "            assert model_state.keys() == ema_state.keys()\n",
    "            for key in ema_state.keys():\n",
    "                if ema_state[key].dtype.is_floating_point:\n",
    "                    ema_state[key].mul_(self.decay).add_(model_state[key], alpha=1 - self.decay)\n",
    "                else:\n",
    "                    ema_state[key].copy_(model_state[key])\n",
    "\n",
    "# ==================== 損失函數 ====================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        if alpha is not None:\n",
    "            self.register_buffer('alpha', alpha)\n",
    "        else:\n",
    "            self.alpha = None\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[target]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0, ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "        self.ignore_index = ignore_index\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        target_1h = F.one_hot(target, pred.shape[1]).permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        if self.ignore_index is not None:\n",
    "            keep = [i for i in range(pred.shape[1]) if i != self.ignore_index]\n",
    "            pred = pred[:, keep]\n",
    "            target_1h = target_1h[:, keep]\n",
    "        \n",
    "        inter = (pred * target_1h).sum(dim=(2, 3, 4))\n",
    "        union = pred.sum(dim=(2, 3, 4)) + target_1h.sum(dim=(2, 3, 4))\n",
    "        dice = (2. * inter + self.smooth) / (union + self.smooth)\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "class CombinedLossDeepSupervision(nn.Module):\n",
    "    def __init__(self, config, device):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.loss_weights = config.loss_weights\n",
    "        \n",
    "        if config.use_focal:\n",
    "            alpha = torch.tensor(config.focal_alpha, device=device)\n",
    "            self.ce = FocalLoss(alpha=alpha, gamma=config.focal_gamma)\n",
    "        else:\n",
    "            weight = torch.tensor(config.focal_alpha, device=device)\n",
    "            self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "        \n",
    "        ignore_idx = 0 if config.dice_ignore_background else None\n",
    "        self.dice = DiceLoss(ignore_index=ignore_idx)\n",
    "    \n",
    "    def forward(self, outputs, target, epoch=None):\n",
    "        ce_weight, dice_weight = self.loss_weights\n",
    "        \n",
    "        if epoch is not None and epoch <= self.config.ds_warmup_epochs:\n",
    "            ds_weights = self.config.ds_warmup_weights\n",
    "        else:\n",
    "            ds_weights = self.config.ds_weights\n",
    "        \n",
    "        if isinstance(outputs, tuple):\n",
    "            main_out, ds3, ds2 = outputs\n",
    "            loss = ds_weights[0] * (ce_weight * self.ce(main_out, target) + dice_weight * self.dice(main_out, target))\n",
    "            loss += ds_weights[1] * (ce_weight * self.ce(ds3, target) + dice_weight * self.dice(ds3, target))\n",
    "            loss += ds_weights[2] * (ce_weight * self.ce(ds2, target) + dice_weight * self.dice(ds2, target))\n",
    "            return loss\n",
    "        else:\n",
    "            return ce_weight * self.ce(outputs, target) + dice_weight * self.dice(outputs, target)\n",
    "\n",
    "# ==================== 指標 ====================\n",
    "\n",
    "class DatasetMetrics:\n",
    "    def __init__(self, num_classes, device):\n",
    "        self.num_classes = num_classes\n",
    "        self.device = device\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tp = torch.zeros(self.num_classes, dtype=torch.float32, device=self.device)\n",
    "        self.fp = torch.zeros(self.num_classes, dtype=torch.float32, device=self.device)\n",
    "        self.fn = torch.zeros(self.num_classes, dtype=torch.float32, device=self.device)\n",
    "    \n",
    "    def update(self, pred, target):\n",
    "        for cls in range(1, self.num_classes):\n",
    "            pred_mask = (pred == cls)\n",
    "            target_mask = (target == cls)\n",
    "            self.tp[cls] += (pred_mask & target_mask).sum().to(self.tp.dtype)\n",
    "            self.fp[cls] += (pred_mask & ~target_mask).sum().to(self.fp.dtype)\n",
    "            self.fn[cls] += (~pred_mask & target_mask).sum().to(self.fn.dtype)\n",
    "    \n",
    "    def compute(self):\n",
    "        smooth = 1.0\n",
    "        tp = self.tp.detach().cpu()\n",
    "        fp = self.fp.detach().cpu()\n",
    "        fn = self.fn.detach().cpu()\n",
    "        \n",
    "        dice_scores = {}\n",
    "        iou_scores = {}\n",
    "        \n",
    "        for cls in range(1, self.num_classes):\n",
    "            dice = (2 * tp[cls] + smooth) / (2 * tp[cls] + fp[cls] + fn[cls] + smooth)\n",
    "            iou = (tp[cls] + smooth) / (tp[cls] + fp[cls] + fn[cls] + smooth)\n",
    "            dice_scores[cls] = dice.item()\n",
    "            iou_scores[cls] = iou.item()\n",
    "        \n",
    "        return dice_scores, iou_scores\n",
    "\n",
    "# ==================== Warmup Cosine Scheduler ====================\n",
    "\n",
    "class WarmupCosineAnnealingLR:\n",
    "    def __init__(self, optimizer, T_max, warmup_epochs, eta_min=0):\n",
    "        self.optimizer = optimizer\n",
    "        self.T_max = T_max\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.eta_min = eta_min\n",
    "        self.base_lr = optimizer.param_groups[0]['lr']\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.current_epoch += 1\n",
    "        \n",
    "        if self.current_epoch <= self.warmup_epochs:\n",
    "            # Warmup: 線性增長\n",
    "            lr = self.base_lr * (self.current_epoch / self.warmup_epochs)\n",
    "        else:\n",
    "            # Cosine annealing\n",
    "            progress = (self.current_epoch - self.warmup_epochs) / (self.T_max - self.warmup_epochs)\n",
    "            lr = self.eta_min + (self.base_lr - self.eta_min) * (1 + math.cos(math.pi * progress)) / 2\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "# ==================== 訓練器 ====================\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, device, config):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.output_dir = Path(config.output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=config.lr,\n",
    "            weight_decay=config.weight_decay,\n",
    "            betas=(0.9, 0.999)\n",
    "        )\n",
    "        \n",
    "        self.scheduler = WarmupCosineAnnealingLR(\n",
    "            self.optimizer, \n",
    "            T_max=config.num_epochs, \n",
    "            warmup_epochs=config.warmup_epochs,\n",
    "            eta_min=config.lr_min\n",
    "        )\n",
    "        self.ema = ModelEMA(model, decay=config.ema_decay) if config.use_ema else None\n",
    "        self.criterion = CombinedLossDeepSupervision(config, device)\n",
    "        \n",
    "        self.use_amp = config.use_amp and torch.cuda.is_available()\n",
    "        self.scaler = GradScaler() if self.use_amp else None\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [], 'val_dice': [],\n",
    "            'val_dice_class1': [], 'val_dice_class2': [],\n",
    "            'val_iou_class1': [], 'val_iou_class2': [], 'lr': []\n",
    "        }\n",
    "        self.best_dice = 0.0\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "        print(f\"  AdamW (lr={config.lr}) + Warmup({config.warmup_epochs}) + Cosine\")\n",
    "        print(f\"  更大模型 (base={config.model_base})\")\n",
    "        print(f\"  更強增強 (noise + blur)\")\n",
    "        print(f\"  更長訓練 ({config.num_epochs} epochs)\")\n",
    "        print(f\"  Dice 權重: {config.loss_weights[1]:.1f}\")\n",
    "    \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(self.train_loader):\n",
    "            images = images.to(self.device, non_blocking=True)\n",
    "            labels = labels.to(self.device, non_blocking=True)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if self.use_amp:\n",
    "                with autocast():\n",
    "                    outputs = self.model(images)\n",
    "                    loss = self.criterion(outputs, labels, epoch=self.current_epoch)\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.config.grad_clip)\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels, epoch=self.current_epoch)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=self.config.grad_clip)\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            if self.ema:\n",
    "                self.ema.update(self.model)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"    Batch {batch_idx}/{len(self.train_loader)}, Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "    \n",
    "    def validate(self, use_ema=True):\n",
    "        model = self.ema.model if (use_ema and self.ema) else self.model\n",
    "        model.eval()\n",
    "        \n",
    "        total_loss = 0\n",
    "        metrics_tracker = DatasetMetrics(self.config.num_classes, self.device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for images, labels in self.val_loader:\n",
    "                images = images.to(self.device, non_blocking=True)\n",
    "                labels = labels.to(self.device, non_blocking=True)\n",
    "                \n",
    "                if self.use_amp:\n",
    "                    with autocast():\n",
    "                        outputs = model(images)\n",
    "                        if isinstance(outputs, tuple):\n",
    "                            outputs = outputs[0]\n",
    "                        loss = self.criterion(outputs, labels)\n",
    "                else:\n",
    "                    outputs = model(images)\n",
    "                    if isinstance(outputs, tuple):\n",
    "                        outputs = outputs[0]\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                \n",
    "                for i in range(preds.shape[0]):\n",
    "                    metrics_tracker.update(preds[i], labels[i])\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        dice_scores, iou_scores = metrics_tracker.compute()\n",
    "        avg_dice = np.mean([dice_scores[1], dice_scores[2]])\n",
    "        \n",
    "        avg_metrics = {\n",
    "            1: {'dice': dice_scores[1], 'iou': iou_scores[1]},\n",
    "            2: {'dice': dice_scores[2], 'iou': iou_scores[2]}\n",
    "        }\n",
    "        \n",
    "        return total_loss / len(self.val_loader), avg_dice, avg_metrics\n",
    "    \n",
    "    def train(self):\n",
    "        print(f\"\\n開始訓練 {self.config.num_epochs} epochs\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for epoch in range(1, self.config.num_epochs + 1):\n",
    "            self.current_epoch = epoch\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch}/{self.config.num_epochs}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss, val_dice, metrics = self.validate(use_ema=True)\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            current_lr = self.scheduler.get_lr()\n",
    "            \n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_dice'].append(val_dice)\n",
    "            self.history['val_dice_class1'].append(metrics[1]['dice'])\n",
    "            self.history['val_dice_class2'].append(metrics[2]['dice'])\n",
    "            self.history['val_iou_class1'].append(metrics[1]['iou'])\n",
    "            self.history['val_iou_class2'].append(metrics[2]['iou'])\n",
    "            self.history['lr'].append(current_lr)\n",
    "            \n",
    "            print(f\"\\n  訓練損失: {train_loss:.4f}\")\n",
    "            print(f\"  驗證損失: {val_loss:.4f}\")\n",
    "            print(f\"  驗證 Dice: {val_dice:.4f} {'🎯 新紀錄!' if val_dice > self.best_dice else ''}\")\n",
    "            print(f\"    Class 1 - Dice: {metrics[1]['dice']:.4f}, IoU: {metrics[1]['iou']:.4f}\")\n",
    "            print(f\"    Class 2 - Dice: {metrics[2]['dice']:.4f}, IoU: {metrics[2]['iou']:.4f}\")\n",
    "            print(f\"  學習率: {current_lr:.6f}\")\n",
    "            \n",
    "            if val_dice > self.best_dice:\n",
    "                self.best_dice = val_dice\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model': self.model.state_dict(),\n",
    "                    'optimizer': self.optimizer.state_dict(),\n",
    "                    'dice': val_dice,\n",
    "                    'metrics': metrics,\n",
    "                    'history': self.history,\n",
    "                    'config': self.config.__dict__\n",
    "                }\n",
    "                if self.ema:\n",
    "                    checkpoint['ema'] = self.ema.model.state_dict()\n",
    "                \n",
    "                torch.save(checkpoint, self.output_dir / 'best_model.pth')\n",
    "                print(f\"  ✓ 已保存最佳模型\")\n",
    "        \n",
    "        with open(self.output_dir / 'history.json', 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        \n",
    "        self.config.save(self.output_dir / 'config.json')\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"訓練完成! 最佳 Dice: {self.best_dice:.4f}\")\n",
    "\n",
    "# ==================== 主程序 ====================\n",
    "\n",
    "def main():\n",
    "    config = ImprovedConfig()\n",
    "    \n",
    "    set_seed(config.seed, config.use_tf32)\n",
    "    \n",
    "    print(f\"隨機種子: {config.seed}\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"使用設備: {device}\")\n",
    "    \n",
    "    print(\"\\n準備資料...\")\n",
    "    with open(Path(config.data_root) / 'dataset.json') as f:\n",
    "        num_samples = len(json.load(f)['training'])\n",
    "    \n",
    "    train_indices, val_indices = get_train_val_split(num_samples, seed=config.seed)\n",
    "    print(f\"  訓練集: {len(train_indices)}\")\n",
    "    print(f\"  驗證集: {len(val_indices)}\")\n",
    "    \n",
    "    train_dataset = HippocampusDataset(config.data_root, train_indices, config, is_training=True)\n",
    "    val_dataset = HippocampusDataset(config.data_root, val_indices, config, is_training=False)\n",
    "    \n",
    "    num_workers = min(config.num_workers, os.cpu_count() or 1) if torch.cuda.is_available() else 0\n",
    "    \n",
    "    train_generator = get_generator(config.seed)\n",
    "    val_generator = get_generator(config.seed)\n",
    "    \n",
    "    train_loader_kwargs = {\n",
    "        'batch_size': config.batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': num_workers,\n",
    "        'pin_memory': config.pin_memory,\n",
    "        'worker_init_fn': worker_init_fn,\n",
    "        'generator': train_generator\n",
    "    }\n",
    "    if num_workers > 0:\n",
    "        train_loader_kwargs.update({\n",
    "            'persistent_workers': config.persistent_workers,\n",
    "            'prefetch_factor': config.prefetch_factor\n",
    "        })\n",
    "    \n",
    "    val_loader_kwargs = {\n",
    "        'batch_size': config.batch_size,\n",
    "        'shuffle': False,\n",
    "        'num_workers': num_workers,\n",
    "        'pin_memory': config.pin_memory,\n",
    "        'worker_init_fn': worker_init_fn,\n",
    "        'generator': val_generator\n",
    "    }\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, **train_loader_kwargs)\n",
    "    val_loader = DataLoader(val_dataset, **val_loader_kwargs)\n",
    "    \n",
    "    print(\"\\n建立模型...\")\n",
    "    model = UNet3DDeepSupervision(1, config.num_classes, config.model_base, config.deep_supervision)\n",
    "    print(f\"  參數: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    trainer = Trainer(model, train_loader, val_loader, device, config)\n",
    "    trainer.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n訓練中斷\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cefe37de-2ee1-40c8-ac79-2a4d32f51248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 找到數據目錄: ./Task04_Hippocampus\n",
      "  (260 個有效文件)\n",
      "\n",
      "============================================================\n",
      "純粹的 3D U-Net 訓練\n",
      "============================================================\n",
      "配置:\n",
      "  data_dir: ./Task04_Hippocampus\n",
      "  batch_size: 2\n",
      "  num_epochs: 30\n",
      "  lr: 0.001\n",
      "  base_channels: 16\n",
      "  target_size: 64\n",
      "  device: cuda\n",
      "\n",
      "準備數據集...\n",
      "找到 260 個訓練樣本\n",
      "訓練集: 208 樣本\n",
      "驗證集: 52 樣本\n",
      "\n",
      "創建模型...\n",
      "模型參數量: 1,402,003 (1.40M)\n",
      "\n",
      "開始訓練...\n",
      "\n",
      "Epoch 1/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 26.90it/s, loss=0.4429]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6237\n",
      "Val Dice - Class 1: 0.6355, Class 2: 0.6403, Avg: 0.6379\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.6379) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 2/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 29.54it/s, loss=0.2678]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3207\n",
      "Val Dice - Class 1: 0.6834, Class 2: 0.7307, Avg: 0.7070\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.7070) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 3/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:04<00:00, 25.00it/s, loss=0.1526]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1983\n",
      "Val Dice - Class 1: 0.7137, Class 2: 0.7626, Avg: 0.7381\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.7381) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 4/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 29.30it/s, loss=0.1304]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1533\n",
      "Val Dice - Class 1: 0.6823, Class 2: 0.7495, Avg: 0.7159\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 5/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.09it/s, loss=0.1059]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1299\n",
      "Val Dice - Class 1: 0.7504, Class 2: 0.7680, Avg: 0.7592\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.7592) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 6/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.12it/s, loss=0.1206]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1147\n",
      "Val Dice - Class 1: 0.7780, Class 2: 0.7877, Avg: 0.7829\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.7829) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 7/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.75it/s, loss=0.0998]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1109\n",
      "Val Dice - Class 1: 0.7887, Class 2: 0.8045, Avg: 0.7966\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.7966) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 8/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.78it/s, loss=0.0930]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1031\n",
      "Val Dice - Class 1: 0.7821, Class 2: 0.7951, Avg: 0.7886\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 9/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.49it/s, loss=0.1116]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1015\n",
      "Val Dice - Class 1: 0.7980, Class 2: 0.8020, Avg: 0.8000\n",
      "Learning Rate: 0.001000\n",
      "✓ 保存最佳模型 (Dice: 0.8000) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 10/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.72it/s, loss=0.0916]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1018\n",
      "Val Dice - Class 1: 0.8194, Class 2: 0.8148, Avg: 0.8171\n",
      "Learning Rate: 0.000500\n",
      "✓ 保存最佳模型 (Dice: 0.8171) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 11/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.60it/s, loss=0.0827]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0937\n",
      "Val Dice - Class 1: 0.8369, Class 2: 0.8204, Avg: 0.8287\n",
      "Learning Rate: 0.000500\n",
      "✓ 保存最佳模型 (Dice: 0.8287) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 12/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.12it/s, loss=0.0698]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0871\n",
      "Val Dice - Class 1: 0.8187, Class 2: 0.8157, Avg: 0.8172\n",
      "Learning Rate: 0.000500\n",
      "\n",
      "Epoch 13/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.93it/s, loss=0.0780]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0887\n",
      "Val Dice - Class 1: 0.8303, Class 2: 0.8223, Avg: 0.8263\n",
      "Learning Rate: 0.000500\n",
      "\n",
      "Epoch 14/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.62it/s, loss=0.0742]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0866\n",
      "Val Dice - Class 1: 0.8296, Class 2: 0.8007, Avg: 0.8151\n",
      "Learning Rate: 0.000500\n",
      "\n",
      "Epoch 15/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.71it/s, loss=0.0687]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0854\n",
      "Val Dice - Class 1: 0.8364, Class 2: 0.8212, Avg: 0.8288\n",
      "Learning Rate: 0.000500\n",
      "✓ 保存最佳模型 (Dice: 0.8288) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 16/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.87it/s, loss=0.0768]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0855\n",
      "Val Dice - Class 1: 0.8348, Class 2: 0.8211, Avg: 0.8280\n",
      "Learning Rate: 0.000500\n",
      "\n",
      "Epoch 17/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.78it/s, loss=0.0676]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0851\n",
      "Val Dice - Class 1: 0.8375, Class 2: 0.8297, Avg: 0.8336\n",
      "Learning Rate: 0.000500\n",
      "✓ 保存最佳模型 (Dice: 0.8336) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 18/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.15it/s, loss=0.0954]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0846\n",
      "Val Dice - Class 1: 0.8441, Class 2: 0.8247, Avg: 0.8344\n",
      "Learning Rate: 0.000500\n",
      "✓ 保存最佳模型 (Dice: 0.8344) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 19/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.88it/s, loss=0.0842]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0840\n",
      "Val Dice - Class 1: 0.8414, Class 2: 0.8183, Avg: 0.8299\n",
      "Learning Rate: 0.000500\n",
      "\n",
      "Epoch 20/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 33.07it/s, loss=0.0814]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0829\n",
      "Val Dice - Class 1: 0.8421, Class 2: 0.8304, Avg: 0.8363\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8363) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 21/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.46it/s, loss=0.0545]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0822\n",
      "Val Dice - Class 1: 0.8485, Class 2: 0.8302, Avg: 0.8394\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8394) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 22/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.95it/s, loss=0.0890]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0802\n",
      "Val Dice - Class 1: 0.8500, Class 2: 0.8312, Avg: 0.8406\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8406) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 23/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.10it/s, loss=0.0727]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0788\n",
      "Val Dice - Class 1: 0.8522, Class 2: 0.8319, Avg: 0.8421\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8421) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 24/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.80it/s, loss=0.0785]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0794\n",
      "Val Dice - Class 1: 0.8461, Class 2: 0.8333, Avg: 0.8397\n",
      "Learning Rate: 0.000250\n",
      "\n",
      "Epoch 25/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 32.27it/s, loss=0.0814]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0788\n",
      "Val Dice - Class 1: 0.8473, Class 2: 0.8378, Avg: 0.8425\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8425) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 26/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.75it/s, loss=0.0944]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0800\n",
      "Val Dice - Class 1: 0.8395, Class 2: 0.8173, Avg: 0.8284\n",
      "Learning Rate: 0.000250\n",
      "\n",
      "Epoch 27/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.59it/s, loss=0.0681]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0790\n",
      "Val Dice - Class 1: 0.8515, Class 2: 0.8339, Avg: 0.8427\n",
      "Learning Rate: 0.000250\n",
      "✓ 保存最佳模型 (Dice: 0.8427) -> /workspace/outputs/pure_unet_best.pth\n",
      "\n",
      "Epoch 28/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.63it/s, loss=0.0790]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0781\n",
      "Val Dice - Class 1: 0.8521, Class 2: 0.8295, Avg: 0.8408\n",
      "Learning Rate: 0.000250\n",
      "\n",
      "Epoch 29/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.60it/s, loss=0.0619]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0787\n",
      "Val Dice - Class 1: 0.8498, Class 2: 0.8351, Avg: 0.8424\n",
      "Learning Rate: 0.000250\n",
      "\n",
      "Epoch 30/30\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:03<00:00, 31.48it/s, loss=0.0616]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0781\n",
      "Val Dice - Class 1: 0.8457, Class 2: 0.8304, Avg: 0.8380\n",
      "Learning Rate: 0.000125\n",
      "\n",
      "============================================================\n",
      "訓練完成！\n",
      "最佳驗證 Dice: 0.8427\n",
      "模型已保存至: /workspace/outputs/pure_unet_best.pth\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "純粹的 3D U-Net 實現（修正版）\n",
    "- 自動檢測數據路徑\n",
    "- 移除深度監督\n",
    "- 移除 Focal Loss\n",
    "- 移除 EMA\n",
    "- 使用最基礎的配置\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ==================== 設置隨機種子 ====================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ==================== 純粹的 3D U-Net 模型 ====================\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"基礎卷積塊\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PureUNet3D(nn.Module):\n",
    "    \"\"\"純粹的 3D U-Net（沒有深度監督）\"\"\"\n",
    "    def __init__(self, in_channels=1, num_classes=3, base_channels=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 編碼器\n",
    "        self.enc1 = ConvBlock(in_channels, base_channels)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        \n",
    "        self.enc2 = ConvBlock(base_channels, base_channels * 2)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        \n",
    "        self.enc3 = ConvBlock(base_channels * 2, base_channels * 4)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        \n",
    "        # 瓶頸層\n",
    "        self.bottleneck = ConvBlock(base_channels * 4, base_channels * 8)\n",
    "        \n",
    "        # 解碼器\n",
    "        self.upconv3 = nn.ConvTranspose3d(base_channels * 8, base_channels * 4, \n",
    "                                          kernel_size=2, stride=2)\n",
    "        self.dec3 = ConvBlock(base_channels * 8, base_channels * 4)\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose3d(base_channels * 4, base_channels * 2, \n",
    "                                          kernel_size=2, stride=2)\n",
    "        self.dec2 = ConvBlock(base_channels * 4, base_channels * 2)\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose3d(base_channels * 2, base_channels, \n",
    "                                          kernel_size=2, stride=2)\n",
    "        self.dec1 = ConvBlock(base_channels * 2, base_channels)\n",
    "        \n",
    "        # 輸出層\n",
    "        self.out = nn.Conv3d(base_channels, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 編碼路徑\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        \n",
    "        # 瓶頸\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "        \n",
    "        # 解碼路徑\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        \n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        \n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        \n",
    "        # 輸出\n",
    "        out = self.out(d1)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ==================== Dice Loss（簡化版）====================\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"簡單的 Dice Loss\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        \n",
    "        # 計算每個類別的 Dice\n",
    "        dice_scores = []\n",
    "        for c in range(pred.shape[1]):\n",
    "            pred_c = pred[:, c]\n",
    "            target_c = (target == c).float()\n",
    "            \n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            union = pred_c.sum() + target_c.sum()\n",
    "            \n",
    "            dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        return 1.0 - torch.stack(dice_scores).mean()\n",
    "\n",
    "\n",
    "# ==================== 數據集 ====================\n",
    "\n",
    "class HippocampusDataset(Dataset):\n",
    "    \"\"\"海馬體數據集\"\"\"\n",
    "    def __init__(self, data_dir, target_size=64, is_train=True):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.target_size = target_size\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # 獲取所有圖像文件（過濾掉 macOS 隱藏文件）\n",
    "        all_image_files = list((self.data_dir / 'imagesTr').glob('*.nii.gz'))\n",
    "        self.image_files = sorted([f for f in all_image_files if not f.name.startswith('._')])\n",
    "        \n",
    "        all_label_files = list((self.data_dir / 'labelsTr').glob('*.nii.gz'))\n",
    "        self.label_files = sorted([f for f in all_label_files if not f.name.startswith('._')])\n",
    "        \n",
    "        if len(self.image_files) == 0:\n",
    "            raise ValueError(f\"在 {self.data_dir / 'imagesTr'} 找不到任何 .nii.gz 文件！\")\n",
    "        \n",
    "        print(f\"找到 {len(self.image_files)} 個訓練樣本\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        \"\"\"預處理\"\"\"\n",
    "        # Percentile clipping\n",
    "        p1, p99 = np.percentile(image, [1, 99])\n",
    "        image = np.clip(image, p1, p99)\n",
    "        \n",
    "        # Z-score normalization\n",
    "        mean, std = image.mean(), image.std()\n",
    "        image = (image - mean) / (std + 1e-8)\n",
    "        return image\n",
    "    \n",
    "    def augment(self, image, label):\n",
    "        \"\"\"簡單的數據增強\"\"\"\n",
    "        # 隨機翻轉\n",
    "        if random.random() > 0.5:\n",
    "            axis = random.choice([0, 1, 2])\n",
    "            image = np.flip(image, axis).copy()\n",
    "            label = np.flip(label, axis).copy()\n",
    "        \n",
    "        # 隨機旋轉 90 度\n",
    "        if random.random() > 0.5:\n",
    "            k = random.randint(1, 3)\n",
    "            axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "            image = np.rot90(image, k, axes).copy()\n",
    "            label = np.rot90(label, k, axes).copy()\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 讀取文件\n",
    "        image = nib.load(self.image_files[idx]).get_fdata(dtype=np.float32)\n",
    "        label = nib.load(self.label_files[idx]).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        # 預處理\n",
    "        image = self.preprocess(image)\n",
    "        \n",
    "        # 數據增強（僅訓練時）\n",
    "        if self.is_train:\n",
    "            image, label = self.augment(image, label)\n",
    "        \n",
    "        # 轉為 tensor 並調整大小\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # [1, H, W, D]\n",
    "        label = torch.from_numpy(label).unsqueeze(0)  # [1, H, W, D]\n",
    "        \n",
    "        image = F.interpolate(\n",
    "            image.unsqueeze(0),\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='trilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        label = F.interpolate(\n",
    "            label.unsqueeze(0),\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='nearest'\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        label = label.squeeze(0).long()\n",
    "        label = torch.clamp(label, 0, 2)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ==================== 評估指標 ====================\n",
    "\n",
    "def compute_dice(pred, target, num_classes=3):\n",
    "    \"\"\"計算 Dice 分數\"\"\"\n",
    "    dice_scores = []\n",
    "    \n",
    "    for c in range(1, num_classes):  # 跳過背景\n",
    "        pred_c = (pred == c)\n",
    "        target_c = (target == c)\n",
    "        \n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = pred_c.sum().float() + target_c.sum().float()\n",
    "        \n",
    "        if union == 0:\n",
    "            dice = 1.0 if intersection == 0 else 0.0\n",
    "        else:\n",
    "            dice = (2.0 * intersection) / union\n",
    "        \n",
    "        dice_scores.append(dice.item())\n",
    "    \n",
    "    return dice_scores\n",
    "\n",
    "\n",
    "# ==================== 訓練函數 ====================\n",
    "\n",
    "def train_epoch(model, loader, criterion_ce, criterion_dice, optimizer, device):\n",
    "    \"\"\"訓練一個 epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向傳播\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 計算損失（簡單的 CE + Dice）\n",
    "        loss_ce = criterion_ce(outputs, labels)\n",
    "        loss_dice = criterion_dice(outputs, labels)\n",
    "        loss = 0.5 * loss_ce + 0.5 * loss_dice\n",
    "        \n",
    "        # 反向傳播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    \"\"\"驗證\"\"\"\n",
    "    model.eval()\n",
    "    all_dice_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            # 計算 Dice\n",
    "            for pred, label in zip(preds, labels):\n",
    "                dice_scores = compute_dice(pred.cpu(), label.cpu())\n",
    "                all_dice_scores.append(dice_scores)\n",
    "    \n",
    "    # 平均 Dice\n",
    "    all_dice_scores = np.array(all_dice_scores)\n",
    "    mean_dice = all_dice_scores.mean(axis=0)\n",
    "    \n",
    "    return mean_dice\n",
    "\n",
    "\n",
    "# ==================== 自動檢測數據路徑 ====================\n",
    "\n",
    "def find_data_directory():\n",
    "    \"\"\"自動查找數據目錄\"\"\"\n",
    "    possible_paths = [\n",
    "        '/home/claude/Task04_Hippocampus',\n",
    "        '/workspace/data/Task04_Hippocampus',\n",
    "        './Task04_Hippocampus',\n",
    "        './data/Task04_Hippocampus',\n",
    "        '../data/Task04_Hippocampus',\n",
    "        '/data/Task04_Hippocampus',\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if Path(path).exists():\n",
    "            images_dir = Path(path) / 'imagesTr'\n",
    "            if images_dir.exists():\n",
    "                # 過濾掉 macOS 隱藏文件\n",
    "                image_files = [f for f in images_dir.glob('*.nii.gz') if not f.name.startswith('._')]\n",
    "                if len(image_files) > 0:\n",
    "                    print(f\"✓ 找到數據目錄: {path}\")\n",
    "                    print(f\"  ({len(image_files)} 個有效文件)\")\n",
    "                    return path\n",
    "    \n",
    "    # 如果都找不到，列出當前目錄\n",
    "    print(\"\\n❌ 找不到數據目錄！\")\n",
    "    print(\"\\n當前目錄內容:\")\n",
    "    for item in Path('.').iterdir():\n",
    "        print(f\"  - {item}\")\n",
    "    \n",
    "    print(\"\\n請確保數據在以下位置之一:\")\n",
    "    for path in possible_paths:\n",
    "        print(f\"  - {path}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# ==================== 主訓練流程 ====================\n",
    "\n",
    "def main():\n",
    "    # 自動查找數據目錄\n",
    "    data_dir = find_data_directory()\n",
    "    \n",
    "    if data_dir is None:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"錯誤：找不到數據集！\")\n",
    "        print(\"=\" * 60)\n",
    "        print(\"\\n解決方案:\")\n",
    "        print(\"1. 下載 Hippocampus 數據集\")\n",
    "        print(\"2. 解壓到以下任一位置:\")\n",
    "        print(\"   - /workspace/data/Task04_Hippocampus\")\n",
    "        print(\"   - ./data/Task04_Hippocampus\")\n",
    "        print(\"   - ./Task04_Hippocampus\")\n",
    "        print(\"\\n數據集結構應該是:\")\n",
    "        print(\"Task04_Hippocampus/\")\n",
    "        print(\"├── imagesTr/\")\n",
    "        print(\"│   ├── hippocampus_001.nii.gz\")\n",
    "        print(\"│   ├── hippocampus_002.nii.gz\")\n",
    "        print(\"│   └── ...\")\n",
    "        print(\"└── labelsTr/\")\n",
    "        print(\"    ├── hippocampus_001.nii.gz\")\n",
    "        print(\"    ├── hippocampus_002.nii.gz\")\n",
    "        print(\"    └── ...\")\n",
    "        print(\"=\" * 60)\n",
    "        return\n",
    "    \n",
    "    # 配置\n",
    "    config = {\n",
    "        'data_dir': data_dir,\n",
    "        'batch_size': 2,\n",
    "        'num_epochs': 30,\n",
    "        'lr': 1e-3,\n",
    "        'base_channels': 16,\n",
    "        'target_size': 64,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"純粹的 3D U-Net 訓練\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"配置:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "    \n",
    "    device = torch.device(config['device'])\n",
    "    \n",
    "    # 創建數據集\n",
    "    print(\"準備數據集...\")\n",
    "    try:\n",
    "        train_dataset = HippocampusDataset(\n",
    "            config['data_dir'],\n",
    "            target_size=config['target_size'],\n",
    "            is_train=True\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n錯誤: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 簡單的訓練/驗證劃分 (80/20)\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"訓練集: {len(train_dataset)} 樣本\")\n",
    "    print(f\"驗證集: {len(val_dataset)} 樣本\")\n",
    "    print()\n",
    "    \n",
    "    # 創建模型\n",
    "    print(\"創建模型...\")\n",
    "    model = PureUNet3D(\n",
    "        in_channels=1,\n",
    "        num_classes=3,\n",
    "        base_channels=config['base_channels']\n",
    "    ).to(device)\n",
    "    \n",
    "    # 計算參數量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型參數量: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
    "    print()\n",
    "    \n",
    "    # 損失函數和優化器\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    criterion_dice = DiceLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    \n",
    "    # 簡單的學習率衰減\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=10, \n",
    "        gamma=0.5\n",
    "    )\n",
    "    \n",
    "    # 訓練循環\n",
    "    print(\"開始訓練...\")\n",
    "    print()\n",
    "    \n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # 訓練\n",
    "        train_loss = train_epoch(\n",
    "            model, train_loader, criterion_ce, criterion_dice, \n",
    "            optimizer, device\n",
    "        )\n",
    "        \n",
    "        # 驗證\n",
    "        val_dice = validate(model, val_loader, device)\n",
    "        \n",
    "        # 學習率衰減\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # 打印結果\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Dice - Class 1: {val_dice[0]:.4f}, Class 2: {val_dice[1]:.4f}, \"\n",
    "              f\"Avg: {val_dice.mean():.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_dice.mean() > best_dice:\n",
    "            best_dice = val_dice.mean()\n",
    "            \n",
    "            # 確保輸出目錄存在\n",
    "            output_dir = Path('/workspace/outputs')\n",
    "            if not output_dir.exists():\n",
    "                output_dir = Path('./outputs')\n",
    "                output_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            save_path = output_dir / 'pure_unet_best.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'dice': val_dice,\n",
    "                'config': config\n",
    "            }, save_path)\n",
    "            print(f\"✓ 保存最佳模型 (Dice: {best_dice:.4f}) -> {save_path}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"訓練完成！\")\n",
    "    print(f\"最佳驗證 Dice: {best_dice:.4f}\")\n",
    "    print(f\"模型已保存至: {save_path}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "57181df4-e879-4de9-9f41-aa2ee58299d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 找到數據目錄: ./Task04_Hippocampus\n",
      "  (260 個有效文件)\n",
      "\n",
      "============================================================\n",
      "完整的 nnU-Net 訓練\n",
      "============================================================\n",
      "配置:\n",
      "  data_dir: ./Task04_Hippocampus\n",
      "  batch_size: 2\n",
      "  num_epochs: 100\n",
      "  initial_lr: 0.01\n",
      "  base_channels: 32\n",
      "  num_pool: 3\n",
      "  target_size: 64\n",
      "  deep_supervision: True\n",
      "  use_augmentation: True\n",
      "  device: cuda\n",
      "\n",
      "SciPy 可用: True\n",
      "\n",
      "準備數據集...\n",
      "找到 260 個訓練樣本\n",
      "訓練集: 208 樣本\n",
      "驗證集: 52 樣本\n",
      "\n",
      "創建 nnU-Net 模型...\n",
      "模型參數量: 6,271,980 (6.27M)\n",
      "\n",
      "開始訓練...\n",
      "使用深度監督: True\n",
      "使用數據增強: True\n",
      "\n",
      "Epoch 1/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.32it/s, loss=0.4146]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6857\n",
      "Val Dice - Class 1: 0.6209, Class 2: 0.6890, Avg: 0.6549\n",
      "Learning Rate: 0.009910\n",
      "✓ 保存最佳模型 (Dice: 0.6549) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 2/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.10it/s, loss=0.2751]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3103\n",
      "Val Dice - Class 1: 0.7304, Class 2: 0.7598, Avg: 0.7451\n",
      "Learning Rate: 0.009820\n",
      "✓ 保存最佳模型 (Dice: 0.7451) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 3/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.04it/s, loss=0.2592]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2503\n",
      "Val Dice - Class 1: 0.7698, Class 2: 0.7791, Avg: 0.7745\n",
      "Learning Rate: 0.009730\n",
      "✓ 保存最佳模型 (Dice: 0.7745) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 4/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.36it/s, loss=0.2159]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2270\n",
      "Val Dice - Class 1: 0.7947, Class 2: 0.7938, Avg: 0.7942\n",
      "Learning Rate: 0.009639\n",
      "✓ 保存最佳模型 (Dice: 0.7942) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 5/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.80it/s, loss=0.1724]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2143\n",
      "Val Dice - Class 1: 0.7947, Class 2: 0.7970, Avg: 0.7959\n",
      "Learning Rate: 0.009549\n",
      "✓ 保存最佳模型 (Dice: 0.7959) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 6/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.98it/s, loss=0.2008]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2040\n",
      "Val Dice - Class 1: 0.8088, Class 2: 0.7982, Avg: 0.8035\n",
      "Learning Rate: 0.009458\n",
      "✓ 保存最佳模型 (Dice: 0.8035) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 7/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.26it/s, loss=0.1725]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1973\n",
      "Val Dice - Class 1: 0.8149, Class 2: 0.8051, Avg: 0.8100\n",
      "Learning Rate: 0.009368\n",
      "✓ 保存最佳模型 (Dice: 0.8100) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 8/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.00it/s, loss=0.2426]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1978\n",
      "Val Dice - Class 1: 0.8212, Class 2: 0.8132, Avg: 0.8172\n",
      "Learning Rate: 0.009277\n",
      "✓ 保存最佳模型 (Dice: 0.8172) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 9/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.02it/s, loss=0.1516]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1893\n",
      "Val Dice - Class 1: 0.8189, Class 2: 0.8140, Avg: 0.8165\n",
      "Learning Rate: 0.009186\n",
      "\n",
      "Epoch 10/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.05it/s, loss=0.1726]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1846\n",
      "Val Dice - Class 1: 0.8244, Class 2: 0.8150, Avg: 0.8197\n",
      "Learning Rate: 0.009095\n",
      "✓ 保存最佳模型 (Dice: 0.8197) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 11/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.96it/s, loss=0.1821]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1814\n",
      "Val Dice - Class 1: 0.8288, Class 2: 0.8192, Avg: 0.8240\n",
      "Learning Rate: 0.009004\n",
      "✓ 保存最佳模型 (Dice: 0.8240) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 12/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.16it/s, loss=0.2224]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1811\n",
      "Val Dice - Class 1: 0.8264, Class 2: 0.8224, Avg: 0.8244\n",
      "Learning Rate: 0.008913\n",
      "✓ 保存最佳模型 (Dice: 0.8244) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 13/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.04it/s, loss=0.1965]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1771\n",
      "Val Dice - Class 1: 0.8279, Class 2: 0.8143, Avg: 0.8211\n",
      "Learning Rate: 0.008822\n",
      "\n",
      "Epoch 14/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.92it/s, loss=0.2030]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1742\n",
      "Val Dice - Class 1: 0.8345, Class 2: 0.8236, Avg: 0.8291\n",
      "Learning Rate: 0.008731\n",
      "✓ 保存最佳模型 (Dice: 0.8291) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 15/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.75it/s, loss=0.2407]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1748\n",
      "Val Dice - Class 1: 0.8323, Class 2: 0.8258, Avg: 0.8291\n",
      "Learning Rate: 0.008639\n",
      "✓ 保存最佳模型 (Dice: 0.8291) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 16/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.77it/s, loss=0.1472]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1735\n",
      "Val Dice - Class 1: 0.8361, Class 2: 0.8200, Avg: 0.8280\n",
      "Learning Rate: 0.008548\n",
      "\n",
      "Epoch 17/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.26it/s, loss=0.1576]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1712\n",
      "Val Dice - Class 1: 0.8350, Class 2: 0.8208, Avg: 0.8279\n",
      "Learning Rate: 0.008456\n",
      "\n",
      "Epoch 18/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.35it/s, loss=0.1474]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1716\n",
      "Val Dice - Class 1: 0.8368, Class 2: 0.8222, Avg: 0.8295\n",
      "Learning Rate: 0.008364\n",
      "✓ 保存最佳模型 (Dice: 0.8295) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 19/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.08it/s, loss=0.1765]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1670\n",
      "Val Dice - Class 1: 0.8444, Class 2: 0.8275, Avg: 0.8360\n",
      "Learning Rate: 0.008272\n",
      "✓ 保存最佳模型 (Dice: 0.8360) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 20/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.15it/s, loss=0.1579]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1681\n",
      "Val Dice - Class 1: 0.8478, Class 2: 0.8264, Avg: 0.8371\n",
      "Learning Rate: 0.008181\n",
      "✓ 保存最佳模型 (Dice: 0.8371) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 21/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.94it/s, loss=0.1647]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1652\n",
      "Val Dice - Class 1: 0.8454, Class 2: 0.8291, Avg: 0.8373\n",
      "Learning Rate: 0.008088\n",
      "✓ 保存最佳模型 (Dice: 0.8373) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 22/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.24it/s, loss=0.1386]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1638\n",
      "Val Dice - Class 1: 0.8425, Class 2: 0.8311, Avg: 0.8368\n",
      "Learning Rate: 0.007996\n",
      "\n",
      "Epoch 23/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.26it/s, loss=0.1782]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1660\n",
      "Val Dice - Class 1: 0.8401, Class 2: 0.8116, Avg: 0.8258\n",
      "Learning Rate: 0.007904\n",
      "\n",
      "Epoch 24/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.07it/s, loss=0.1542]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1645\n",
      "Val Dice - Class 1: 0.8443, Class 2: 0.8306, Avg: 0.8375\n",
      "Learning Rate: 0.007811\n",
      "✓ 保存最佳模型 (Dice: 0.8375) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 25/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.00it/s, loss=0.1252]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1614\n",
      "Val Dice - Class 1: 0.8459, Class 2: 0.8310, Avg: 0.8385\n",
      "Learning Rate: 0.007719\n",
      "✓ 保存最佳模型 (Dice: 0.8385) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 26/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.94it/s, loss=0.1834]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1612\n",
      "Val Dice - Class 1: 0.8481, Class 2: 0.8314, Avg: 0.8398\n",
      "Learning Rate: 0.007626\n",
      "✓ 保存最佳模型 (Dice: 0.8398) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 27/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.14it/s, loss=0.1442]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1603\n",
      "Val Dice - Class 1: 0.8492, Class 2: 0.8307, Avg: 0.8400\n",
      "Learning Rate: 0.007533\n",
      "✓ 保存最佳模型 (Dice: 0.8400) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 28/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.29it/s, loss=0.1483]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1601\n",
      "Val Dice - Class 1: 0.8448, Class 2: 0.8294, Avg: 0.8371\n",
      "Learning Rate: 0.007440\n",
      "\n",
      "Epoch 29/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.79it/s, loss=0.2072]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1596\n",
      "Val Dice - Class 1: 0.8522, Class 2: 0.8333, Avg: 0.8428\n",
      "Learning Rate: 0.007347\n",
      "✓ 保存最佳模型 (Dice: 0.8428) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 30/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.06it/s, loss=0.1859]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1580\n",
      "Val Dice - Class 1: 0.8488, Class 2: 0.8340, Avg: 0.8414\n",
      "Learning Rate: 0.007254\n",
      "\n",
      "Epoch 31/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.00it/s, loss=0.1590]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1580\n",
      "Val Dice - Class 1: 0.8451, Class 2: 0.8334, Avg: 0.8392\n",
      "Learning Rate: 0.007161\n",
      "\n",
      "Epoch 32/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.96it/s, loss=0.1449]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1546\n",
      "Val Dice - Class 1: 0.8488, Class 2: 0.8361, Avg: 0.8425\n",
      "Learning Rate: 0.007067\n",
      "\n",
      "Epoch 33/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.09it/s, loss=0.1603]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1556\n",
      "Val Dice - Class 1: 0.8513, Class 2: 0.8245, Avg: 0.8379\n",
      "Learning Rate: 0.006974\n",
      "\n",
      "Epoch 34/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.87it/s, loss=0.1641]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1559\n",
      "Val Dice - Class 1: 0.8461, Class 2: 0.8340, Avg: 0.8401\n",
      "Learning Rate: 0.006880\n",
      "\n",
      "Epoch 35/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.07it/s, loss=0.1296]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1549\n",
      "Val Dice - Class 1: 0.8479, Class 2: 0.8298, Avg: 0.8389\n",
      "Learning Rate: 0.006786\n",
      "\n",
      "Epoch 36/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.03it/s, loss=0.2202]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1539\n",
      "Val Dice - Class 1: 0.8507, Class 2: 0.8348, Avg: 0.8428\n",
      "Learning Rate: 0.006692\n",
      "\n",
      "Epoch 37/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.25it/s, loss=0.1766]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1522\n",
      "Val Dice - Class 1: 0.8551, Class 2: 0.8332, Avg: 0.8442\n",
      "Learning Rate: 0.006598\n",
      "✓ 保存最佳模型 (Dice: 0.8442) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 38/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.98it/s, loss=0.1441]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1537\n",
      "Val Dice - Class 1: 0.8523, Class 2: 0.8354, Avg: 0.8438\n",
      "Learning Rate: 0.006504\n",
      "\n",
      "Epoch 39/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.20it/s, loss=0.1755]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1539\n",
      "Val Dice - Class 1: 0.8567, Class 2: 0.8417, Avg: 0.8492\n",
      "Learning Rate: 0.006409\n",
      "✓ 保存最佳模型 (Dice: 0.8492) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 40/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.18it/s, loss=0.1352]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1536\n",
      "Val Dice - Class 1: 0.8543, Class 2: 0.8372, Avg: 0.8457\n",
      "Learning Rate: 0.006314\n",
      "\n",
      "Epoch 41/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.82it/s, loss=0.1327]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1513\n",
      "Val Dice - Class 1: 0.8543, Class 2: 0.8347, Avg: 0.8445\n",
      "Learning Rate: 0.006220\n",
      "\n",
      "Epoch 42/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.32it/s, loss=0.1674]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1514\n",
      "Val Dice - Class 1: 0.8550, Class 2: 0.8339, Avg: 0.8444\n",
      "Learning Rate: 0.006125\n",
      "\n",
      "Epoch 43/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.43it/s, loss=0.1328]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1482\n",
      "Val Dice - Class 1: 0.8548, Class 2: 0.8403, Avg: 0.8475\n",
      "Learning Rate: 0.006030\n",
      "\n",
      "Epoch 44/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.85it/s, loss=0.1863]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1483\n",
      "Val Dice - Class 1: 0.8525, Class 2: 0.8332, Avg: 0.8429\n",
      "Learning Rate: 0.005934\n",
      "\n",
      "Epoch 45/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.22it/s, loss=0.1644]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1530\n",
      "Val Dice - Class 1: 0.8588, Class 2: 0.8406, Avg: 0.8497\n",
      "Learning Rate: 0.005839\n",
      "✓ 保存最佳模型 (Dice: 0.8497) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 46/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.24it/s, loss=0.1548]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1492\n",
      "Val Dice - Class 1: 0.8523, Class 2: 0.8349, Avg: 0.8436\n",
      "Learning Rate: 0.005743\n",
      "\n",
      "Epoch 47/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.38it/s, loss=0.1297]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1490\n",
      "Val Dice - Class 1: 0.8564, Class 2: 0.8418, Avg: 0.8491\n",
      "Learning Rate: 0.005647\n",
      "\n",
      "Epoch 48/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.35it/s, loss=0.1354]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1483\n",
      "Val Dice - Class 1: 0.8607, Class 2: 0.8427, Avg: 0.8517\n",
      "Learning Rate: 0.005551\n",
      "✓ 保存最佳模型 (Dice: 0.8517) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 49/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.44it/s, loss=0.1453]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1478\n",
      "Val Dice - Class 1: 0.8569, Class 2: 0.8390, Avg: 0.8480\n",
      "Learning Rate: 0.005455\n",
      "\n",
      "Epoch 50/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.57it/s, loss=0.1586]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1470\n",
      "Val Dice - Class 1: 0.8583, Class 2: 0.8379, Avg: 0.8481\n",
      "Learning Rate: 0.005359\n",
      "\n",
      "Epoch 51/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.53it/s, loss=0.1603]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1463\n",
      "Val Dice - Class 1: 0.8585, Class 2: 0.8399, Avg: 0.8492\n",
      "Learning Rate: 0.005262\n",
      "\n",
      "Epoch 52/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.33it/s, loss=0.1127]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1447\n",
      "Val Dice - Class 1: 0.8538, Class 2: 0.8376, Avg: 0.8457\n",
      "Learning Rate: 0.005166\n",
      "\n",
      "Epoch 53/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.99it/s, loss=0.1734]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1477\n",
      "Val Dice - Class 1: 0.8584, Class 2: 0.8367, Avg: 0.8476\n",
      "Learning Rate: 0.005069\n",
      "\n",
      "Epoch 54/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.32it/s, loss=0.1253]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1459\n",
      "Val Dice - Class 1: 0.8600, Class 2: 0.8421, Avg: 0.8511\n",
      "Learning Rate: 0.004971\n",
      "\n",
      "Epoch 55/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.35it/s, loss=0.1218]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1436\n",
      "Val Dice - Class 1: 0.8606, Class 2: 0.8416, Avg: 0.8511\n",
      "Learning Rate: 0.004874\n",
      "\n",
      "Epoch 56/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.42it/s, loss=0.1137]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1451\n",
      "Val Dice - Class 1: 0.8624, Class 2: 0.8420, Avg: 0.8522\n",
      "Learning Rate: 0.004776\n",
      "✓ 保存最佳模型 (Dice: 0.8522) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 57/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.56it/s, loss=0.1239]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1435\n",
      "Val Dice - Class 1: 0.8620, Class 2: 0.8462, Avg: 0.8541\n",
      "Learning Rate: 0.004679\n",
      "✓ 保存最佳模型 (Dice: 0.8541) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 58/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.44it/s, loss=0.1559]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1428\n",
      "Val Dice - Class 1: 0.8613, Class 2: 0.8456, Avg: 0.8534\n",
      "Learning Rate: 0.004581\n",
      "\n",
      "Epoch 59/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.52it/s, loss=0.1973]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1412\n",
      "Val Dice - Class 1: 0.8644, Class 2: 0.8429, Avg: 0.8537\n",
      "Learning Rate: 0.004482\n",
      "\n",
      "Epoch 60/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.39it/s, loss=0.1234]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1415\n",
      "Val Dice - Class 1: 0.8626, Class 2: 0.8445, Avg: 0.8536\n",
      "Learning Rate: 0.004384\n",
      "\n",
      "Epoch 61/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.23it/s, loss=0.1289]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1424\n",
      "Val Dice - Class 1: 0.8638, Class 2: 0.8433, Avg: 0.8536\n",
      "Learning Rate: 0.004285\n",
      "\n",
      "Epoch 62/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.59it/s, loss=0.1293]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1417\n",
      "Val Dice - Class 1: 0.8601, Class 2: 0.8406, Avg: 0.8503\n",
      "Learning Rate: 0.004186\n",
      "\n",
      "Epoch 63/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:07<00:00, 13.11it/s, loss=0.1834]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1413\n",
      "Val Dice - Class 1: 0.8624, Class 2: 0.8444, Avg: 0.8534\n",
      "Learning Rate: 0.004087\n",
      "\n",
      "Epoch 64/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.51it/s, loss=0.2080]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1429\n",
      "Val Dice - Class 1: 0.8612, Class 2: 0.8396, Avg: 0.8504\n",
      "Learning Rate: 0.003987\n",
      "\n",
      "Epoch 65/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.43it/s, loss=0.1526]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1417\n",
      "Val Dice - Class 1: 0.8628, Class 2: 0.8398, Avg: 0.8513\n",
      "Learning Rate: 0.003887\n",
      "\n",
      "Epoch 66/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.21it/s, loss=0.1415]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1399\n",
      "Val Dice - Class 1: 0.8626, Class 2: 0.8468, Avg: 0.8547\n",
      "Learning Rate: 0.003787\n",
      "✓ 保存最佳模型 (Dice: 0.8547) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 67/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.23it/s, loss=0.1230]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1408\n",
      "Val Dice - Class 1: 0.8664, Class 2: 0.8456, Avg: 0.8560\n",
      "Learning Rate: 0.003687\n",
      "✓ 保存最佳模型 (Dice: 0.8560) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 68/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.07it/s, loss=0.1630]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1390\n",
      "Val Dice - Class 1: 0.8612, Class 2: 0.8405, Avg: 0.8509\n",
      "Learning Rate: 0.003586\n",
      "\n",
      "Epoch 69/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.03it/s, loss=0.1194]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1395\n",
      "Val Dice - Class 1: 0.8620, Class 2: 0.8405, Avg: 0.8513\n",
      "Learning Rate: 0.003485\n",
      "\n",
      "Epoch 70/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.48it/s, loss=0.1557]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1381\n",
      "Val Dice - Class 1: 0.8627, Class 2: 0.8463, Avg: 0.8545\n",
      "Learning Rate: 0.003384\n",
      "\n",
      "Epoch 71/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.42it/s, loss=0.1368]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1368\n",
      "Val Dice - Class 1: 0.8638, Class 2: 0.8444, Avg: 0.8541\n",
      "Learning Rate: 0.003282\n",
      "\n",
      "Epoch 72/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.18it/s, loss=0.1579]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1357\n",
      "Val Dice - Class 1: 0.8651, Class 2: 0.8460, Avg: 0.8555\n",
      "Learning Rate: 0.003180\n",
      "\n",
      "Epoch 73/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:07<00:00, 13.03it/s, loss=0.1581]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1381\n",
      "Val Dice - Class 1: 0.8636, Class 2: 0.8458, Avg: 0.8547\n",
      "Learning Rate: 0.003078\n",
      "\n",
      "Epoch 74/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.19it/s, loss=0.1365]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1360\n",
      "Val Dice - Class 1: 0.8617, Class 2: 0.8452, Avg: 0.8534\n",
      "Learning Rate: 0.002975\n",
      "\n",
      "Epoch 75/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.46it/s, loss=0.1247]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1350\n",
      "Val Dice - Class 1: 0.8646, Class 2: 0.8478, Avg: 0.8562\n",
      "Learning Rate: 0.002872\n",
      "✓ 保存最佳模型 (Dice: 0.8562) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 76/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.42it/s, loss=0.1273]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1361\n",
      "Val Dice - Class 1: 0.8615, Class 2: 0.8451, Avg: 0.8533\n",
      "Learning Rate: 0.002768\n",
      "\n",
      "Epoch 77/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.17it/s, loss=0.1342]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1347\n",
      "Val Dice - Class 1: 0.8652, Class 2: 0.8408, Avg: 0.8530\n",
      "Learning Rate: 0.002664\n",
      "\n",
      "Epoch 78/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.46it/s, loss=0.1157]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1357\n",
      "Val Dice - Class 1: 0.8638, Class 2: 0.8475, Avg: 0.8556\n",
      "Learning Rate: 0.002560\n",
      "\n",
      "Epoch 79/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.75it/s, loss=0.1491]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1337\n",
      "Val Dice - Class 1: 0.8668, Class 2: 0.8490, Avg: 0.8579\n",
      "Learning Rate: 0.002455\n",
      "✓ 保存最佳模型 (Dice: 0.8579) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 80/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.32it/s, loss=0.1278]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1342\n",
      "Val Dice - Class 1: 0.8679, Class 2: 0.8488, Avg: 0.8584\n",
      "Learning Rate: 0.002349\n",
      "✓ 保存最佳模型 (Dice: 0.8584) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 81/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.13it/s, loss=0.1451]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1341\n",
      "Val Dice - Class 1: 0.8659, Class 2: 0.8472, Avg: 0.8565\n",
      "Learning Rate: 0.002243\n",
      "\n",
      "Epoch 82/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.79it/s, loss=0.1194]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1325\n",
      "Val Dice - Class 1: 0.8651, Class 2: 0.8432, Avg: 0.8541\n",
      "Learning Rate: 0.002137\n",
      "\n",
      "Epoch 83/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.99it/s, loss=0.1404]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1324\n",
      "Val Dice - Class 1: 0.8659, Class 2: 0.8489, Avg: 0.8574\n",
      "Learning Rate: 0.002030\n",
      "\n",
      "Epoch 84/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.73it/s, loss=0.1334]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1311\n",
      "Val Dice - Class 1: 0.8688, Class 2: 0.8500, Avg: 0.8594\n",
      "Learning Rate: 0.001922\n",
      "✓ 保存最佳模型 (Dice: 0.8594) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 85/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.40it/s, loss=0.1167]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1309\n",
      "Val Dice - Class 1: 0.8692, Class 2: 0.8497, Avg: 0.8595\n",
      "Learning Rate: 0.001813\n",
      "✓ 保存最佳模型 (Dice: 0.8595) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 86/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.28it/s, loss=0.1140]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1288\n",
      "Val Dice - Class 1: 0.8654, Class 2: 0.8506, Avg: 0.8580\n",
      "Learning Rate: 0.001704\n",
      "\n",
      "Epoch 87/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.41it/s, loss=0.1443]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1308\n",
      "Val Dice - Class 1: 0.8685, Class 2: 0.8506, Avg: 0.8595\n",
      "Learning Rate: 0.001594\n",
      "✓ 保存最佳模型 (Dice: 0.8595) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 88/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.09it/s, loss=0.1125]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1293\n",
      "Val Dice - Class 1: 0.8678, Class 2: 0.8486, Avg: 0.8582\n",
      "Learning Rate: 0.001483\n",
      "\n",
      "Epoch 89/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.38it/s, loss=0.1265]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1303\n",
      "Val Dice - Class 1: 0.8683, Class 2: 0.8482, Avg: 0.8583\n",
      "Learning Rate: 0.001372\n",
      "\n",
      "Epoch 90/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.46it/s, loss=0.1469]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1293\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8496, Avg: 0.8601\n",
      "Learning Rate: 0.001259\n",
      "✓ 保存最佳模型 (Dice: 0.8601) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 91/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.15it/s, loss=0.1358]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1276\n",
      "Val Dice - Class 1: 0.8684, Class 2: 0.8505, Avg: 0.8594\n",
      "Learning Rate: 0.001145\n",
      "\n",
      "Epoch 92/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.81it/s, loss=0.1364]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1280\n",
      "Val Dice - Class 1: 0.8722, Class 2: 0.8537, Avg: 0.8629\n",
      "Learning Rate: 0.001030\n",
      "✓ 保存最佳模型 (Dice: 0.8629) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 93/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.07it/s, loss=0.1418]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1254\n",
      "Val Dice - Class 1: 0.8697, Class 2: 0.8510, Avg: 0.8603\n",
      "Learning Rate: 0.000913\n",
      "\n",
      "Epoch 94/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.11it/s, loss=0.1217]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1270\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8527, Avg: 0.8617\n",
      "Learning Rate: 0.000795\n",
      "\n",
      "Epoch 95/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.17it/s, loss=0.1147]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1270\n",
      "Val Dice - Class 1: 0.8697, Class 2: 0.8514, Avg: 0.8606\n",
      "Learning Rate: 0.000675\n",
      "\n",
      "Epoch 96/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.97it/s, loss=0.1824]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1283\n",
      "Val Dice - Class 1: 0.8695, Class 2: 0.8525, Avg: 0.8610\n",
      "Learning Rate: 0.000552\n",
      "\n",
      "Epoch 97/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.23it/s, loss=0.1218]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1248\n",
      "Val Dice - Class 1: 0.8723, Class 2: 0.8544, Avg: 0.8634\n",
      "Learning Rate: 0.000426\n",
      "✓ 保存最佳模型 (Dice: 0.8634) -> /workspace/outputs/nnunet_best.pth\n",
      "\n",
      "Epoch 98/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 11.96it/s, loss=0.1215]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1254\n",
      "Val Dice - Class 1: 0.8722, Class 2: 0.8529, Avg: 0.8626\n",
      "Learning Rate: 0.000296\n",
      "\n",
      "Epoch 99/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.22it/s, loss=0.1237]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1267\n",
      "Val Dice - Class 1: 0.8719, Class 2: 0.8530, Avg: 0.8625\n",
      "Learning Rate: 0.000158\n",
      "\n",
      "Epoch 100/100\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:08<00:00, 12.13it/s, loss=0.1153]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1253\n",
      "Val Dice - Class 1: 0.8691, Class 2: 0.8517, Avg: 0.8604\n",
      "Learning Rate: 0.000000\n",
      "\n",
      "============================================================\n",
      "訓練完成！\n",
      "最佳驗證 Dice: 0.8634\n",
      "模型已保存至: /workspace/outputs/nnunet_best.pth\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "完整的 nnU-Net 實現\n",
    "基於論文: nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation\n",
    "\n",
    "核心特性:\n",
    "- nnU-Net 架構（Leaky ReLU + Instance Norm）\n",
    "- 深度監督（Deep Supervision）\n",
    "- 數據增強（旋轉、縮放、彈性變形等）\n",
    "- Dice + CE 組合損失\n",
    "- Poly 學習率調度\n",
    "- 5-fold 交叉驗證（簡化版）\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 檢查 scipy 是否可用（不在這裡導入以避免版本衝突）\n",
    "SCIPY_AVAILABLE = False\n",
    "try:\n",
    "    import scipy\n",
    "    SCIPY_AVAILABLE = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not SCIPY_AVAILABLE:\n",
    "    print(\"警告: scipy 不可用，將使用簡化的數據增強\")\n",
    "\n",
    "# ==================== 設置隨機種子 ====================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# ==================== nnU-Net 架構組件 ====================\n",
    "\n",
    "class nnUNetConvBlock(nn.Module):\n",
    "    \"\"\"nnU-Net 卷積塊: Conv -> InstanceNorm -> LeakyReLU\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.norm = nn.InstanceNorm3d(out_channels, affine=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class nnUNetResidualBlock(nn.Module):\n",
    "    \"\"\"nnU-Net 的雙卷積塊（類殘差結構）\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nnUNetConvBlock(in_channels, out_channels)\n",
    "        self.conv2 = nnUNetConvBlock(out_channels, out_channels)\n",
    "        \n",
    "        # 如果通道數改變，需要 1x1 卷積調整\n",
    "        self.skip = None\n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.skip is not None:\n",
    "            residual = self.skip(residual)\n",
    "        \n",
    "        return out + residual\n",
    "\n",
    "\n",
    "class nnUNetDownsample(nn.Module):\n",
    "    \"\"\"nnU-Net 下採樣: Strided Convolution\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nnUNetConvBlock(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class nnUNetUpsample(nn.Module):\n",
    "    \"\"\"nnU-Net 上採樣: Transposed Convolution\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.upconv(x)\n",
    "\n",
    "\n",
    "class nnUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    完整的 nnU-Net 架構（3D）\n",
    "    - 使用 Instance Normalization\n",
    "    - 使用 Leaky ReLU\n",
    "    - 使用 Strided Convolution 下採樣\n",
    "    - 支持深度監督\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=1, num_classes=3, base_channels=32, num_pool=3, deep_supervision=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_pool = num_pool\n",
    "        self.deep_supervision = deep_supervision\n",
    "        \n",
    "        # 編碼器\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.downsamplers = nn.ModuleList()\n",
    "        \n",
    "        current_channels = in_channels\n",
    "        for i in range(num_pool + 1):\n",
    "            out_channels = base_channels * (2 ** i)\n",
    "            self.encoders.append(nnUNetResidualBlock(current_channels, out_channels))\n",
    "            \n",
    "            if i < num_pool:\n",
    "                self.downsamplers.append(nnUNetDownsample(out_channels, out_channels))\n",
    "            \n",
    "            current_channels = out_channels\n",
    "        \n",
    "        # 解碼器\n",
    "        self.upsamplers = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_pool):\n",
    "            in_ch = base_channels * (2 ** (num_pool - i))\n",
    "            out_ch = base_channels * (2 ** (num_pool - i - 1))\n",
    "            \n",
    "            self.upsamplers.append(nnUNetUpsample(in_ch, out_ch))\n",
    "            self.decoders.append(nnUNetResidualBlock(in_ch, out_ch))  # in_ch 因為有 skip connection\n",
    "        \n",
    "        # 輸出頭（多個用於深度監督）\n",
    "        self.seg_outputs = nn.ModuleList()\n",
    "        for i in range(num_pool + 1):\n",
    "            out_ch = base_channels * (2 ** i) if i == num_pool else base_channels * (2 ** i)\n",
    "            self.seg_outputs.append(nn.Conv3d(out_ch if i == 0 else base_channels * (2 ** i), num_classes, kernel_size=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 編碼路徑\n",
    "        encoder_outputs = []\n",
    "        current = x\n",
    "        \n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            current = encoder(current)\n",
    "            encoder_outputs.append(current)\n",
    "            \n",
    "            if i < self.num_pool:\n",
    "                current = self.downsamplers[i](current)\n",
    "        \n",
    "        # 解碼路徑\n",
    "        seg_outputs = []\n",
    "        \n",
    "        # 最深層的輸出（用於深度監督）\n",
    "        if self.deep_supervision:\n",
    "            seg_outputs.append(self.seg_outputs[-1](encoder_outputs[-1]))\n",
    "        \n",
    "        current = encoder_outputs[-1]\n",
    "        \n",
    "        for i in range(self.num_pool):\n",
    "            # 上採樣\n",
    "            current = self.upsamplers[i](current)\n",
    "            \n",
    "            # Skip connection\n",
    "            skip = encoder_outputs[-(i + 2)]\n",
    "            current = torch.cat([current, skip], dim=1)\n",
    "            \n",
    "            # 解碼塊\n",
    "            current = self.decoders[i](current)\n",
    "            \n",
    "            # 深度監督輸出\n",
    "            if self.deep_supervision:\n",
    "                seg_outputs.append(self.seg_outputs[-(i + 2)](current))\n",
    "        \n",
    "        # 最終輸出\n",
    "        final_output = self.seg_outputs[0](current) if not self.deep_supervision else seg_outputs[-1]\n",
    "        \n",
    "        if self.deep_supervision and self.training:\n",
    "            # 反轉順序，從淺到深\n",
    "            return list(reversed(seg_outputs))\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "\n",
    "# ==================== nnU-Net 損失函數 ====================\n",
    "\n",
    "class nnUNetLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    nnU-Net 損失: Dice + CE\n",
    "    支持深度監督\n",
    "    \"\"\"\n",
    "    def __init__(self, deep_supervision_weights=None, dice_weight=1.0, ce_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.deep_supervision_weights = deep_supervision_weights\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def dice_loss(self, pred, target, smooth=1.0):\n",
    "        \"\"\"Soft Dice Loss\"\"\"\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        \n",
    "        # 計算每個類別的 Dice\n",
    "        dice_scores = []\n",
    "        for c in range(pred.shape[1]):\n",
    "            pred_c = pred[:, c]\n",
    "            target_c = (target == c).float()\n",
    "            \n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            union = pred_c.sum() + target_c.sum()\n",
    "            \n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        return 1.0 - torch.stack(dice_scores).mean()\n",
    "    \n",
    "    def forward(self, outputs, target):\n",
    "        if isinstance(outputs, (list, tuple)):\n",
    "            # 深度監督\n",
    "            if self.deep_supervision_weights is None:\n",
    "                # 默認權重：越深層權重越小\n",
    "                weights = [1.0 / (2 ** i) for i in range(len(outputs))]\n",
    "                weights = [w / sum(weights) for w in weights]\n",
    "            else:\n",
    "                weights = self.deep_supervision_weights\n",
    "            \n",
    "            total_loss = 0\n",
    "            for i, output in enumerate(outputs):\n",
    "                # 需要調整 target 大小以匹配輸出\n",
    "                if output.shape[2:] != target.shape[1:]:\n",
    "                    target_resized = F.interpolate(\n",
    "                        target.unsqueeze(1).float(),\n",
    "                        size=output.shape[2:],\n",
    "                        mode='nearest'\n",
    "                    ).squeeze(1).long()\n",
    "                else:\n",
    "                    target_resized = target\n",
    "                \n",
    "                ce = self.ce_loss(output, target_resized)\n",
    "                dice = self.dice_loss(output, target_resized)\n",
    "                total_loss += weights[i] * (self.ce_weight * ce + self.dice_weight * dice)\n",
    "            \n",
    "            return total_loss\n",
    "        else:\n",
    "            # 單一輸出\n",
    "            ce = self.ce_loss(outputs, target)\n",
    "            dice = self.dice_loss(outputs, target)\n",
    "            return self.ce_weight * ce + self.dice_weight * dice\n",
    "\n",
    "\n",
    "# ==================== nnU-Net 數據增強 ====================\n",
    "\n",
    "class nnUNetAugmentation:\n",
    "    \"\"\"nnU-Net 風格的數據增強\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_rotation(image, label, angle_range=(-15, 15)):\n",
    "        \"\"\"隨機旋轉\"\"\"\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            # 簡化版：只做 90 度旋轉\n",
    "            if random.random() > 0.5:\n",
    "                k = random.randint(1, 3)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = np.rot90(image, k, axes).copy()\n",
    "                label = np.rot90(label, k, axes).copy()\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                from scipy.ndimage import rotate\n",
    "                angle = random.uniform(*angle_range)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = rotate(image, angle, axes=axes, reshape=False, order=3, mode='constant')\n",
    "                label = rotate(label, angle, axes=axes, reshape=False, order=0, mode='constant')\n",
    "            except:\n",
    "                # 如果導入失敗，使用 90 度旋轉\n",
    "                k = random.randint(1, 3)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = np.rot90(image, k, axes).copy()\n",
    "                label = np.rot90(label, k, axes).copy()\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_scaling(image, label, scale_range=(0.85, 1.25)):\n",
    "        \"\"\"隨機縮放\"\"\"\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                from scipy.ndimage import zoom\n",
    "                scale = random.uniform(*scale_range)\n",
    "                scales = [scale] * 3\n",
    "                image = zoom(image, scales, order=3, mode='constant')\n",
    "                label = zoom(label, scales, order=0, mode='constant')\n",
    "            except:\n",
    "                pass  # 如果失敗就跳過縮放\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_elastic_deformation(image, label, alpha=100, sigma=10):\n",
    "        \"\"\"彈性變形\"\"\"\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.3:  # 30% 機率\n",
    "            try:\n",
    "                from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "                shape = image.shape\n",
    "                \n",
    "                # 生成隨機位移場\n",
    "                dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                dz = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                \n",
    "                x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "                indices = np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1)), np.reshape(z + dz, (-1, 1))\n",
    "                \n",
    "                image = map_coordinates(image, indices, order=3, mode='reflect').reshape(shape)\n",
    "                label = map_coordinates(label, indices, order=0, mode='reflect').reshape(shape)\n",
    "            except:\n",
    "                pass  # 如果失敗就跳過彈性變形\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_gamma(image, gamma_range=(0.7, 1.5)):\n",
    "        \"\"\"隨機 Gamma 校正\"\"\"\n",
    "        if random.random() > 0.5:\n",
    "            gamma = random.uniform(*gamma_range)\n",
    "            image_min = image.min()\n",
    "            image_range = image.max() - image_min\n",
    "            if image_range > 0:\n",
    "                image = ((image - image_min) / image_range) ** gamma * image_range + image_min\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_brightness(image, brightness_range=(-0.2, 0.2)):\n",
    "        \"\"\"隨機亮度調整\"\"\"\n",
    "        if random.random() > 0.5:\n",
    "            brightness = random.uniform(*brightness_range)\n",
    "            image = image + brightness * image.std()\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_contrast(image, contrast_range=(0.75, 1.25)):\n",
    "        \"\"\"隨機對比度調整\"\"\"\n",
    "        if random.random() > 0.5:\n",
    "            contrast = random.uniform(*contrast_range)\n",
    "            mean = image.mean()\n",
    "            image = (image - mean) * contrast + mean\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_flip(image, label):\n",
    "        \"\"\"隨機翻轉\"\"\"\n",
    "        for axis in range(3):\n",
    "            if random.random() > 0.5:\n",
    "                image = np.flip(image, axis=axis).copy()\n",
    "                label = np.flip(label, axis=axis).copy()\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ==================== nnU-Net 數據集 ====================\n",
    "\n",
    "class nnUNetDataset(Dataset):\n",
    "    \"\"\"nnU-Net 風格的數據集\"\"\"\n",
    "    def __init__(self, data_dir, target_size=64, is_train=True, use_augmentation=True):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.target_size = target_size\n",
    "        self.is_train = is_train\n",
    "        self.use_augmentation = use_augmentation and is_train\n",
    "        \n",
    "        # 獲取所有圖像文件（過濾掉 macOS 隱藏文件）\n",
    "        all_image_files = list((self.data_dir / 'imagesTr').glob('*.nii.gz'))\n",
    "        self.image_files = sorted([f for f in all_image_files if not f.name.startswith('._')])\n",
    "        \n",
    "        all_label_files = list((self.data_dir / 'labelsTr').glob('*.nii.gz'))\n",
    "        self.label_files = sorted([f for f in all_label_files if not f.name.startswith('._')])\n",
    "        \n",
    "        if len(self.image_files) == 0:\n",
    "            raise ValueError(f\"在 {self.data_dir / 'imagesTr'} 找不到任何 .nii.gz 文件！\")\n",
    "        \n",
    "        print(f\"找到 {len(self.image_files)} 個訓練樣本\")\n",
    "        \n",
    "        self.aug = nnUNetAugmentation()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        \"\"\"nnU-Net 風格預處理\"\"\"\n",
    "        # Clip to percentiles\n",
    "        p1, p99 = np.percentile(image[image > 0], [0.5, 99.5]) if (image > 0).any() else (0, 1)\n",
    "        image = np.clip(image, p1, p99)\n",
    "        \n",
    "        # Z-score normalization (per image)\n",
    "        mean = image[image > 0].mean() if (image > 0).any() else 0\n",
    "        std = image[image > 0].std() if (image > 0).any() else 1\n",
    "        image = (image - mean) / (std + 1e-8)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def apply_augmentation(self, image, label):\n",
    "        \"\"\"應用 nnU-Net 數據增強\"\"\"\n",
    "        # 幾何變換\n",
    "        image, label = self.aug.random_rotation(image, label)\n",
    "        image, label = self.aug.random_scaling(image, label)\n",
    "        image, label = self.aug.random_flip(image, label)\n",
    "        \n",
    "        # 強度變換（僅對圖像）\n",
    "        image = self.aug.random_gamma(image)\n",
    "        image = self.aug.random_brightness(image)\n",
    "        image = self.aug.random_contrast(image)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 讀取文件\n",
    "        image = nib.load(self.image_files[idx]).get_fdata(dtype=np.float32)\n",
    "        label = nib.load(self.label_files[idx]).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        # 預處理\n",
    "        image = self.preprocess(image)\n",
    "        \n",
    "        # 數據增強\n",
    "        if self.use_augmentation:\n",
    "            image, label = self.apply_augmentation(image, label)\n",
    "        \n",
    "        # 轉為 tensor 並調整大小\n",
    "        image = torch.from_numpy(image).unsqueeze(0).unsqueeze(0)  # [1, 1, H, W, D]\n",
    "        label = torch.from_numpy(label).unsqueeze(0).unsqueeze(0)  # [1, 1, H, W, D]\n",
    "        \n",
    "        image = F.interpolate(\n",
    "            image,\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='trilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        label = F.interpolate(\n",
    "            label,\n",
    "            size=(self.target_size, self.target_size, self.target_size),\n",
    "            mode='nearest'\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        label = label.squeeze(0).long()\n",
    "        label = torch.clamp(label, 0, 2)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# ==================== 評估指標 ====================\n",
    "\n",
    "def compute_dice(pred, target, num_classes=3):\n",
    "    \"\"\"計算 Dice 分數\"\"\"\n",
    "    dice_scores = []\n",
    "    \n",
    "    for c in range(1, num_classes):  # 跳過背景\n",
    "        pred_c = (pred == c)\n",
    "        target_c = (target == c)\n",
    "        \n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = pred_c.sum().float() + target_c.sum().float()\n",
    "        \n",
    "        if union == 0:\n",
    "            dice = 1.0 if intersection == 0 else 0.0\n",
    "        else:\n",
    "            dice = (2.0 * intersection) / union\n",
    "        \n",
    "        dice_scores.append(dice.item())\n",
    "    \n",
    "    return dice_scores\n",
    "\n",
    "\n",
    "# ==================== Poly 學習率調度器 ====================\n",
    "\n",
    "class PolynomialLRScheduler:\n",
    "    \"\"\"nnU-Net 使用的 Polynomial 學習率調度\"\"\"\n",
    "    def __init__(self, optimizer, initial_lr, max_epochs, power=0.9):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.power = power\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.current_epoch += 1\n",
    "        lr = self.initial_lr * (1 - self.current_epoch / self.max_epochs) ** self.power\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr\n",
    "\n",
    "\n",
    "# ==================== 訓練函數 ====================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"訓練一個 epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向傳播\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 計算損失（支持深度監督）\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向傳播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪（nnU-Net 使用）\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 12)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    \"\"\"驗證\"\"\"\n",
    "    model.eval()\n",
    "    all_dice_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # 如果是深度監督，只取最終輸出\n",
    "            if isinstance(outputs, (list, tuple)):\n",
    "                outputs = outputs[-1]\n",
    "            \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            \n",
    "            # 計算 Dice\n",
    "            for pred, label in zip(preds, labels):\n",
    "                dice_scores = compute_dice(pred.cpu(), label.cpu())\n",
    "                all_dice_scores.append(dice_scores)\n",
    "    \n",
    "    # 平均 Dice\n",
    "    all_dice_scores = np.array(all_dice_scores)\n",
    "    mean_dice = all_dice_scores.mean(axis=0)\n",
    "    \n",
    "    return mean_dice\n",
    "\n",
    "\n",
    "# ==================== 自動檢測數據路徑 ====================\n",
    "\n",
    "def find_data_directory():\n",
    "    \"\"\"自動查找數據目錄\"\"\"\n",
    "    possible_paths = [\n",
    "        '/home/claude/Task04_Hippocampus',\n",
    "        '/workspace/data/Task04_Hippocampus',\n",
    "        './Task04_Hippocampus',\n",
    "        './data/Task04_Hippocampus',\n",
    "        '../data/Task04_Hippocampus',\n",
    "        '/data/Task04_Hippocampus',\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if Path(path).exists():\n",
    "            images_dir = Path(path) / 'imagesTr'\n",
    "            if images_dir.exists():\n",
    "                # 過濾掉 macOS 隱藏文件\n",
    "                image_files = [f for f in images_dir.glob('*.nii.gz') if not f.name.startswith('._')]\n",
    "                if len(image_files) > 0:\n",
    "                    print(f\"✓ 找到數據目錄: {path}\")\n",
    "                    print(f\"  ({len(image_files)} 個有效文件)\")\n",
    "                    return path\n",
    "    \n",
    "    print(\"\\n❌ 找不到數據目錄！\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==================== 主訓練流程 ====================\n",
    "\n",
    "def main():\n",
    "    # 自動查找數據目錄\n",
    "    data_dir = find_data_directory()\n",
    "    \n",
    "    if data_dir is None:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"錯誤：找不到數據集！\")\n",
    "        print(\"=\" * 60)\n",
    "        return\n",
    "    \n",
    "    # nnU-Net 配置\n",
    "    config = {\n",
    "        'data_dir': data_dir,\n",
    "        'batch_size': 2,\n",
    "        'num_epochs': 100,  # nnU-Net 通常訓練更長時間\n",
    "        'initial_lr': 1e-2,  # nnU-Net 使用較大的初始學習率\n",
    "        'base_channels': 32,  # nnU-Net 使用更多通道\n",
    "        'num_pool': 3,  # 下採樣層數\n",
    "        'target_size': 64,\n",
    "        'deep_supervision': True,\n",
    "        'use_augmentation': True,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"完整的 nnU-Net 訓練\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"配置:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "    print(f\"SciPy 可用: {SCIPY_AVAILABLE}\")\n",
    "    if not SCIPY_AVAILABLE:\n",
    "        print(\"  ⚠️  將使用簡化的數據增強（僅翻轉和 90° 旋轉）\")\n",
    "    print()\n",
    "    \n",
    "    device = torch.device(config['device'])\n",
    "    \n",
    "    # 創建數據集\n",
    "    print(\"準備數據集...\")\n",
    "    try:\n",
    "        full_dataset = nnUNetDataset(\n",
    "            config['data_dir'],\n",
    "            target_size=config['target_size'],\n",
    "            is_train=True,\n",
    "            use_augmentation=config['use_augmentation']\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n錯誤: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 訓練/驗證劃分 (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"訓練集: {len(train_dataset)} 樣本\")\n",
    "    print(f\"驗證集: {len(val_dataset)} 樣本\")\n",
    "    print()\n",
    "    \n",
    "    # 創建 nnU-Net 模型\n",
    "    print(\"創建 nnU-Net 模型...\")\n",
    "    model = nnUNet(\n",
    "        in_channels=1,\n",
    "        num_classes=3,\n",
    "        base_channels=config['base_channels'],\n",
    "        num_pool=config['num_pool'],\n",
    "        deep_supervision=config['deep_supervision']\n",
    "    ).to(device)\n",
    "    \n",
    "    # 計算參數量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型參數量: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
    "    print()\n",
    "    \n",
    "    # 損失函數和優化器\n",
    "    criterion = nnUNetLoss(dice_weight=1.0, ce_weight=1.0)\n",
    "    \n",
    "    # nnU-Net 使用 SGD with momentum 和 Nesterov\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=config['initial_lr'],\n",
    "        momentum=0.99,\n",
    "        weight_decay=3e-5,\n",
    "        nesterov=True\n",
    "    )\n",
    "    \n",
    "    # Polynomial 學習率調度\n",
    "    scheduler = PolynomialLRScheduler(\n",
    "        optimizer,\n",
    "        initial_lr=config['initial_lr'],\n",
    "        max_epochs=config['num_epochs'],\n",
    "        power=0.9\n",
    "    )\n",
    "    \n",
    "    # 訓練循環\n",
    "    print(\"開始訓練...\")\n",
    "    print(f\"使用深度監督: {config['deep_supervision']}\")\n",
    "    print(f\"使用數據增強: {config['use_augmentation']}\")\n",
    "    print()\n",
    "    \n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # 訓練\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # 驗證\n",
    "        val_dice = validate(model, val_loader, device)\n",
    "        \n",
    "        # 學習率調度\n",
    "        current_lr = scheduler.step()\n",
    "        \n",
    "        # 打印結果\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Dice - Class 1: {val_dice[0]:.4f}, Class 2: {val_dice[1]:.4f}, \"\n",
    "              f\"Avg: {val_dice.mean():.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_dice.mean() > best_dice:\n",
    "            best_dice = val_dice.mean()\n",
    "            \n",
    "            # 確保輸出目錄存在\n",
    "            output_dir = Path('/workspace/outputs')\n",
    "            if not output_dir.exists():\n",
    "                output_dir = Path('./outputs')\n",
    "                output_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            save_path = output_dir / 'nnunet_best.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'dice': val_dice,\n",
    "                'config': config\n",
    "            }, save_path)\n",
    "            print(f\"✓ 保存最佳模型 (Dice: {best_dice:.4f}) -> {save_path}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"訓練完成！\")\n",
    "    print(f\"最佳驗證 Dice: {best_dice:.4f}\")\n",
    "    print(f\"模型已保存至: {save_path}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "950ddbea-82b5-430f-8759-0c8c7e81fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "檢測到 Jupyter 環境，使用默認種子 42\n",
      "\n",
      "============================================================\n",
      "增強版 nnU-Net 訓練 (Seed: 42)\n",
      "============================================================\n",
      "配置:\n",
      "  data_dir: ./Task04_Hippocampus\n",
      "  batch_size: 2\n",
      "  num_epochs: 200\n",
      "  initial_lr: 0.01\n",
      "  base_channels: 48\n",
      "  num_pool: 3\n",
      "  target_size: 64\n",
      "  deep_supervision: True\n",
      "  use_augmentation: True\n",
      "  device: cuda\n",
      "  seed: 42\n",
      "\n",
      "訓練集: 208 樣本\n",
      "驗證集: 52 樣本\n",
      "\n",
      "模型參數量: 14,105,820 (14.11M)\n",
      "\n",
      "Epoch 1/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.22it/s, loss=0.4846]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6262\n",
      "Val Dice - Class 1: 0.6574, Class 2: 0.7210, Avg: 0.6892\n",
      "Learning Rate: 0.009955\n",
      "✓ 保存最佳模型 (Dice: 0.6892)\n",
      "\n",
      "Epoch 2/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.22it/s, loss=0.2565]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3083\n",
      "Val Dice - Class 1: 0.7604, Class 2: 0.7597, Avg: 0.7601\n",
      "Learning Rate: 0.009910\n",
      "✓ 保存最佳模型 (Dice: 0.7601)\n",
      "\n",
      "Epoch 3/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.25it/s, loss=0.3606]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2527\n",
      "Val Dice - Class 1: 0.7627, Class 2: 0.7887, Avg: 0.7757\n",
      "Learning Rate: 0.009865\n",
      "✓ 保存最佳模型 (Dice: 0.7757)\n",
      "\n",
      "Epoch 4/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.22it/s, loss=0.3312]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2279\n",
      "Val Dice - Class 1: 0.7816, Class 2: 0.7886, Avg: 0.7851\n",
      "Learning Rate: 0.009820\n",
      "✓ 保存最佳模型 (Dice: 0.7851)\n",
      "\n",
      "Epoch 5/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.22it/s, loss=0.2139]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2142\n",
      "Val Dice - Class 1: 0.8059, Class 2: 0.8074, Avg: 0.8067\n",
      "Learning Rate: 0.009775\n",
      "✓ 保存最佳模型 (Dice: 0.8067)\n",
      "\n",
      "Epoch 6/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.17it/s, loss=0.1980]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2056\n",
      "Val Dice - Class 1: 0.8091, Class 2: 0.8054, Avg: 0.8072\n",
      "Learning Rate: 0.009730\n",
      "✓ 保存最佳模型 (Dice: 0.8072)\n",
      "\n",
      "Epoch 7/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.3041]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1974\n",
      "Val Dice - Class 1: 0.8150, Class 2: 0.8128, Avg: 0.8139\n",
      "Learning Rate: 0.009684\n",
      "✓ 保存最佳模型 (Dice: 0.8139)\n",
      "\n",
      "Epoch 8/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.1863]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1951\n",
      "Val Dice - Class 1: 0.8179, Class 2: 0.8091, Avg: 0.8135\n",
      "Learning Rate: 0.009639\n",
      "\n",
      "Epoch 9/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.17it/s, loss=0.2450]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1924\n",
      "Val Dice - Class 1: 0.8231, Class 2: 0.8178, Avg: 0.8205\n",
      "Learning Rate: 0.009594\n",
      "✓ 保存最佳模型 (Dice: 0.8205)\n",
      "\n",
      "Epoch 10/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.16it/s, loss=0.1478]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1828\n",
      "Val Dice - Class 1: 0.8331, Class 2: 0.8205, Avg: 0.8268\n",
      "Learning Rate: 0.009549\n",
      "✓ 保存最佳模型 (Dice: 0.8268)\n",
      "\n",
      "Epoch 11/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.17it/s, loss=0.1918]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1806\n",
      "Val Dice - Class 1: 0.8321, Class 2: 0.8194, Avg: 0.8258\n",
      "Learning Rate: 0.009504\n",
      "\n",
      "Epoch 12/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.1885]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1776\n",
      "Val Dice - Class 1: 0.8354, Class 2: 0.8243, Avg: 0.8299\n",
      "Learning Rate: 0.009458\n",
      "✓ 保存最佳模型 (Dice: 0.8299)\n",
      "\n",
      "Epoch 13/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.16it/s, loss=0.1763]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1769\n",
      "Val Dice - Class 1: 0.8329, Class 2: 0.8222, Avg: 0.8276\n",
      "Learning Rate: 0.009413\n",
      "\n",
      "Epoch 14/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.21it/s, loss=0.1331]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1730\n",
      "Val Dice - Class 1: 0.8334, Class 2: 0.8175, Avg: 0.8255\n",
      "Learning Rate: 0.009368\n",
      "\n",
      "Epoch 15/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.1415]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1730\n",
      "Val Dice - Class 1: 0.8389, Class 2: 0.8259, Avg: 0.8324\n",
      "Learning Rate: 0.009322\n",
      "✓ 保存最佳模型 (Dice: 0.8324)\n",
      "\n",
      "Epoch 16/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.16it/s, loss=0.1551]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1717\n",
      "Val Dice - Class 1: 0.8380, Class 2: 0.8231, Avg: 0.8306\n",
      "Learning Rate: 0.009277\n",
      "\n",
      "Epoch 17/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.2227]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1711\n",
      "Val Dice - Class 1: 0.8451, Class 2: 0.8293, Avg: 0.8372\n",
      "Learning Rate: 0.009232\n",
      "✓ 保存最佳模型 (Dice: 0.8372)\n",
      "\n",
      "Epoch 18/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.15it/s, loss=0.2356]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1674\n",
      "Val Dice - Class 1: 0.8401, Class 2: 0.8271, Avg: 0.8336\n",
      "Learning Rate: 0.009186\n",
      "\n",
      "Epoch 19/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.21it/s, loss=0.1827]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1665\n",
      "Val Dice - Class 1: 0.8454, Class 2: 0.8338, Avg: 0.8396\n",
      "Learning Rate: 0.009141\n",
      "✓ 保存最佳模型 (Dice: 0.8396)\n",
      "\n",
      "Epoch 20/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.17it/s, loss=0.1469]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1664\n",
      "Val Dice - Class 1: 0.8422, Class 2: 0.8304, Avg: 0.8363\n",
      "Learning Rate: 0.009095\n",
      "\n",
      "Epoch 21/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1294]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1649\n",
      "Val Dice - Class 1: 0.8469, Class 2: 0.8308, Avg: 0.8389\n",
      "Learning Rate: 0.009050\n",
      "\n",
      "Epoch 22/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.17it/s, loss=0.1923]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1633\n",
      "Val Dice - Class 1: 0.8405, Class 2: 0.8321, Avg: 0.8363\n",
      "Learning Rate: 0.009004\n",
      "\n",
      "Epoch 23/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.19it/s, loss=0.1628]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1653\n",
      "Val Dice - Class 1: 0.8462, Class 2: 0.8294, Avg: 0.8378\n",
      "Learning Rate: 0.008959\n",
      "\n",
      "Epoch 24/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.19it/s, loss=0.1754]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1642\n",
      "Val Dice - Class 1: 0.8367, Class 2: 0.8283, Avg: 0.8325\n",
      "Learning Rate: 0.008913\n",
      "\n",
      "Epoch 25/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.21it/s, loss=0.1230]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1618\n",
      "Val Dice - Class 1: 0.8488, Class 2: 0.8312, Avg: 0.8400\n",
      "Learning Rate: 0.008868\n",
      "✓ 保存最佳模型 (Dice: 0.8400)\n",
      "\n",
      "Epoch 26/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.24it/s, loss=0.1456]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1600\n",
      "Val Dice - Class 1: 0.8513, Class 2: 0.8328, Avg: 0.8421\n",
      "Learning Rate: 0.008822\n",
      "✓ 保存最佳模型 (Dice: 0.8421)\n",
      "\n",
      "Epoch 27/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.28it/s, loss=0.1508]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1594\n",
      "Val Dice - Class 1: 0.8542, Class 2: 0.8347, Avg: 0.8445\n",
      "Learning Rate: 0.008776\n",
      "✓ 保存最佳模型 (Dice: 0.8445)\n",
      "\n",
      "Epoch 28/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.23it/s, loss=0.2022]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1578\n",
      "Val Dice - Class 1: 0.8475, Class 2: 0.8272, Avg: 0.8374\n",
      "Learning Rate: 0.008731\n",
      "\n",
      "Epoch 29/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.29it/s, loss=0.1569]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1556\n",
      "Val Dice - Class 1: 0.8500, Class 2: 0.8312, Avg: 0.8406\n",
      "Learning Rate: 0.008685\n",
      "\n",
      "Epoch 30/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.24it/s, loss=0.1726]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1543\n",
      "Val Dice - Class 1: 0.8483, Class 2: 0.8344, Avg: 0.8414\n",
      "Learning Rate: 0.008639\n",
      "\n",
      "Epoch 31/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.28it/s, loss=0.1446]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1556\n",
      "Val Dice - Class 1: 0.8515, Class 2: 0.8350, Avg: 0.8433\n",
      "Learning Rate: 0.008594\n",
      "\n",
      "Epoch 32/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.30it/s, loss=0.1331]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1583\n",
      "Val Dice - Class 1: 0.8508, Class 2: 0.8349, Avg: 0.8429\n",
      "Learning Rate: 0.008548\n",
      "\n",
      "Epoch 33/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.28it/s, loss=0.1141]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1539\n",
      "Val Dice - Class 1: 0.8539, Class 2: 0.8327, Avg: 0.8433\n",
      "Learning Rate: 0.008502\n",
      "\n",
      "Epoch 34/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.27it/s, loss=0.1787]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1557\n",
      "Val Dice - Class 1: 0.8561, Class 2: 0.8370, Avg: 0.8466\n",
      "Learning Rate: 0.008456\n",
      "✓ 保存最佳模型 (Dice: 0.8466)\n",
      "\n",
      "Epoch 35/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.28it/s, loss=0.1466]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1508\n",
      "Val Dice - Class 1: 0.8527, Class 2: 0.8380, Avg: 0.8453\n",
      "Learning Rate: 0.008410\n",
      "\n",
      "Epoch 36/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.29it/s, loss=0.1990]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 10.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1515\n",
      "Val Dice - Class 1: 0.8558, Class 2: 0.8397, Avg: 0.8478\n",
      "Learning Rate: 0.008364\n",
      "✓ 保存最佳模型 (Dice: 0.8478)\n",
      "\n",
      "Epoch 37/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.27it/s, loss=0.1467]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1500\n",
      "Val Dice - Class 1: 0.8558, Class 2: 0.8359, Avg: 0.8459\n",
      "Learning Rate: 0.008318\n",
      "\n",
      "Epoch 38/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.30it/s, loss=0.1297]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1491\n",
      "Val Dice - Class 1: 0.8567, Class 2: 0.8392, Avg: 0.8480\n",
      "Learning Rate: 0.008272\n",
      "✓ 保存最佳模型 (Dice: 0.8480)\n",
      "\n",
      "Epoch 39/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.27it/s, loss=0.1883]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1498\n",
      "Val Dice - Class 1: 0.8581, Class 2: 0.8368, Avg: 0.8474\n",
      "Learning Rate: 0.008227\n",
      "\n",
      "Epoch 40/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.25it/s, loss=0.1431]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1477\n",
      "Val Dice - Class 1: 0.8547, Class 2: 0.8424, Avg: 0.8486\n",
      "Learning Rate: 0.008181\n",
      "✓ 保存最佳模型 (Dice: 0.8486)\n",
      "\n",
      "Epoch 41/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.20it/s, loss=0.1373]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1480\n",
      "Val Dice - Class 1: 0.8566, Class 2: 0.8386, Avg: 0.8476\n",
      "Learning Rate: 0.008134\n",
      "\n",
      "Epoch 42/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.25it/s, loss=0.1336]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1470\n",
      "Val Dice - Class 1: 0.8570, Class 2: 0.8415, Avg: 0.8492\n",
      "Learning Rate: 0.008088\n",
      "✓ 保存最佳模型 (Dice: 0.8492)\n",
      "\n",
      "Epoch 43/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.26it/s, loss=0.1398]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1468\n",
      "Val Dice - Class 1: 0.8590, Class 2: 0.8407, Avg: 0.8499\n",
      "Learning Rate: 0.008042\n",
      "✓ 保存最佳模型 (Dice: 0.8499)\n",
      "\n",
      "Epoch 44/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.25it/s, loss=0.1486]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1468\n",
      "Val Dice - Class 1: 0.8617, Class 2: 0.8435, Avg: 0.8526\n",
      "Learning Rate: 0.007996\n",
      "✓ 保存最佳模型 (Dice: 0.8526)\n",
      "\n",
      "Epoch 45/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.27it/s, loss=0.1521]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1430\n",
      "Val Dice - Class 1: 0.8628, Class 2: 0.8451, Avg: 0.8539\n",
      "Learning Rate: 0.007950\n",
      "✓ 保存最佳模型 (Dice: 0.8539)\n",
      "\n",
      "Epoch 46/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1757]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1429\n",
      "Val Dice - Class 1: 0.8624, Class 2: 0.8409, Avg: 0.8516\n",
      "Learning Rate: 0.007904\n",
      "\n",
      "Epoch 47/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1523]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1459\n",
      "Val Dice - Class 1: 0.8592, Class 2: 0.8364, Avg: 0.8478\n",
      "Learning Rate: 0.007858\n",
      "\n",
      "Epoch 48/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1713]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1431\n",
      "Val Dice - Class 1: 0.8591, Class 2: 0.8406, Avg: 0.8499\n",
      "Learning Rate: 0.007811\n",
      "\n",
      "Epoch 49/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1219]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1456\n",
      "Val Dice - Class 1: 0.8569, Class 2: 0.8419, Avg: 0.8494\n",
      "Learning Rate: 0.007765\n",
      "\n",
      "Epoch 50/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1422]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1457\n",
      "Val Dice - Class 1: 0.8571, Class 2: 0.8392, Avg: 0.8482\n",
      "Learning Rate: 0.007719\n",
      "\n",
      "Epoch 51/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1373]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1444\n",
      "Val Dice - Class 1: 0.8617, Class 2: 0.8454, Avg: 0.8535\n",
      "Learning Rate: 0.007673\n",
      "\n",
      "Epoch 52/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1531]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1454\n",
      "Val Dice - Class 1: 0.8556, Class 2: 0.8452, Avg: 0.8504\n",
      "Learning Rate: 0.007626\n",
      "\n",
      "Epoch 53/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.03it/s, loss=0.1287]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1433\n",
      "Val Dice - Class 1: 0.8651, Class 2: 0.8458, Avg: 0.8554\n",
      "Learning Rate: 0.007580\n",
      "✓ 保存最佳模型 (Dice: 0.8554)\n",
      "\n",
      "Epoch 54/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.05it/s, loss=0.1564]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1452\n",
      "Val Dice - Class 1: 0.8554, Class 2: 0.8411, Avg: 0.8483\n",
      "Learning Rate: 0.007533\n",
      "\n",
      "Epoch 55/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1264]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1444\n",
      "Val Dice - Class 1: 0.8602, Class 2: 0.8391, Avg: 0.8496\n",
      "Learning Rate: 0.007487\n",
      "\n",
      "Epoch 56/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.05it/s, loss=0.1651]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1420\n",
      "Val Dice - Class 1: 0.8673, Class 2: 0.8454, Avg: 0.8564\n",
      "Learning Rate: 0.007440\n",
      "✓ 保存最佳模型 (Dice: 0.8564)\n",
      "\n",
      "Epoch 57/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.1449]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1386\n",
      "Val Dice - Class 1: 0.8636, Class 2: 0.8446, Avg: 0.8541\n",
      "Learning Rate: 0.007394\n",
      "\n",
      "Epoch 58/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1269]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1404\n",
      "Val Dice - Class 1: 0.8632, Class 2: 0.8466, Avg: 0.8549\n",
      "Learning Rate: 0.007347\n",
      "\n",
      "Epoch 59/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.05it/s, loss=0.1062]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1407\n",
      "Val Dice - Class 1: 0.8626, Class 2: 0.8436, Avg: 0.8531\n",
      "Learning Rate: 0.007301\n",
      "\n",
      "Epoch 60/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1392]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1394\n",
      "Val Dice - Class 1: 0.8690, Class 2: 0.8506, Avg: 0.8598\n",
      "Learning Rate: 0.007254\n",
      "✓ 保存最佳模型 (Dice: 0.8598)\n",
      "\n",
      "Epoch 61/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1357]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1376\n",
      "Val Dice - Class 1: 0.8580, Class 2: 0.8442, Avg: 0.8511\n",
      "Learning Rate: 0.007208\n",
      "\n",
      "Epoch 62/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1666]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1363\n",
      "Val Dice - Class 1: 0.8647, Class 2: 0.8435, Avg: 0.8541\n",
      "Learning Rate: 0.007161\n",
      "\n",
      "Epoch 63/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.16it/s, loss=0.1191]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1396\n",
      "Val Dice - Class 1: 0.8645, Class 2: 0.8483, Avg: 0.8564\n",
      "Learning Rate: 0.007114\n",
      "\n",
      "Epoch 64/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1484]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1368\n",
      "Val Dice - Class 1: 0.8690, Class 2: 0.8511, Avg: 0.8600\n",
      "Learning Rate: 0.007067\n",
      "✓ 保存最佳模型 (Dice: 0.8600)\n",
      "\n",
      "Epoch 65/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.05it/s, loss=0.1635]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1378\n",
      "Val Dice - Class 1: 0.8629, Class 2: 0.8469, Avg: 0.8549\n",
      "Learning Rate: 0.007021\n",
      "\n",
      "Epoch 66/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.03it/s, loss=0.1366]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1376\n",
      "Val Dice - Class 1: 0.8622, Class 2: 0.8469, Avg: 0.8545\n",
      "Learning Rate: 0.006974\n",
      "\n",
      "Epoch 67/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.03it/s, loss=0.1303]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1391\n",
      "Val Dice - Class 1: 0.8643, Class 2: 0.8434, Avg: 0.8538\n",
      "Learning Rate: 0.006927\n",
      "\n",
      "Epoch 68/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1269]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1368\n",
      "Val Dice - Class 1: 0.8603, Class 2: 0.8399, Avg: 0.8501\n",
      "Learning Rate: 0.006880\n",
      "\n",
      "Epoch 69/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1553]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1363\n",
      "Val Dice - Class 1: 0.8612, Class 2: 0.8445, Avg: 0.8529\n",
      "Learning Rate: 0.006833\n",
      "\n",
      "Epoch 70/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1530]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1370\n",
      "Val Dice - Class 1: 0.8645, Class 2: 0.8457, Avg: 0.8551\n",
      "Learning Rate: 0.006786\n",
      "\n",
      "Epoch 71/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1496]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1366\n",
      "Val Dice - Class 1: 0.8605, Class 2: 0.8470, Avg: 0.8537\n",
      "Learning Rate: 0.006739\n",
      "\n",
      "Epoch 72/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1183]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1349\n",
      "Val Dice - Class 1: 0.8626, Class 2: 0.8458, Avg: 0.8542\n",
      "Learning Rate: 0.006692\n",
      "\n",
      "Epoch 73/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1842]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1346\n",
      "Val Dice - Class 1: 0.8658, Class 2: 0.8451, Avg: 0.8555\n",
      "Learning Rate: 0.006645\n",
      "\n",
      "Epoch 74/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1530]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1339\n",
      "Val Dice - Class 1: 0.8634, Class 2: 0.8480, Avg: 0.8557\n",
      "Learning Rate: 0.006598\n",
      "\n",
      "Epoch 75/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1179]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1345\n",
      "Val Dice - Class 1: 0.8647, Class 2: 0.8472, Avg: 0.8559\n",
      "Learning Rate: 0.006551\n",
      "\n",
      "Epoch 76/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1299]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1346\n",
      "Val Dice - Class 1: 0.8647, Class 2: 0.8492, Avg: 0.8569\n",
      "Learning Rate: 0.006504\n",
      "\n",
      "Epoch 77/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1140]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1334\n",
      "Val Dice - Class 1: 0.8641, Class 2: 0.8459, Avg: 0.8550\n",
      "Learning Rate: 0.006456\n",
      "\n",
      "Epoch 78/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1619]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1346\n",
      "Val Dice - Class 1: 0.8643, Class 2: 0.8474, Avg: 0.8558\n",
      "Learning Rate: 0.006409\n",
      "\n",
      "Epoch 79/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.1274]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1319\n",
      "Val Dice - Class 1: 0.8656, Class 2: 0.8491, Avg: 0.8573\n",
      "Learning Rate: 0.006362\n",
      "\n",
      "Epoch 80/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1472]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1328\n",
      "Val Dice - Class 1: 0.8671, Class 2: 0.8490, Avg: 0.8580\n",
      "Learning Rate: 0.006314\n",
      "\n",
      "Epoch 81/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1184]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1303\n",
      "Val Dice - Class 1: 0.8660, Class 2: 0.8526, Avg: 0.8593\n",
      "Learning Rate: 0.006267\n",
      "\n",
      "Epoch 82/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.15it/s, loss=0.1048]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1324\n",
      "Val Dice - Class 1: 0.8661, Class 2: 0.8478, Avg: 0.8569\n",
      "Learning Rate: 0.006220\n",
      "\n",
      "Epoch 83/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1463]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1309\n",
      "Val Dice - Class 1: 0.8690, Class 2: 0.8495, Avg: 0.8592\n",
      "Learning Rate: 0.006172\n",
      "\n",
      "Epoch 84/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1390]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1318\n",
      "Val Dice - Class 1: 0.8616, Class 2: 0.8452, Avg: 0.8534\n",
      "Learning Rate: 0.006125\n",
      "\n",
      "Epoch 85/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1432]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1296\n",
      "Val Dice - Class 1: 0.8668, Class 2: 0.8504, Avg: 0.8586\n",
      "Learning Rate: 0.006077\n",
      "\n",
      "Epoch 86/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1193]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1308\n",
      "Val Dice - Class 1: 0.8646, Class 2: 0.8512, Avg: 0.8579\n",
      "Learning Rate: 0.006030\n",
      "\n",
      "Epoch 87/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1507]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1273\n",
      "Val Dice - Class 1: 0.8680, Class 2: 0.8494, Avg: 0.8587\n",
      "Learning Rate: 0.005982\n",
      "\n",
      "Epoch 88/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1139]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1265\n",
      "Val Dice - Class 1: 0.8730, Class 2: 0.8556, Avg: 0.8643\n",
      "Learning Rate: 0.005934\n",
      "✓ 保存最佳模型 (Dice: 0.8643)\n",
      "\n",
      "Epoch 89/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1208]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1247\n",
      "Val Dice - Class 1: 0.8690, Class 2: 0.8531, Avg: 0.8611\n",
      "Learning Rate: 0.005887\n",
      "\n",
      "Epoch 90/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1211]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1278\n",
      "Val Dice - Class 1: 0.8655, Class 2: 0.8502, Avg: 0.8579\n",
      "Learning Rate: 0.005839\n",
      "\n",
      "Epoch 91/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1100]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1289\n",
      "Val Dice - Class 1: 0.8683, Class 2: 0.8498, Avg: 0.8590\n",
      "Learning Rate: 0.005791\n",
      "\n",
      "Epoch 92/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.0964]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1259\n",
      "Val Dice - Class 1: 0.8680, Class 2: 0.8518, Avg: 0.8599\n",
      "Learning Rate: 0.005743\n",
      "\n",
      "Epoch 93/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1336]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1282\n",
      "Val Dice - Class 1: 0.8700, Class 2: 0.8509, Avg: 0.8605\n",
      "Learning Rate: 0.005695\n",
      "\n",
      "Epoch 94/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1106]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1270\n",
      "Val Dice - Class 1: 0.8673, Class 2: 0.8489, Avg: 0.8581\n",
      "Learning Rate: 0.005647\n",
      "\n",
      "Epoch 95/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1544]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1262\n",
      "Val Dice - Class 1: 0.8684, Class 2: 0.8553, Avg: 0.8618\n",
      "Learning Rate: 0.005599\n",
      "\n",
      "Epoch 96/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1359]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1255\n",
      "Val Dice - Class 1: 0.8691, Class 2: 0.8508, Avg: 0.8599\n",
      "Learning Rate: 0.005551\n",
      "\n",
      "Epoch 97/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1368]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1278\n",
      "Val Dice - Class 1: 0.8691, Class 2: 0.8504, Avg: 0.8597\n",
      "Learning Rate: 0.005503\n",
      "\n",
      "Epoch 98/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1017]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1265\n",
      "Val Dice - Class 1: 0.8699, Class 2: 0.8515, Avg: 0.8607\n",
      "Learning Rate: 0.005455\n",
      "\n",
      "Epoch 99/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.1257]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1256\n",
      "Val Dice - Class 1: 0.8711, Class 2: 0.8521, Avg: 0.8616\n",
      "Learning Rate: 0.005407\n",
      "\n",
      "Epoch 100/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1186]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1252\n",
      "Val Dice - Class 1: 0.8675, Class 2: 0.8532, Avg: 0.8604\n",
      "Learning Rate: 0.005359\n",
      "\n",
      "Epoch 101/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1254]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1234\n",
      "Val Dice - Class 1: 0.8692, Class 2: 0.8534, Avg: 0.8613\n",
      "Learning Rate: 0.005311\n",
      "\n",
      "Epoch 102/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1344]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1237\n",
      "Val Dice - Class 1: 0.8653, Class 2: 0.8484, Avg: 0.8568\n",
      "Learning Rate: 0.005262\n",
      "\n",
      "Epoch 103/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.1340]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1245\n",
      "Val Dice - Class 1: 0.8698, Class 2: 0.8510, Avg: 0.8604\n",
      "Learning Rate: 0.005214\n",
      "\n",
      "Epoch 104/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.04it/s, loss=0.1169]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1228\n",
      "Val Dice - Class 1: 0.8705, Class 2: 0.8545, Avg: 0.8625\n",
      "Learning Rate: 0.005166\n",
      "\n",
      "Epoch 105/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1184]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1215\n",
      "Val Dice - Class 1: 0.8679, Class 2: 0.8502, Avg: 0.8590\n",
      "Learning Rate: 0.005117\n",
      "\n",
      "Epoch 106/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1149]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1230\n",
      "Val Dice - Class 1: 0.8682, Class 2: 0.8544, Avg: 0.8613\n",
      "Learning Rate: 0.005069\n",
      "\n",
      "Epoch 107/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1239]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1229\n",
      "Val Dice - Class 1: 0.8690, Class 2: 0.8552, Avg: 0.8621\n",
      "Learning Rate: 0.005020\n",
      "\n",
      "Epoch 108/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.0851]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1225\n",
      "Val Dice - Class 1: 0.8720, Class 2: 0.8552, Avg: 0.8636\n",
      "Learning Rate: 0.004971\n",
      "\n",
      "Epoch 109/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1081]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1217\n",
      "Val Dice - Class 1: 0.8680, Class 2: 0.8545, Avg: 0.8612\n",
      "Learning Rate: 0.004923\n",
      "\n",
      "Epoch 110/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1188]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1214\n",
      "Val Dice - Class 1: 0.8698, Class 2: 0.8547, Avg: 0.8623\n",
      "Learning Rate: 0.004874\n",
      "\n",
      "Epoch 111/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1768]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1234\n",
      "Val Dice - Class 1: 0.8667, Class 2: 0.8521, Avg: 0.8594\n",
      "Learning Rate: 0.004825\n",
      "\n",
      "Epoch 112/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.1087]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1215\n",
      "Val Dice - Class 1: 0.8656, Class 2: 0.8512, Avg: 0.8584\n",
      "Learning Rate: 0.004776\n",
      "\n",
      "Epoch 113/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0962]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1195\n",
      "Val Dice - Class 1: 0.8724, Class 2: 0.8549, Avg: 0.8636\n",
      "Learning Rate: 0.004728\n",
      "\n",
      "Epoch 114/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1147]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1195\n",
      "Val Dice - Class 1: 0.8710, Class 2: 0.8539, Avg: 0.8625\n",
      "Learning Rate: 0.004679\n",
      "\n",
      "Epoch 115/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.16it/s, loss=0.1530]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1199\n",
      "Val Dice - Class 1: 0.8710, Class 2: 0.8539, Avg: 0.8625\n",
      "Learning Rate: 0.004630\n",
      "\n",
      "Epoch 116/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1308]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1223\n",
      "Val Dice - Class 1: 0.8701, Class 2: 0.8540, Avg: 0.8621\n",
      "Learning Rate: 0.004581\n",
      "\n",
      "Epoch 117/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1105]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1204\n",
      "Val Dice - Class 1: 0.8706, Class 2: 0.8554, Avg: 0.8630\n",
      "Learning Rate: 0.004532\n",
      "\n",
      "Epoch 118/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1169]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1201\n",
      "Val Dice - Class 1: 0.8722, Class 2: 0.8552, Avg: 0.8637\n",
      "Learning Rate: 0.004482\n",
      "\n",
      "Epoch 119/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1187]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1187\n",
      "Val Dice - Class 1: 0.8719, Class 2: 0.8515, Avg: 0.8617\n",
      "Learning Rate: 0.004433\n",
      "\n",
      "Epoch 120/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0828]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1187\n",
      "Val Dice - Class 1: 0.8678, Class 2: 0.8521, Avg: 0.8599\n",
      "Learning Rate: 0.004384\n",
      "\n",
      "Epoch 121/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1338]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1187\n",
      "Val Dice - Class 1: 0.8712, Class 2: 0.8550, Avg: 0.8631\n",
      "Learning Rate: 0.004334\n",
      "\n",
      "Epoch 122/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.18it/s, loss=0.0896]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1183\n",
      "Val Dice - Class 1: 0.8714, Class 2: 0.8539, Avg: 0.8626\n",
      "Learning Rate: 0.004285\n",
      "\n",
      "Epoch 123/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1094]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1173\n",
      "Val Dice - Class 1: 0.8695, Class 2: 0.8516, Avg: 0.8605\n",
      "Learning Rate: 0.004236\n",
      "\n",
      "Epoch 124/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1348]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1174\n",
      "Val Dice - Class 1: 0.8719, Class 2: 0.8531, Avg: 0.8625\n",
      "Learning Rate: 0.004186\n",
      "\n",
      "Epoch 125/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1013]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1162\n",
      "Val Dice - Class 1: 0.8744, Class 2: 0.8570, Avg: 0.8657\n",
      "Learning Rate: 0.004136\n",
      "✓ 保存最佳模型 (Dice: 0.8657)\n",
      "\n",
      "Epoch 126/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.04it/s, loss=0.1492]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1138\n",
      "Val Dice - Class 1: 0.8703, Class 2: 0.8558, Avg: 0.8630\n",
      "Learning Rate: 0.004087\n",
      "\n",
      "Epoch 127/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1116]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1170\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8504, Avg: 0.8606\n",
      "Learning Rate: 0.004037\n",
      "\n",
      "Epoch 128/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1601]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1149\n",
      "Val Dice - Class 1: 0.8737, Class 2: 0.8561, Avg: 0.8649\n",
      "Learning Rate: 0.003987\n",
      "\n",
      "Epoch 129/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1134]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1130\n",
      "Val Dice - Class 1: 0.8706, Class 2: 0.8533, Avg: 0.8620\n",
      "Learning Rate: 0.003937\n",
      "\n",
      "Epoch 130/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0934]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1139\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8537, Avg: 0.8623\n",
      "Learning Rate: 0.003887\n",
      "\n",
      "Epoch 131/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0882]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1127\n",
      "Val Dice - Class 1: 0.8711, Class 2: 0.8538, Avg: 0.8624\n",
      "Learning Rate: 0.003837\n",
      "\n",
      "Epoch 132/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1148]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1128\n",
      "Val Dice - Class 1: 0.8703, Class 2: 0.8540, Avg: 0.8622\n",
      "Learning Rate: 0.003787\n",
      "\n",
      "Epoch 133/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0918]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1142\n",
      "Val Dice - Class 1: 0.8691, Class 2: 0.8542, Avg: 0.8617\n",
      "Learning Rate: 0.003737\n",
      "\n",
      "Epoch 134/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.0923]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1160\n",
      "Val Dice - Class 1: 0.8741, Class 2: 0.8563, Avg: 0.8652\n",
      "Learning Rate: 0.003687\n",
      "\n",
      "Epoch 135/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1090]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1140\n",
      "Val Dice - Class 1: 0.8716, Class 2: 0.8530, Avg: 0.8623\n",
      "Learning Rate: 0.003637\n",
      "\n",
      "Epoch 136/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1227]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1132\n",
      "Val Dice - Class 1: 0.8711, Class 2: 0.8535, Avg: 0.8623\n",
      "Learning Rate: 0.003586\n",
      "\n",
      "Epoch 137/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0880]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1133\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8530, Avg: 0.8619\n",
      "Learning Rate: 0.003536\n",
      "\n",
      "Epoch 138/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1264]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1123\n",
      "Val Dice - Class 1: 0.8728, Class 2: 0.8561, Avg: 0.8644\n",
      "Learning Rate: 0.003485\n",
      "\n",
      "Epoch 139/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1183]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1114\n",
      "Val Dice - Class 1: 0.8712, Class 2: 0.8533, Avg: 0.8623\n",
      "Learning Rate: 0.003435\n",
      "\n",
      "Epoch 140/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0842]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1129\n",
      "Val Dice - Class 1: 0.8706, Class 2: 0.8550, Avg: 0.8628\n",
      "Learning Rate: 0.003384\n",
      "\n",
      "Epoch 141/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1013]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1127\n",
      "Val Dice - Class 1: 0.8726, Class 2: 0.8552, Avg: 0.8639\n",
      "Learning Rate: 0.003333\n",
      "\n",
      "Epoch 142/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0904]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1128\n",
      "Val Dice - Class 1: 0.8714, Class 2: 0.8537, Avg: 0.8626\n",
      "Learning Rate: 0.003282\n",
      "\n",
      "Epoch 143/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0913]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107\n",
      "Val Dice - Class 1: 0.8680, Class 2: 0.8535, Avg: 0.8607\n",
      "Learning Rate: 0.003231\n",
      "\n",
      "Epoch 144/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1234]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1137\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8527, Avg: 0.8617\n",
      "Learning Rate: 0.003180\n",
      "\n",
      "Epoch 145/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1017]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1111\n",
      "Val Dice - Class 1: 0.8704, Class 2: 0.8540, Avg: 0.8622\n",
      "Learning Rate: 0.003129\n",
      "\n",
      "Epoch 146/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.0895]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1105\n",
      "Val Dice - Class 1: 0.8727, Class 2: 0.8555, Avg: 0.8641\n",
      "Learning Rate: 0.003078\n",
      "\n",
      "Epoch 147/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1099]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1099\n",
      "Val Dice - Class 1: 0.8722, Class 2: 0.8506, Avg: 0.8614\n",
      "Learning Rate: 0.003026\n",
      "\n",
      "Epoch 148/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1258]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1115\n",
      "Val Dice - Class 1: 0.8704, Class 2: 0.8548, Avg: 0.8626\n",
      "Learning Rate: 0.002975\n",
      "\n",
      "Epoch 149/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1280]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1094\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8553, Avg: 0.8630\n",
      "Learning Rate: 0.002923\n",
      "\n",
      "Epoch 150/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1071]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1088\n",
      "Val Dice - Class 1: 0.8697, Class 2: 0.8546, Avg: 0.8621\n",
      "Learning Rate: 0.002872\n",
      "\n",
      "Epoch 151/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1097]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1091\n",
      "Val Dice - Class 1: 0.8675, Class 2: 0.8533, Avg: 0.8604\n",
      "Learning Rate: 0.002820\n",
      "\n",
      "Epoch 152/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.0896]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1082\n",
      "Val Dice - Class 1: 0.8686, Class 2: 0.8533, Avg: 0.8609\n",
      "Learning Rate: 0.002768\n",
      "\n",
      "Epoch 153/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1056]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1092\n",
      "Val Dice - Class 1: 0.8692, Class 2: 0.8549, Avg: 0.8621\n",
      "Learning Rate: 0.002716\n",
      "\n",
      "Epoch 154/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1184]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1091\n",
      "Val Dice - Class 1: 0.8728, Class 2: 0.8549, Avg: 0.8639\n",
      "Learning Rate: 0.002664\n",
      "\n",
      "Epoch 155/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.06it/s, loss=0.0943]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1091\n",
      "Val Dice - Class 1: 0.8738, Class 2: 0.8563, Avg: 0.8650\n",
      "Learning Rate: 0.002612\n",
      "\n",
      "Epoch 156/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0910]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1069\n",
      "Val Dice - Class 1: 0.8696, Class 2: 0.8549, Avg: 0.8623\n",
      "Learning Rate: 0.002560\n",
      "\n",
      "Epoch 157/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0865]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1070\n",
      "Val Dice - Class 1: 0.8721, Class 2: 0.8567, Avg: 0.8644\n",
      "Learning Rate: 0.002507\n",
      "\n",
      "Epoch 158/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1415]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1066\n",
      "Val Dice - Class 1: 0.8732, Class 2: 0.8566, Avg: 0.8649\n",
      "Learning Rate: 0.002455\n",
      "\n",
      "Epoch 159/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.04it/s, loss=0.0990]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1076\n",
      "Val Dice - Class 1: 0.8712, Class 2: 0.8559, Avg: 0.8635\n",
      "Learning Rate: 0.002402\n",
      "\n",
      "Epoch 160/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1069]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1081\n",
      "Val Dice - Class 1: 0.8702, Class 2: 0.8555, Avg: 0.8629\n",
      "Learning Rate: 0.002349\n",
      "\n",
      "Epoch 161/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.04it/s, loss=0.0908]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1073\n",
      "Val Dice - Class 1: 0.8717, Class 2: 0.8559, Avg: 0.8638\n",
      "Learning Rate: 0.002296\n",
      "\n",
      "Epoch 162/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1179]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1061\n",
      "Val Dice - Class 1: 0.8733, Class 2: 0.8578, Avg: 0.8655\n",
      "Learning Rate: 0.002243\n",
      "\n",
      "Epoch 163/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1223]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1049\n",
      "Val Dice - Class 1: 0.8735, Class 2: 0.8575, Avg: 0.8655\n",
      "Learning Rate: 0.002190\n",
      "\n",
      "Epoch 164/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.0941]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1034\n",
      "Val Dice - Class 1: 0.8731, Class 2: 0.8555, Avg: 0.8643\n",
      "Learning Rate: 0.002137\n",
      "\n",
      "Epoch 165/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1207]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1037\n",
      "Val Dice - Class 1: 0.8736, Class 2: 0.8571, Avg: 0.8654\n",
      "Learning Rate: 0.002083\n",
      "\n",
      "Epoch 166/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1165]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1045\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8531, Avg: 0.8620\n",
      "Learning Rate: 0.002030\n",
      "\n",
      "Epoch 167/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1113]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1052\n",
      "Val Dice - Class 1: 0.8738, Class 2: 0.8558, Avg: 0.8648\n",
      "Learning Rate: 0.001976\n",
      "\n",
      "Epoch 168/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1165]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1038\n",
      "Val Dice - Class 1: 0.8723, Class 2: 0.8578, Avg: 0.8650\n",
      "Learning Rate: 0.001922\n",
      "\n",
      "Epoch 169/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.1266]\n",
      "Validating: 100%|██████████| 26/26 [00:02<00:00,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1035\n",
      "Val Dice - Class 1: 0.8705, Class 2: 0.8541, Avg: 0.8623\n",
      "Learning Rate: 0.001868\n",
      "\n",
      "Epoch 170/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.0827]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1057\n",
      "Val Dice - Class 1: 0.8739, Class 2: 0.8574, Avg: 0.8657\n",
      "Learning Rate: 0.001813\n",
      "\n",
      "Epoch 171/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.0935]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1020\n",
      "Val Dice - Class 1: 0.8723, Class 2: 0.8568, Avg: 0.8645\n",
      "Learning Rate: 0.001759\n",
      "\n",
      "Epoch 172/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.1306]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1029\n",
      "Val Dice - Class 1: 0.8710, Class 2: 0.8550, Avg: 0.8630\n",
      "Learning Rate: 0.001704\n",
      "\n",
      "Epoch 173/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.0914]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1000\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8543, Avg: 0.8625\n",
      "Learning Rate: 0.001649\n",
      "\n",
      "Epoch 174/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.1040]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1018\n",
      "Val Dice - Class 1: 0.8738, Class 2: 0.8583, Avg: 0.8661\n",
      "Learning Rate: 0.001594\n",
      "✓ 保存最佳模型 (Dice: 0.8661)\n",
      "\n",
      "Epoch 175/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1037]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1008\n",
      "Val Dice - Class 1: 0.8720, Class 2: 0.8521, Avg: 0.8620\n",
      "Learning Rate: 0.001539\n",
      "\n",
      "Epoch 176/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.15it/s, loss=0.0996]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1013\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8517, Avg: 0.8612\n",
      "Learning Rate: 0.001483\n",
      "\n",
      "Epoch 177/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1324]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1009\n",
      "Val Dice - Class 1: 0.8709, Class 2: 0.8573, Avg: 0.8641\n",
      "Learning Rate: 0.001428\n",
      "\n",
      "Epoch 178/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.09it/s, loss=0.1049]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1017\n",
      "Val Dice - Class 1: 0.8729, Class 2: 0.8579, Avg: 0.8654\n",
      "Learning Rate: 0.001372\n",
      "\n",
      "Epoch 179/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.0880]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1006\n",
      "Val Dice - Class 1: 0.8707, Class 2: 0.8550, Avg: 0.8628\n",
      "Learning Rate: 0.001315\n",
      "\n",
      "Epoch 180/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0989]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1003\n",
      "Val Dice - Class 1: 0.8708, Class 2: 0.8558, Avg: 0.8633\n",
      "Learning Rate: 0.001259\n",
      "\n",
      "Epoch 181/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1182]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1011\n",
      "Val Dice - Class 1: 0.8715, Class 2: 0.8555, Avg: 0.8635\n",
      "Learning Rate: 0.001202\n",
      "\n",
      "Epoch 182/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.0932]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1003\n",
      "Val Dice - Class 1: 0.8758, Class 2: 0.8585, Avg: 0.8672\n",
      "Learning Rate: 0.001145\n",
      "✓ 保存最佳模型 (Dice: 0.8672)\n",
      "\n",
      "Epoch 183/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.19it/s, loss=0.1180]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0998\n",
      "Val Dice - Class 1: 0.8724, Class 2: 0.8568, Avg: 0.8646\n",
      "Learning Rate: 0.001088\n",
      "\n",
      "Epoch 184/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.1154]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0994\n",
      "Val Dice - Class 1: 0.8741, Class 2: 0.8580, Avg: 0.8661\n",
      "Learning Rate: 0.001030\n",
      "\n",
      "Epoch 185/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.0849]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0982\n",
      "Val Dice - Class 1: 0.8743, Class 2: 0.8579, Avg: 0.8661\n",
      "Learning Rate: 0.000972\n",
      "\n",
      "Epoch 186/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.08it/s, loss=0.1393]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0993\n",
      "Val Dice - Class 1: 0.8757, Class 2: 0.8592, Avg: 0.8674\n",
      "Learning Rate: 0.000913\n",
      "✓ 保存最佳模型 (Dice: 0.8674)\n",
      "\n",
      "Epoch 187/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.0844]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0972\n",
      "Val Dice - Class 1: 0.8727, Class 2: 0.8574, Avg: 0.8651\n",
      "Learning Rate: 0.000854\n",
      "\n",
      "Epoch 188/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1131]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0991\n",
      "Val Dice - Class 1: 0.8732, Class 2: 0.8571, Avg: 0.8651\n",
      "Learning Rate: 0.000795\n",
      "\n",
      "Epoch 189/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.14it/s, loss=0.0898]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0979\n",
      "Val Dice - Class 1: 0.8726, Class 2: 0.8572, Avg: 0.8649\n",
      "Learning Rate: 0.000735\n",
      "\n",
      "Epoch 190/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1014]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0972\n",
      "Val Dice - Class 1: 0.8735, Class 2: 0.8583, Avg: 0.8659\n",
      "Learning Rate: 0.000675\n",
      "\n",
      "Epoch 191/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.1026]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0971\n",
      "Val Dice - Class 1: 0.8704, Class 2: 0.8546, Avg: 0.8625\n",
      "Learning Rate: 0.000614\n",
      "\n",
      "Epoch 192/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1096]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0964\n",
      "Val Dice - Class 1: 0.8729, Class 2: 0.8572, Avg: 0.8650\n",
      "Learning Rate: 0.000552\n",
      "\n",
      "Epoch 193/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.10it/s, loss=0.0868]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0988\n",
      "Val Dice - Class 1: 0.8732, Class 2: 0.8598, Avg: 0.8665\n",
      "Learning Rate: 0.000489\n",
      "\n",
      "Epoch 194/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.07it/s, loss=0.0918]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0958\n",
      "Val Dice - Class 1: 0.8742, Class 2: 0.8563, Avg: 0.8653\n",
      "Learning Rate: 0.000426\n",
      "\n",
      "Epoch 195/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.0958]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0979\n",
      "Val Dice - Class 1: 0.8733, Class 2: 0.8578, Avg: 0.8656\n",
      "Learning Rate: 0.000362\n",
      "\n",
      "Epoch 196/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.15it/s, loss=0.0712]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0970\n",
      "Val Dice - Class 1: 0.8732, Class 2: 0.8570, Avg: 0.8651\n",
      "Learning Rate: 0.000296\n",
      "\n",
      "Epoch 197/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1040]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0963\n",
      "Val Dice - Class 1: 0.8748, Class 2: 0.8591, Avg: 0.8670\n",
      "Learning Rate: 0.000228\n",
      "\n",
      "Epoch 198/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.13it/s, loss=0.0980]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0963\n",
      "Val Dice - Class 1: 0.8745, Class 2: 0.8578, Avg: 0.8661\n",
      "Learning Rate: 0.000158\n",
      "\n",
      "Epoch 199/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.12it/s, loss=0.1221]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0959\n",
      "Val Dice - Class 1: 0.8751, Class 2: 0.8594, Avg: 0.8673\n",
      "Learning Rate: 0.000085\n",
      "\n",
      "Epoch 200/200\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 104/104 [00:12<00:00,  8.11it/s, loss=0.0976]\n",
      "Validating: 100%|██████████| 26/26 [00:03<00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0958\n",
      "Val Dice - Class 1: 0.8713, Class 2: 0.8548, Avg: 0.8630\n",
      "Learning Rate: 0.000000\n",
      "\n",
      "============================================================\n",
      "訓練完成！Seed: 42\n",
      "最佳驗證 Dice: 0.8674\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "增強版 nnU-Net - 用於 Ensemble\n",
    "- 200 epochs（更長訓練）\n",
    "- 48 base channels（更大模型）\n",
    "- 支持多個隨機種子訓練\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "# 檢查 scipy 是否可用\n",
    "SCIPY_AVAILABLE = False\n",
    "try:\n",
    "    import scipy\n",
    "    SCIPY_AVAILABLE = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# ==================== 設置隨機種子 ====================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==================== nnU-Net 架構（與之前相同）====================\n",
    "\n",
    "class nnUNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.norm = nn.InstanceNorm3d(out_channels, affine=True)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.activation(self.norm(self.conv(x)))\n",
    "\n",
    "class nnUNetResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nnUNetConvBlock(in_channels, out_channels)\n",
    "        self.conv2 = nnUNetConvBlock(out_channels, out_channels)\n",
    "        self.skip = None\n",
    "        if in_channels != out_channels:\n",
    "            self.skip = nn.Conv3d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.skip is not None:\n",
    "            residual = self.skip(residual)\n",
    "        return out + residual\n",
    "\n",
    "class nnUNetDownsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nnUNetConvBlock(in_channels, out_channels, kernel_size=3, stride=2, padding=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class nnUNetUpsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.upconv(x)\n",
    "\n",
    "class nnUNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3, base_channels=48, num_pool=3, deep_supervision=True):\n",
    "        super().__init__()\n",
    "        self.num_pool = num_pool\n",
    "        self.deep_supervision = deep_supervision\n",
    "        \n",
    "        # 編碼器\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.downsamplers = nn.ModuleList()\n",
    "        \n",
    "        current_channels = in_channels\n",
    "        for i in range(num_pool + 1):\n",
    "            out_channels = base_channels * (2 ** i)\n",
    "            self.encoders.append(nnUNetResidualBlock(current_channels, out_channels))\n",
    "            if i < num_pool:\n",
    "                self.downsamplers.append(nnUNetDownsample(out_channels, out_channels))\n",
    "            current_channels = out_channels\n",
    "        \n",
    "        # 解碼器\n",
    "        self.upsamplers = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_pool):\n",
    "            in_ch = base_channels * (2 ** (num_pool - i))\n",
    "            out_ch = base_channels * (2 ** (num_pool - i - 1))\n",
    "            self.upsamplers.append(nnUNetUpsample(in_ch, out_ch))\n",
    "            self.decoders.append(nnUNetResidualBlock(in_ch, out_ch))\n",
    "        \n",
    "        # 輸出頭\n",
    "        self.seg_outputs = nn.ModuleList()\n",
    "        for i in range(num_pool + 1):\n",
    "            out_ch = base_channels * (2 ** i)\n",
    "            self.seg_outputs.append(nn.Conv3d(out_ch, num_classes, kernel_size=1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoder_outputs = []\n",
    "        current = x\n",
    "        \n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            current = encoder(current)\n",
    "            encoder_outputs.append(current)\n",
    "            if i < self.num_pool:\n",
    "                current = self.downsamplers[i](current)\n",
    "        \n",
    "        seg_outputs = []\n",
    "        if self.deep_supervision:\n",
    "            seg_outputs.append(self.seg_outputs[-1](encoder_outputs[-1]))\n",
    "        \n",
    "        current = encoder_outputs[-1]\n",
    "        for i in range(self.num_pool):\n",
    "            current = self.upsamplers[i](current)\n",
    "            skip = encoder_outputs[-(i + 2)]\n",
    "            current = torch.cat([current, skip], dim=1)\n",
    "            current = self.decoders[i](current)\n",
    "            if self.deep_supervision:\n",
    "                seg_outputs.append(self.seg_outputs[-(i + 2)](current))\n",
    "        \n",
    "        final_output = self.seg_outputs[0](current) if not self.deep_supervision else seg_outputs[-1]\n",
    "        \n",
    "        if self.deep_supervision and self.training:\n",
    "            return list(reversed(seg_outputs))\n",
    "        else:\n",
    "            return final_output\n",
    "\n",
    "# ==================== 損失函數 ====================\n",
    "\n",
    "class nnUNetLoss(nn.Module):\n",
    "    def __init__(self, deep_supervision_weights=None, dice_weight=1.0, ce_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.deep_supervision_weights = deep_supervision_weights\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def dice_loss(self, pred, target, smooth=1.0):\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        dice_scores = []\n",
    "        for c in range(pred.shape[1]):\n",
    "            pred_c = pred[:, c]\n",
    "            target_c = (target == c).float()\n",
    "            intersection = (pred_c * target_c).sum()\n",
    "            union = pred_c.sum() + target_c.sum()\n",
    "            dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "            dice_scores.append(dice)\n",
    "        return 1.0 - torch.stack(dice_scores).mean()\n",
    "    \n",
    "    def forward(self, outputs, target):\n",
    "        if isinstance(outputs, (list, tuple)):\n",
    "            if self.deep_supervision_weights is None:\n",
    "                weights = [1.0 / (2 ** i) for i in range(len(outputs))]\n",
    "                weights = [w / sum(weights) for w in weights]\n",
    "            else:\n",
    "                weights = self.deep_supervision_weights\n",
    "            \n",
    "            total_loss = 0\n",
    "            for i, output in enumerate(outputs):\n",
    "                if output.shape[2:] != target.shape[1:]:\n",
    "                    target_resized = F.interpolate(\n",
    "                        target.unsqueeze(1).float(),\n",
    "                        size=output.shape[2:],\n",
    "                        mode='nearest'\n",
    "                    ).squeeze(1).long()\n",
    "                else:\n",
    "                    target_resized = target\n",
    "                \n",
    "                ce = self.ce_loss(output, target_resized)\n",
    "                dice = self.dice_loss(output, target_resized)\n",
    "                total_loss += weights[i] * (self.ce_weight * ce + self.dice_weight * dice)\n",
    "            return total_loss\n",
    "        else:\n",
    "            ce = self.ce_loss(outputs, target)\n",
    "            dice = self.dice_loss(outputs, target)\n",
    "            return self.ce_weight * ce + self.dice_weight * dice\n",
    "\n",
    "# ==================== 數據增強 ====================\n",
    "\n",
    "class nnUNetAugmentation:\n",
    "    @staticmethod\n",
    "    def random_rotation(image, label, angle_range=(-20, 20)):  # 增強到 ±20°\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            if random.random() > 0.5:\n",
    "                k = random.randint(1, 3)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = np.rot90(image, k, axes).copy()\n",
    "                label = np.rot90(label, k, axes).copy()\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                from scipy.ndimage import rotate\n",
    "                angle = random.uniform(*angle_range)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = rotate(image, angle, axes=axes, reshape=False, order=3, mode='constant')\n",
    "                label = rotate(label, angle, axes=axes, reshape=False, order=0, mode='constant')\n",
    "            except:\n",
    "                k = random.randint(1, 3)\n",
    "                axes = random.choice([(0, 1), (0, 2), (1, 2)])\n",
    "                image = np.rot90(image, k, axes).copy()\n",
    "                label = np.rot90(label, k, axes).copy()\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_scaling(image, label, scale_range=(0.8, 1.3)):  # 增強縮放範圍\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.5:\n",
    "            try:\n",
    "                from scipy.ndimage import zoom\n",
    "                scale = random.uniform(*scale_range)\n",
    "                scales = [scale] * 3\n",
    "                image = zoom(image, scales, order=3, mode='constant')\n",
    "                label = zoom(label, scales, order=0, mode='constant')\n",
    "            except:\n",
    "                pass\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_elastic_deformation(image, label, alpha=100, sigma=10):\n",
    "        if not SCIPY_AVAILABLE:\n",
    "            return image, label\n",
    "        \n",
    "        if random.random() > 0.3:\n",
    "            try:\n",
    "                from scipy.ndimage import gaussian_filter, map_coordinates\n",
    "                shape = image.shape\n",
    "                dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                dz = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "                x, y, z = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "                indices = np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1)), np.reshape(z + dz, (-1, 1))\n",
    "                image = map_coordinates(image, indices, order=3, mode='reflect').reshape(shape)\n",
    "                label = map_coordinates(label, indices, order=0, mode='reflect').reshape(shape)\n",
    "            except:\n",
    "                pass\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_gamma(image, gamma_range=(0.7, 1.5)):\n",
    "        if random.random() > 0.5:\n",
    "            gamma = random.uniform(*gamma_range)\n",
    "            image_min = image.min()\n",
    "            image_range = image.max() - image_min\n",
    "            if image_range > 0:\n",
    "                image = ((image - image_min) / image_range) ** gamma * image_range + image_min\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_brightness(image, brightness_range=(-0.2, 0.2)):\n",
    "        if random.random() > 0.5:\n",
    "            brightness = random.uniform(*brightness_range)\n",
    "            image = image + brightness * image.std()\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_contrast(image, contrast_range=(0.75, 1.25)):\n",
    "        if random.random() > 0.5:\n",
    "            contrast = random.uniform(*contrast_range)\n",
    "            mean = image.mean()\n",
    "            image = (image - mean) * contrast + mean\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_flip(image, label):\n",
    "        for axis in range(3):\n",
    "            if random.random() > 0.5:\n",
    "                image = np.flip(image, axis=axis).copy()\n",
    "                label = np.flip(label, axis=axis).copy()\n",
    "        return image, label\n",
    "\n",
    "# ==================== 數據集 ====================\n",
    "\n",
    "class nnUNetDataset(Dataset):\n",
    "    def __init__(self, data_dir, target_size=64, is_train=True, use_augmentation=True):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.target_size = target_size\n",
    "        self.is_train = is_train\n",
    "        self.use_augmentation = use_augmentation and is_train\n",
    "        \n",
    "        all_image_files = list((self.data_dir / 'imagesTr').glob('*.nii.gz'))\n",
    "        self.image_files = sorted([f for f in all_image_files if not f.name.startswith('._')])\n",
    "        all_label_files = list((self.data_dir / 'labelsTr').glob('*.nii.gz'))\n",
    "        self.label_files = sorted([f for f in all_label_files if not f.name.startswith('._')])\n",
    "        \n",
    "        if len(self.image_files) == 0:\n",
    "            raise ValueError(f\"在 {self.data_dir / 'imagesTr'} 找不到任何 .nii.gz 文件！\")\n",
    "        \n",
    "        self.aug = nnUNetAugmentation()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def preprocess(self, image):\n",
    "        p1, p99 = np.percentile(image[image > 0], [0.5, 99.5]) if (image > 0).any() else (0, 1)\n",
    "        image = np.clip(image, p1, p99)\n",
    "        mean = image[image > 0].mean() if (image > 0).any() else 0\n",
    "        std = image[image > 0].std() if (image > 0).any() else 1\n",
    "        image = (image - mean) / (std + 1e-8)\n",
    "        return image\n",
    "    \n",
    "    def apply_augmentation(self, image, label):\n",
    "        image, label = self.aug.random_rotation(image, label)\n",
    "        image, label = self.aug.random_scaling(image, label)\n",
    "        image, label = self.aug.random_flip(image, label)\n",
    "        image = self.aug.random_gamma(image)\n",
    "        image = self.aug.random_brightness(image)\n",
    "        image = self.aug.random_contrast(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = nib.load(self.image_files[idx]).get_fdata(dtype=np.float32)\n",
    "        label = nib.load(self.label_files[idx]).get_fdata(dtype=np.float32)\n",
    "        \n",
    "        image = self.preprocess(image)\n",
    "        \n",
    "        if self.use_augmentation:\n",
    "            image, label = self.apply_augmentation(image, label)\n",
    "        \n",
    "        image = torch.from_numpy(image).unsqueeze(0).unsqueeze(0)\n",
    "        label = torch.from_numpy(label).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        image = F.interpolate(image, size=(self.target_size, self.target_size, self.target_size),\n",
    "                            mode='trilinear', align_corners=False).squeeze(0)\n",
    "        label = F.interpolate(label, size=(self.target_size, self.target_size, self.target_size),\n",
    "                            mode='nearest').squeeze(0)\n",
    "        \n",
    "        label = label.squeeze(0).long()\n",
    "        label = torch.clamp(label, 0, 2)\n",
    "        return image, label\n",
    "\n",
    "# ==================== 評估指標 ====================\n",
    "\n",
    "def compute_dice(pred, target, num_classes=3):\n",
    "    dice_scores = []\n",
    "    for c in range(1, num_classes):\n",
    "        pred_c = (pred == c)\n",
    "        target_c = (target == c)\n",
    "        intersection = (pred_c & target_c).sum().float()\n",
    "        union = pred_c.sum().float() + target_c.sum().float()\n",
    "        if union == 0:\n",
    "            dice = 1.0 if intersection == 0 else 0.0\n",
    "        else:\n",
    "            dice = (2.0 * intersection) / union\n",
    "        dice_scores.append(dice.item())\n",
    "    return dice_scores\n",
    "\n",
    "# ==================== 學習率調度器 ====================\n",
    "\n",
    "class PolynomialLRScheduler:\n",
    "    def __init__(self, optimizer, initial_lr, max_epochs, power=0.9):\n",
    "        self.optimizer = optimizer\n",
    "        self.initial_lr = initial_lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.power = power\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def step(self):\n",
    "        self.current_epoch += 1\n",
    "        lr = self.initial_lr * (1 - self.current_epoch / self.max_epochs) ** self.power\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        return lr\n",
    "\n",
    "# ==================== 訓練函數 ====================\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 12)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_dice_scores = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            if isinstance(outputs, (list, tuple)):\n",
    "                outputs = outputs[-1]\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            for pred, label in zip(preds, labels):\n",
    "                dice_scores = compute_dice(pred.cpu(), label.cpu())\n",
    "                all_dice_scores.append(dice_scores)\n",
    "    all_dice_scores = np.array(all_dice_scores)\n",
    "    mean_dice = all_dice_scores.mean(axis=0)\n",
    "    return mean_dice\n",
    "\n",
    "# ==================== 主訓練流程 ====================\n",
    "\n",
    "def main(seed=42):\n",
    "    set_seed(seed)\n",
    "    \n",
    "    config = {\n",
    "        'data_dir': './Task04_Hippocampus',\n",
    "        'batch_size': 2,\n",
    "        'num_epochs': 200,  # 增加到 200\n",
    "        'initial_lr': 1e-2,\n",
    "        'base_channels': 48,  # 增加到 48\n",
    "        'num_pool': 3,\n",
    "        'target_size': 64,\n",
    "        'deep_supervision': True,\n",
    "        'use_augmentation': True,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'seed': seed\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"增強版 nnU-Net 訓練 (Seed: {seed})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"配置:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "    \n",
    "    device = torch.device(config['device'])\n",
    "    \n",
    "    # 數據集\n",
    "    full_dataset = nnUNetDataset(\n",
    "        config['data_dir'],\n",
    "        target_size=config['target_size'],\n",
    "        is_train=True,\n",
    "        use_augmentation=config['use_augmentation']\n",
    "    )\n",
    "    \n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'],\n",
    "                            shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'],\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    print(f\"訓練集: {len(train_dataset)} 樣本\")\n",
    "    print(f\"驗證集: {len(val_dataset)} 樣本\\n\")\n",
    "    \n",
    "    # 模型\n",
    "    model = nnUNet(\n",
    "        in_channels=1,\n",
    "        num_classes=3,\n",
    "        base_channels=config['base_channels'],\n",
    "        num_pool=config['num_pool'],\n",
    "        deep_supervision=config['deep_supervision']\n",
    "    ).to(device)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型參數量: {total_params:,} ({total_params/1e6:.2f}M)\\n\")\n",
    "    \n",
    "    # 優化器\n",
    "    criterion = nnUNetLoss(dice_weight=1.0, ce_weight=1.0)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config['initial_lr'],\n",
    "                               momentum=0.99, weight_decay=3e-5, nesterov=True)\n",
    "    scheduler = PolynomialLRScheduler(optimizer, config['initial_lr'],\n",
    "                                     config['num_epochs'], power=0.9)\n",
    "    \n",
    "    # 訓練\n",
    "    best_dice = 0.0\n",
    "    output_dir = Path('./outputs')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    for epoch in range(config['num_epochs']):\n",
    "        print(f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_dice = validate(model, val_loader, device)\n",
    "        current_lr = scheduler.step()\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Dice - Class 1: {val_dice[0]:.4f}, Class 2: {val_dice[1]:.4f}, \"\n",
    "              f\"Avg: {val_dice.mean():.4f}\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "        \n",
    "        if val_dice.mean() > best_dice:\n",
    "            best_dice = val_dice.mean()\n",
    "            save_path = output_dir / f'nnunet_enhanced_seed{seed}_best.pth'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'dice': val_dice,\n",
    "                'config': config\n",
    "            }, save_path)\n",
    "            print(f\"✓ 保存最佳模型 (Dice: {best_dice:.4f})\")\n",
    "        print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"訓練完成！Seed: {seed}\")\n",
    "    print(f\"最佳驗證 Dice: {best_dice:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return best_dice\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 檢測是否在 Jupyter 環境中\n",
    "    try:\n",
    "        get_ipython()\n",
    "        # 在 Jupyter 中，直接使用默認種子\n",
    "        print(\"檢測到 Jupyter 環境，使用默認種子 42\")\n",
    "        main(seed=42)\n",
    "    except NameError:\n",
    "        # 在命令行中，使用 argparse\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--seed', type=int, default=42, help='隨機種子')\n",
    "        args = parser.parse_args()\n",
    "        main(seed=args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a965f-6956-4aba-a6b0-098c16faba99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
